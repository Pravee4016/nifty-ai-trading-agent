NIFTY AI TRADING AGENT - FULL SOURCE CODE
==========================================

# ======================================================================
# FILE: main.py
# ======================================================================

"""
Nifty AI Trading Agent - Main Entry Point
Uses AppFactory pattern and centralized logging.
"""
import logging
import pytz
from datetime import datetime, time
import argparse

# Config
from config.settings import TIME_ZONE, DEBUG_MODE
from config.logging_config import setup_logging

# App Bootstrap
from app.bootstrap import create_agent

# Dependencies for standalone tasks
from data_module.persistence import get_persistence
from telegram_module.bot_handler import get_bot

# Setup Logger
logger = setup_logging(__name__)

# ------------------------------------------------------
# Helper Functions
# ------------------------------------------------------

def _is_market_hours_quick():
    """Quick market hours check for early exit (Cloud Function optimization)."""
    ist = pytz.timezone("Asia/Kolkata")
    now = datetime.now(ist).time()
    today = datetime.now(ist).weekday()
    # Allow execution until 16:30 for EOD activities (Summary, Market Closed Alert)
    # Weekdays only (0-4)
    if today > 4: return False
    return time(9, 15) <= now <= time(16, 30)

def check_and_send_market_closed_alert():
    """
    Check if 'Market Closed' alert has been sent today. 
    If not, and it is after 15:30 IST, send it once.
    """
    try:
        tz = pytz.timezone(TIME_ZONE)
        now = datetime.now(tz)
        
        # Only check if it's after market close (15:30)
        # We use 15:30 inclusive in case the job runs exactly then
        if now.time() >= time(15, 30):
            persistence = get_persistence()
            stats = persistence.get_daily_stats()
            
            if not stats.get("market_closed_msg_sent"):
                logger.info("üåô Market Closed - Sending one-time alert")
                bot = get_bot()
                bot.send_message("üåô <b>Market Closed</b> - Analysis Paused")
                persistence.increment_stat("market_closed_msg_sent")
            else:
                logger.debug("üåô Market Closed - Alert already sent today")
                
    except Exception as e:
        logger.error(f"‚ùå Failed to check/send market closed alert: {e}")

# ------------------------------------------------------
# Main Execution
# ------------------------------------------------------

def main():
    """Main entry point for local run or cloud function."""
    logger.info("üöÄ Agent starting...")
    
    # Use Factory to create agent
    try:
        agent = create_agent()
    except Exception as e:
        logger.critical("üî• Agent initialization failed. Exiting.")
        return

    logger.info("\nüîå Testing external connections...")
    if not agent.ai_analyzer.test_connection():
        logger.error("‚ùå Groq API connection failed")
        agent.telegram_bot.send_error_notification(
            "Groq API connection failed"
        )
        return

    if not agent.telegram_bot.test_connection():
        logger.error("‚ùå Telegram connection failed")
        return

    logger.info("‚úÖ All connections successful\n")

    # Check for scheduled messages (Startup, Market Context, EOD Summary)
    # Must run outside is_market_hours() to catch EOD summary at 15:31+
    agent.check_scheduled_messages()

    if agent.is_market_hours():
        # Run Analysis
        results = agent.run_analysis()
    else:
        logger.info("‚è∞ Outside market hours - skipping analysis")
        check_and_send_market_closed_alert()

    stats = agent.get_statistics()
    logger.info("\nüìà STATISTICS")
    logger.info(f"   Signals: {stats['signals_generated']}")
    logger.info(f"   Alerts Sent: {stats['alerts_sent']}")
    logger.info(
        f"   AI Usage: {stats['ai_usage']['tokens_used']} tokens used"
    )


def cloud_function_handler(request):
    """Entry point for Google Cloud Functions."""
    # Early exit for outside market hours (avoid full initialization)
    if not _is_market_hours_quick():
        # Check if we need to send the "Market Closed" alert before exiting
        check_and_send_market_closed_alert()
        return {"status": "skipped", "message": "Outside market hours"}
    
    logger.info("‚òÅÔ∏è  Cloud Function triggered")
    main()
    return {"status": "success", "message": "Analysis completed"}


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Nifty AI Trading Agent")
    parser.add_argument(
        "--once", action="store_true", help="Run analysis once"
    )
    parser.add_argument(
        "--test", action="store_true", help="Test connections only"
    )

    args = parser.parse_args()

    if args.test:
        logger.info("üîß Running Connection Tests...")
        try:
            agent = create_agent()
            logger.info("Testing connections...")
            if agent.ai_analyzer.test_connection():
                logger.info("‚úÖ AI Connection OK")
            else:
                logger.error("‚ùå AI Connection FAILED")
                
            if agent.telegram_bot.test_connection():
                 logger.info("‚úÖ Telegram Connection OK")
            else:
                 logger.error("‚ùå Telegram Connection FAILED")
                 
        except Exception as e:
            logger.error(f"‚ùå Test initialization failed: {e}")
    else:
        main()


# ======================================================================
# FILE: audit_system.py
# ======================================================================


import sys
import os
import logging
import pandas as pd
from datetime import datetime
from unittest.mock import MagicMock, patch

# Add project root to path
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from main import NiftyTradingAgent
from config.settings import INSTRUMENTS

# Configure Logging
logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
logger = logging.getLogger("SystemAudit")

def create_mock_ohlcv(rows=500, trend="UP"):
    """Generate mock OHLCV data."""
    data = []
    price = 25000.0
    for i in range(rows):
        if trend == "UP":
            price += 10 if i % 2 == 0 else -5
        else:
            price -= 10 if i % 2 == 0 else 5
            
        high = price + 20
        low = price - 20
        close = price + 5
        volume = 100000 + (i * 100)
        
        data.append({
            "timestamp": datetime.now(),
            "open": price,
            "high": high,
            "low": low,
            "close": close,
            "volume": volume
        })
    df = pd.DataFrame(data)
    df.set_index("timestamp", inplace=True)
    return df

def audit_system():
    logger.info("üöÄ Starting System Health Audit...")
    
    try:
        # 1. Initialize Agent
        logger.info("Step 1: Initializing Agent...")
        agent = NiftyTradingAgent()
        logger.info("‚úÖ Agent Initialized")

        # 2. Mock Data Fetcher
        logger.info("Step 2: Mocking Data Sources...")
        agent.fetcher.fetch_nse_data = MagicMock(return_value={"price": 25500, "lastPrice": 25500})
        agent.fetcher.fetch_historical_data = MagicMock(side_effect=[
            create_mock_ohlcv(500, "UP"), # 5m
            create_mock_ohlcv(500, "UP"), # 15m
            create_mock_ohlcv(50, "UP")   # Daily
        ])
        agent.fetcher.preprocess_ohlcv = MagicMock(side_effect=lambda x: x) # Passthrough

        # 3. Mock Option Fetcher
        logger.info("Step 3: Mocking Option Chain...")
        agent.option_fetcher.fetch_option_chain = MagicMock(return_value={
            "records": {
                "expiryDates": ["12-Dec-2024"],
                "data": []
            },
            "filtered": {
                "data": []
            }
        })
        
        # 4. Mock AI & Telegram (Don't want real calls)
        agent.groq_analyzer.analyze_signal = MagicMock(return_value={"verdict": "BULLISH", "confidence": 85, "reasoning": "Audit Test"})
        agent.telegram_bot.send_message = MagicMock(return_value=True)
        agent.telegram_bot.send_alert = MagicMock(return_value=True)

        # 5. Run Analysis
        logger.info("Step 4: Running Full Analysis Cycle...")
        results = agent.run_analysis(instruments=["NIFTY"])
        
        logger.info(f"üìä Audit Results: {results}")
        
        if results["errors"] > 0:
            logger.error(f"‚ùå Audit Failed with {results['errors']} errors!")
            sys.exit(1)
            
        if results["signals_generated"] == 0:
             logger.warning("‚ö†Ô∏è No signals generated (Check filters?)")
        else:
             logger.info(f"‚úÖ Generated {results['signals_generated']} signals")

        logger.info("‚úÖ System Audit Passed!")

    except Exception as e:
        logger.error(f"‚ùå CRITICAL AUDIT FAILURE: {e}", exc_info=True)
        sys.exit(1)

if __name__ == "__main__":
    audit_system()


# ======================================================================
# FILE: app/__init__.py
# ======================================================================



# ======================================================================
# FILE: app/agent.py
# ======================================================================

"""
NIFTY AI TRADING AGENT - Main Orchestrator
Coordinates: Data ‚Üí Technical Analysis ‚Üí AI ‚Üí Telegram Alerts
"""

import sys
import os
import logging
from datetime import datetime, time, timedelta
import pytz
import pandas as pd
from typing import Dict, List, Optional, Tuple, Union

from config.settings import (
    INSTRUMENTS,
    ANALYSIS_START_TIME,
    MARKET_CLOSE_TIME,
    TIME_ZONE,
    DEBUG_MODE,
    MIN_VOLUME_RATIO,
    MIN_SIGNAL_CONFIDENCE,
)
# MIN_SIGNAL_CONFIDENCE is imported from settings

from data_module.fetcher import get_data_fetcher, DataFetcher
from analysis_module.signal_pipeline import SignalPipeline
from analysis_module.technical import TechnicalAnalyzer, Signal, TechnicalLevels
from ai_module.groq_analyzer import get_analyzer, GroqAnalyzer
from telegram_module.bot_handler import get_bot, TelegramBotHandler, format_signal_message
from data_module.persistence import get_persistence
from data_module.persistence_models import AlertKey, build_alert_key
from data_module.trade_tracker import get_trade_tracker, TradeTracker
from data_module.option_chain_fetcher import OptionChainFetcher

from analysis_module.option_chain_analyzer import OptionChainAnalyzer
from analysis_module.manipulation_guard import CircuitBreaker
from config.logging_config import setup_logging

# ------------------------------------------------------
# Market Hours Check (moved to cloud_function_handler)
# ------------------------------------------------------
def _is_market_hours_quick():
    """Quick market hours check for early exit."""
    ist = pytz.timezone("Asia/Kolkata")
    now = datetime.now(ist).time()
    today = datetime.now(ist).weekday()
    # Allow execution until 16:30 for EOD activities (Summary, Market Closed Alert)
    # Weekdays only (0-4)
    if today > 4: return False
    return time(9, 15) <= now <= time(16, 30)

logger = setup_logging(__name__)


class NiftyTradingAgent:
    """Main trading agent orchestrator."""

    def __init__(self):
        self.fetcher: DataFetcher = get_data_fetcher()
        self.option_analyzer = OptionChainAnalyzer()
        self.trade_tracker = TradeTracker()
        self.bot_handler = TelegramBotHandler()
        self.telegram_bot = self.bot_handler  # Alias for consistency
        self.groq_analyzer = GroqAnalyzer()
        self.ai_analyzer = self.groq_analyzer # Alias for compatibility
        self.persistence = get_persistence()
        self.option_fetcher = OptionChainFetcher()
        self.circuit_breaker = CircuitBreaker()
        
        # Initialize Signal Pipeline
        self.signal_pipeline = SignalPipeline(groq_analyzer=self.groq_analyzer)
        
        self.signals_generated: List[Dict] = []
        self.alerts_sent = 0
        
        # Daily event tracking for EOD summary
        self.daily_breakouts: List[Dict] = []
        self.daily_breakdowns: List[Dict] = []
        self.daily_retests: List[Dict] = []
        self.daily_reversals: List[Dict] = []
        self.daily_data_fetches = 0
        self.daily_analyses = 0
        
        # Duplicate alert prevention - Load from Firestore (persistent across executions)
        self.recent_alerts: Dict[str, datetime] = self.persistence.get_recent_alerts()
        logger.info(f"üìÇ Loaded {len(self.recent_alerts)} recent alerts from Firestore")
        
        # Level-based memory (tracks S/R levels to prevent repeats all day)
        self.daily_level_memory: set = set()
        
        # Market Context for AI Analysis
        self.market_context: Dict = {}

        logger.info("=" * 70)
        logger.info("ü§ñ Nifty AI Trading Agent Initialized (Phase 3: AI Analyst)")
        logger.info("=" * 70)
        logger.info(f"Mode: {'DEBUG' if DEBUG_MODE else 'PRODUCTION'}")
        logger.info(f"Timezone: {TIME_ZONE}")
        logger.info(f"Analysis start time: {ANALYSIS_START_TIME}")

    # =====================================================================
    # MAIN EXECUTION
    # =====================================================================

    def run_analysis(self, instruments: List[str] = None) -> Dict:
        """
        Main analysis execution loop.
        """
        if instruments is None:
            instruments = [
                k for k, v in INSTRUMENTS.items() if v.get("active", False)
            ]

        logger.info(f"\nüìä ANALYSIS STARTED | Instruments: {instruments}")
        logger.info("=" * 70)

        # Track data fetch count
        self.persistence.increment_stat("data_fetches", len(instruments))

        results = {
            "timestamp": datetime.now().isoformat(),
            "instruments_analyzed": 0,
            "signals_generated": 0,
            "alerts_sent": 0,
            "errors": 0,
            "details": {},
        }

        for instrument in instruments:
            try:
                logger.info(f"\nüîç Analyzing: {instrument}")
                logger.info("-" * 70)

                instrument_result = self._analyze_single_instrument(instrument)
                results["details"][instrument] = instrument_result

                if instrument_result["success"]:
                    results["instruments_analyzed"] += 1
                    results["signals_generated"] += instrument_result[
                        "signals_count"
                    ]
                    results["alerts_sent"] += instrument_result["alerts_sent"]
                else:
                    results["errors"] += 1
                
                self.persistence.increment_stat("analyses_run")

            except Exception as e:
                logger.error(
                    f"‚ùå Error analyzing {instrument}: {str(e)}",
                    exc_info=DEBUG_MODE,
                )
                results["errors"] += 1

        self._print_analysis_summary(results)
        return results

    def _analyze_single_instrument(self, instrument: str) -> Dict:
        """Analyze single instrument with 5m + 15m data and MTF filters."""
        result = {
            "instrument": instrument,
            "success": False,
            "signals_count": 0,
            "alerts_sent": 0,
            "signals": [],
            "errors": [],
        }

        try:
            logger.debug("Step 1: Fetching real-time market data (Fyers/YF)...")
            market_data = self.fetcher.fetch_realtime_data(instrument)

            if not market_data:
                logger.warning("‚ö†Ô∏è  Market data fetch failed, using empty fallback")
                market_data = {}  # Empty dict as fallback


            logger.debug("Step 2: Fetching 5m and 15m historical data...")
            df_5m = self.fetcher.fetch_historical_data(
                instrument, period="5d", interval="5m"
            )
            df_15m = self.fetcher.fetch_historical_data(
                instrument, period="10d", interval="15m"
            )
            # Fetch daily data for previous day trend
            df_daily = self.fetcher.fetch_historical_data(
                instrument, period="5d", interval="1d"
            )

            if df_5m is None or df_5m.empty:
                logger.error("‚ùå No 5m historical data available")
                result["errors"].append("5m data unavailable")
                return result

            if df_15m is None or df_15m.empty:
                logger.error("‚ùå No 15m historical data available")
                result["errors"].append("15m data unavailable")
                return result

            df_5m = self.fetcher.preprocess_ohlcv(df_5m)
            df_15m = self.fetcher.preprocess_ohlcv(df_15m)
            if df_daily is not None and not df_daily.empty:
                df_daily = self.fetcher.preprocess_ohlcv(df_daily)

            logger.debug(
                f"5m shape: {df_5m.shape} | 15m shape: {df_15m.shape}"
            )

            # --- MANIPULATION DEFENSE (Phase 4) ---
            current_price = market_data.get("price", df_5m.iloc[-1]['close'])
            is_safe, safety_reason = self.circuit_breaker.check_market_integrity(df_5m, current_price, instrument)
            if not is_safe:
                logger.warning(f"üõ°Ô∏è MANIPULATION GUARD ACTIVE: {safety_reason}")
                result["errors"].append(f"SAFETY LOCK: {safety_reason}")
                # Log event but gracefully exit analysis for this instrument
                return result
            # --------------------------------------

            analyzer = TechnicalAnalyzer(instrument)
            higher_tf_context = analyzer.get_higher_tf_context(df_15m, df_5m, df_daily)
            
            # Update global market context for AI
            self.market_context[instrument] = {
                "trend_5m": higher_tf_context.get("trend_5m", "NEUTRAL"),
                "trend_15m": higher_tf_context.get("trend_15m", "NEUTRAL"),
                "trend_daily": higher_tf_context.get("trend_daily", "NEUTRAL"),
                "volatility_score": higher_tf_context.get("volatility_score", 0),
                "pdh": higher_tf_context.get("pdh", 0),
                "pdl": higher_tf_context.get("pdl", 0),
                "last_price": current_price
            }
            
            analysis = analyzer.analyze_with_multi_tf(
                df_5m, higher_tf_context, df_15m=df_15m
            )
            # Inject context for signal generation
            analysis["higher_tf_context"] = higher_tf_context
            
            # Check and auto-close open trades based on current price
            current_price = market_data.get("lastPrice", 0)
            if current_price > 0:
                closed = self.trade_tracker.check_open_trades({instrument: current_price})
                if closed > 0:
                    logger.info(f"   ‚úÖ Auto-closed {closed} trade(s) for {instrument}")

            signals = self._generate_signals(instrument, analysis, market_data, df_5m)

            enriched_signals = []
            for sig in signals:
                if "BREAKOUT" in sig.get("signal_type", ""):
                    direction = (
                        "UP"
                        if "BULLISH" in sig["signal_type"]
                        else "DOWN"
                    )
                    is_false, fb_details = analyzer.detect_false_breakout(
                        df_5m, sig["price_level"], direction
                    )
                    sig["false_breakout"] = is_false
                    sig["false_breakout_details"] = fb_details
                enriched_signals.append(sig)

            final_signals = []
            for sig in enriched_signals:
                if sig.get("false_breakout"):
                    logger.info(
                        "‚è≠Ô∏è  Suppressing alert due to false breakout | "
                        f"{sig['instrument']} @ {sig['price_level']:.2f}"
                    )
                    # Optionally send a dedicated false breakout alert:
                    # self.telegram_bot.send_false_breakout_alert(sig)
                    continue
                final_signals.append(sig)

            result["signals"] = final_signals
            result["signals_count"] = len(final_signals)

            for signal in final_signals:
                ai_analysis = self._get_ai_analysis(signal)
                signal["ai_analysis"] = ai_analysis
                
                # Track events for daily summary
                self._track_daily_event(signal)

                if self._send_alert(signal):
                    result["alerts_sent"] += 1
                    self.alerts_sent += 1
            
            self.daily_analyses += 1

            logger.info(
                f"‚úÖ {instrument} analysis complete | "
                f"{result['signals_count']} signals | "
                f"{result['alerts_sent']} alerts sent"
            )
            result["success"] = True
            return result

        except Exception as e:
            logger.error(f"‚ùå Exception: {str(e)}", exc_info=DEBUG_MODE)
            result["errors"].append(str(e))
            return result

    def _generate_signals(
        self, instrument: str, analysis: Dict, nse_data: Dict, df_5m: pd.DataFrame = None
    ) -> List[Dict]:
        """
        Generate trading signals using SignalPipeline.
        """
        signals: List[Dict] = []
        
        # 1. Fetch Option Data (Inputs for Pipeline)
        option_metrics = {}
        try:
            logger.info(f"üß¨ Fetching Option Chain for {instrument}...")
            oc_data = self.option_fetcher.fetch_option_chain(instrument)
            if oc_data:
                pcr_value = self.option_analyzer.calculate_pcr(oc_data)
                spot_price = float(nse_data.get("price", 0) or 0)
                iv_value = self.option_analyzer.calculate_atm_iv(oc_data, spot_price)
                oi_change_data = self.option_analyzer.analyze_oi_change(oc_data, spot_price)
                max_pain = self.option_analyzer.calculate_max_pain(oc_data)
                
                if pcr_value is not None: option_metrics["pcr"] = pcr_value
                if iv_value is not None: option_metrics["iv"] = iv_value
                if oi_change_data: option_metrics["oi_change"] = oi_change_data
                if max_pain is not None: option_metrics["max_pain"] = max_pain
                    
                logger.info(f"üìä Option Metrics: PCR={pcr_value}, IV={iv_value}%, MaxPain={max_pain}")
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Failed to calculate option metrics: {e}")

        # 2. Gather Raw Signals from Technical Analysis
        raw_signals = []
        
        # Extract signals from analysis object
        breakout = analysis.get("breakout_signal")
        retest = analysis.get("retest_signal")
        inside_bar = analysis.get("inside_bar_signal")
        pin_bar = analysis.get("pin_bar_signal")
        engulfing = analysis.get("engulfing_signal")
        
        for potential_signal in [breakout, retest, inside_bar, pin_bar, engulfing]:
            if not potential_signal:
                continue
                
            sig = {
                "instrument": instrument,
                "signal_type": potential_signal.signal_type.value,
                "entry_price": potential_signal.entry_price,
                "stop_loss": potential_signal.stop_loss,
                "take_profit": potential_signal.take_profit,
                "confidence": potential_signal.confidence, 
                "volume_confirmed": getattr(potential_signal, "volume_confirmed", False),
                "momentum_confirmed": getattr(potential_signal, "momentum_confirmed", True),
                "risk_reward_ratio": getattr(potential_signal, "risk_reward_ratio", 0),
                "description": potential_signal.description,
                "price_level": potential_signal.price_level,
                "timestamp": potential_signal.timestamp.isoformat(),
            }
            # Add simple technical gate here if needed, but Pipeline handles scoring
            if sig["confidence"] >= MIN_SIGNAL_CONFIDENCE:
                 raw_signals.append(sig)

        # 3. Market Status for Pipeline
        market_status = {}
        # Choppy check
        analyzer = TechnicalAnalyzer(instrument)
        choppy_df = df_5m if df_5m is not None else self.fetcher.get_historical_data(instrument, "5m", 100)
        is_choppy, choppy_reason = analyzer._is_choppy_session(choppy_df)
        market_status["is_choppy"] = is_choppy
        market_status["choppy_reason"] = choppy_reason

        # 4. Delegate to Pipeline
        try:
            processed_signals = self.signal_pipeline.process_signals(
                raw_signals=raw_signals,
                instrument=instrument,
                technical_context=analysis,
                option_metrics=option_metrics,
                recent_alerts=self.recent_alerts,
                market_status=market_status
            )
            return processed_signals
            
        except Exception as e:
            logger.error(f"‚ùå Signal Pipeline Error: {e}", exc_info=True)
            return []

    def _get_ai_analysis(self, signal: Dict) -> Dict:
        """Deprecated: AI is now called inside SignalPipeline."""
        return signal.get("ai_analysis", {})

    def _check_alert_limits(self, signal: Dict) -> Tuple[bool, str]:
        """
        Check if sending this alert would exceed daily limits.
        Uses AlertKey structure from recent_alerts.
        
        Returns:
            (can_send, rejection_reason)
        """
        try:
            from config.settings import (
                MAX_ALERTS_PER_DAY,
                MAX_ALERTS_PER_TYPE,
                MAX_ALERTS_PER_INSTRUMENT,
            )
            
            # Check total alerts from list size
            total_alerts = len(self.recent_alerts)
            if total_alerts >= MAX_ALERTS_PER_DAY:
                return False, f"Daily limit reached ({total_alerts}/{MAX_ALERTS_PER_DAY})"

            instrument = signal.get("instrument", "")
            signal_type = signal.get("signal_type", "")
            
            # Count per type
            recent_of_type = sum(
                1 for key in self.recent_alerts.keys()
                if hasattr(key, 'signal_type') and signal_type in key.signal_type
            )
            
            if recent_of_type >= MAX_ALERTS_PER_TYPE:
                return False, f"{signal_type} limit reached ({recent_of_type}/{MAX_ALERTS_PER_TYPE})"
            
            # Count per instrument
            recent_for_instrument = sum(
                1 for key in self.recent_alerts.keys()
                if hasattr(key, 'instrument') and key.instrument == instrument
            )
            
            if recent_for_instrument >= MAX_ALERTS_PER_INSTRUMENT:
                return False, f"{instrument} limit reached ({recent_for_instrument}/{MAX_ALERTS_PER_INSTRUMENT})"
            
            return True, ""
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Alert limit check failed, entering SAFE mode: {e}")
            # Fail Closed to prevent spam in degraded state
            return False, "ALERT_LIMIT_CHECK_FAILED"

    def _should_suppress_retest(self, signal: Dict) -> Tuple[bool, str]:
        """
        Specialized filter for RETEST alerts to reduce noise.
        
        Rules:
        1. Proximity: Block if within 0.2% of recent alert at same level (60m window).
        2. Conflict: Block if opposing retest at same level within 30m.
        """
        try:
            stype = signal.get("signal_type", "")
            if "RETEST" not in stype and "BOUNCE" not in stype:
                return False, ""  # Not a retest, don't suppress
            
            instrument = signal.get("instrument", "")
            price = float(signal.get("price_level", 0))
            current_direction = "LONG" if "BULLISH" in stype or "SUPPORT" in stype else "SHORT"
            
            ist = pytz.timezone("Asia/Kolkata")
            now = datetime.now(ist)
            
            for key, timestamp in self.recent_alerts.items():
                # Ensure key is AlertKey
                if not hasattr(key, "instrument"): continue
                
                if key.instrument != instrument:
                    continue
                
                # Retrieve approximate price from ticks
                # Assume 0.05 tick size (standard for Nifty indices)
                prev_price = key.level_ticks * 0.05
                
                # Check 1: Proximity (Same Level)
                # If within 0.2% price difference
                if abs(prev_price - price) < (price * 0.002):
                    prev_direction = "LONG" if "BULLISH" in key.signal_type or "SUPPORT" in key.signal_type else "SHORT"
                    time_diff = (now - timestamp).total_seconds() / 60.0
                    
                    # A. Same Direction (Duplicate) -> 60 min cooldown for Retests
                    if current_direction == prev_direction:
                        if time_diff < 60:
                            return True, f"Recent similar retest {time_diff:.1f}m ago"
                    
                    # B. Opposing Direction (Conflict) -> 30 min suppression
                    else:
                        if time_diff < 30:
                            return True, f"Conflicting retest ({prev_direction}) {time_diff:.1f}m ago"
                            
            return False, ""
            
        except Exception as e:
            logger.error(f"‚ùå Retest suppression check failed: {e}")
            return False, ""

    def _send_alert(self, signal: Dict) -> bool:
        """Send Telegram alert with structured duplicate prevention."""
        try:
            
            stype = signal.get("signal_type", "")
            instrument = signal.get("instrument", "")
            price_level = signal.get("price_level", 0)
            
            # Limit Check
            can_send, reject_reason = self._check_alert_limits(signal)
            if not can_send:
                logger.warning(f"‚è≠Ô∏è Alert limit: {reject_reason}")
                return False
            
            # Retest Filter
            if "RETEST" in stype or "BOUNCE" in stype:
                should_suppress, reason = self._should_suppress_retest(signal)
                if should_suppress:
                    logger.info(f"‚è≠Ô∏è Suppressing RETEST alert: {reason}")
                    return False
            
            # Structured Duplicate Check using AlertKey
            new_key = build_alert_key(signal)
            ist = pytz.timezone("Asia/Kolkata")
            now = datetime.now(ist)
            
            # 1. Exact/Zone Duplicate Check
            # Check if we have an alert with same key (same inst, type, level, date)
            # or very close level
            for key, timestamp in self.recent_alerts.items():
                if not hasattr(key, "instrument"): continue # skip legacy string keys if any
                
                if key.instrument == new_key.instrument and key.signal_type == new_key.signal_type:
                    # Check level proximity (within 3 ticks = 0.15 pts roughly)
                    # Actually let's use the explicit logic from before (0.1%)
                    # Convert ticks back to price for comparison
                    prev_price = key.level_ticks * 0.05
                    curr_price = new_key.level_ticks * 0.05
                    
                    if abs(prev_price - curr_price) < (curr_price * 0.001):
                        time_diff = (now - timestamp).total_seconds() / 60.0
                        if time_diff < 30: # 30 min cooldown
                            logger.info(f"‚è≠Ô∏è Duplicate Alert {time_diff:.1f}m ago | {key}")
                            return False
            
            # 2. Directional Conflict Check
            # Prevent LONG signal if SHORT sent recently at same level (and vice versa)
            current_direction = "LONG" if "BULLISH" in stype or "SUPPORT" in stype else "SHORT"
            
            for key, timestamp in self.recent_alerts.items():
                if not hasattr(key, "instrument"): continue

                if key.instrument == instrument:
                    prev_price = key.level_ticks * 0.05
                    # Check if nearby level (within 0.2%)
                    if abs(prev_price - price_level) < (price_level * 0.002):
                        prev_direction = "LONG" if "BULLISH" in key.signal_type or "SUPPORT" in key.signal_type else "SHORT"
                        
                        # If directions oppose and within 15 mins
                        if current_direction != prev_direction:
                            conflict_diff = (now - timestamp).total_seconds() / 60.0
                            if conflict_diff < 15:
                                logger.info(
                                    f"‚è≠Ô∏è Skipping conflicting signal | {current_direction} vs recent {prev_direction} | "
                                    f"Diff: {conflict_diff:.1f} mins"
                                )
                                return False
            
            # ====================
            # Send Alert
            # ====================
            if "BREAKOUT" in stype or "BREAKDOWN" in stype:
                success = self.telegram_bot.send_breakout_alert(signal)
            elif "RETEST" in stype or "SUPPORT_BOUNCE" in stype or "RESISTANCE_BOUNCE" in stype:
                success = self.telegram_bot.send_retest_alert(signal)
            elif "INSIDE_BAR" in stype:
                success = self.telegram_bot.send_inside_bar_alert(signal)
            elif "PIN_BAR" in stype or "ENGULFING" in stype:
                # Use retest alert format for pin bars and engulfing (similar structure)
                success = self.telegram_bot.send_retest_alert(signal)
            else:
                msg = (
                    f"{stype}\nEntry: {signal.get('entry_price')}\n"
                    f"{signal.get('description', '')}"
                )
                success = self.telegram_bot.send_message(msg)

            if success:
                logger.info("   ‚úÖ Telegram alert sent")
                self.persistence.increment_stat("alerts_sent")
                
                # Record trade for performance tracking
                trade_id = self.trade_tracker.record_alert(signal)
                if trade_id:
                    logger.info(f"   üìù Trade tracked: {trade_id}")
                
                # Record this alert to prevent duplicates
                self.recent_alerts[new_key] = now
                
                # Record level for all-day blocking
                level_key = f"{instrument}_{stype}_level_{round(price_level / 25) * 25:.0f}"
                self.daily_level_memory.add(level_key)
                
                # Cleanup old entries (older than 6 hours)
                cutoff_time = now - timedelta(hours=6)
                self.recent_alerts = {
                    k: v for k, v in self.recent_alerts.items() 
                    if v > cutoff_time
                }
                
                # Save to Firestore for persistence across executions
                self.persistence.save_recent_alerts(self.recent_alerts)
            else:
                logger.warning("   ‚ö†Ô∏è  Telegram alert failed")
            return success

        except Exception as e:
            logger.error(f"‚ùå Alert sending failed: {str(e)}")
            return False

    # =====================================================================
    # DAILY EVENT TRACKING & SUMMARY
    # =====================================================================

    def _track_daily_event(self, signal: Dict):
        """Track signal event for daily summary."""
        signal_type = signal.get("signal_type", "")
        
        # Local tracking - categorize all signal types
        if signal_type == "BULLISH_BREAKOUT":
            self.daily_breakouts.append(signal)
            self.persistence.add_event("breakouts", signal)
        elif signal_type == "BEARISH_BREAKOUT" or "BREAKDOWN" in signal_type:
            self.daily_breakdowns.append(signal)
            self.persistence.add_event("breakdowns", signal)
        elif any(x in signal_type for x in ["RETEST", "BOUNCE", "PIN_BAR", "ENGULFING", "INSIDE_BAR"]):
            self.daily_retests.append(signal)
            self.persistence.add_event("retests", signal)
        # Could add reversal detection logic here if needed

    def generate_daily_summary(self) -> Dict:
        """Generate comprehensive end-of-day market summary."""
        try:
            logger.info("üìä Generating end-of-day market summary")
            
            # Fetch persisted stats
            stored_stats = self.persistence.get_daily_stats()
            events = stored_stats.get("events", {})
            
            instruments = [
                k for k, v in INSTRUMENTS.items() if v.get("active", False)
            ]
            
            summary = {
                "timestamp": datetime.now().isoformat(),
                "instruments": {},
                "statistics": {
                    "data_fetches": stored_stats.get("data_fetches", 0),
                    "analyses_run": stored_stats.get("analyses_run", 0),
                    "alerts_sent": stored_stats.get("alerts_sent", 0),
                    "breakouts": len(events.get("breakouts", [])),
                    "breakdowns": len(events.get("breakdowns", [])),
                    "retests": len(events.get("retests", [])),
                    "reversals": len(events.get("reversals", [])),
                },
                "events": events
            }
            
            # Get latest data for each instrument
            for instrument in instruments:
                try:
                    # Fetch latest daily candle
                    df_day = self.fetcher.fetch_historical_data(
                        instrument, period="2d", interval="1d"
                    )
                    
                    if df_day is not None and not df_day.empty:
                        df_day = self.fetcher.preprocess_ohlcv(df_day)
                        latest = df_day.iloc[-1]
                        
                        # Get PDH/PDL for context
                        pdh_pdl = self.fetcher.get_previous_day_stats(instrument)
                        
                        # Get intraday data for trend analysis
                        df_5m = self.fetcher.fetch_historical_data(
                            instrument, period="1d", interval="5m"
                        )
                        
                        # Calculate short-term trend (last hour of trading)
                        short_term_trend = "NEUTRAL"
                        long_term_trend = "NEUTRAL"
                        
                        if df_5m is not None and not df_5m.empty and len(df_5m) >= 12:
                            df_5m = self.fetcher.preprocess_ohlcv(df_5m)
                            last_12 = df_5m.tail(12)  # Last hour
                            
                            if last_12.iloc[-1]["close"] > last_12.iloc[0]["close"] * 1.001:
                                short_term_trend = "BULLISH"
                            elif last_12.iloc[-1]["close"] < last_12.iloc[0]["close"] * 0.999:
                                short_term_trend = "BEARISH"
                        
                        # Long-term trend from daily close vs open
                        if latest["close"] > latest["open"] * 1.005:
                            long_term_trend = "BULLISH"
                        elif latest["close"] < latest["open"] * 0.995:
                            long_term_trend = "BEARISH"
                        
                        change_pct = ((latest["close"] - latest["open"]) / latest["open"]) * 100
                        
                        summary["instruments"][instrument] = {
                            "open": latest["open"],
                            "high": latest["high"],
                            "low": latest["low"],
                            "close": latest["close"],
                            "change_pct": change_pct,
                            "pdh": pdh_pdl.get("pdh") if pdh_pdl else None,
                            "pdl": pdh_pdl.get("pdl") if pdh_pdl else None,
                            "short_term_trend": short_term_trend,
                            "long_term_trend": long_term_trend,
                        }

                        # NEW: Option Chain Stats for EOD
                        try:
                            oc_data = self.option_fetcher.fetch_option_chain(instrument)
                            if oc_data:
                                pcr = self.option_analyzer.calculate_pcr(oc_data)
                                max_pain = self.option_analyzer.calculate_max_pain(oc_data)
                                spot = latest["close"]
                                oi_data = self.option_analyzer.analyze_oi_change(oc_data, spot)
                                
                                summary["instruments"][instrument]["option_chain"] = {
                                    "pcr": pcr,
                                    "max_pain": max_pain,
                                    "sentiment": oi_data.get("sentiment", "NEUTRAL"),
                                }
                        except Exception as e:
                            logger.error(f"‚ö†Ô∏è Failed to add option stats to summary for {instrument}: {e}")
                        
                except Exception as e:
                    logger.error(f"Error getting summary for {instrument}: {str(e)}")
            
            # Get AI forecast
            summary["ai_forecast"] = self._get_ai_market_forecast(summary)
            
            # Get performance stats
            summary["performance"] = self.trade_tracker.get_stats(days=1)
            
            return summary
            
        except Exception as e:
            logger.error(f"Failed to generate daily summary: {str(e)}")
            return {}

    def _get_ai_market_forecast(self, summary: Dict) -> Dict:
        """Get AI-powered market forecast for next trading day."""
        try:
            # Build context for AI
            context_parts = []
            
            for inst, data in summary.get("instruments", {}).items():
                context_parts.append(
                    f"{inst}: Close {data['close']:.2f} ({data['change_pct']:+.2f}%), "
                    f"Trend: {data['short_term_trend']}/{data['long_term_trend']}"
                )
            
            stats = summary.get("statistics", {})
            context_parts.append(
                f"Today's activity: {stats.get('breakouts', 0)} breakouts, "
                f"{stats.get('breakdowns', 0)} breakdowns, {stats.get('retests', 0)} retests"
            )
            
            context = ". ".join(context_parts)
            
            forecast = self.ai_analyzer.forecast_market_outlook(context)
            return forecast
            
        except Exception as e:
            logger.warning(f"AI forecast failed: {str(e)}")
            return {"outlook": "NEUTRAL", "confidence": 50, "summary": "Forecast unavailable"}

    # =====================================================================
    # UTILITY
    # =====================================================================

    def _print_analysis_summary(self, results: Dict):
        logger.info("\n" + "=" * 70)
        logger.info("üìä ANALYSIS SUMMARY")
        logger.info("=" * 70)
        logger.info(f"Timestamp: {results['timestamp']}")
        logger.info(
            f"Instruments Analyzed: {results['instruments_analyzed']}"
        )
        logger.info(
            f"Total Signals Generated: {results['signals_generated']}"
        )
        logger.info(f"Alerts Sent: {results['alerts_sent']}")
        logger.info(f"Errors: {results['errors']}")
        logger.info("=" * 70 + "\n")

    def is_market_hours(self) -> bool:
        """Check if current time is within market hours (Mon-Fri, IST)."""
        tz = pytz.timezone(TIME_ZONE)
        now = datetime.now(tz)

        market_open = datetime.strptime(
            ANALYSIS_START_TIME, "%H:%M"
        ).time()
        market_close = datetime.strptime(
            MARKET_CLOSE_TIME, "%H:%M"
        ).time()

        if now.weekday() > 4:
            logger.debug("üìÖ Market closed (weekend)")
            return False

        if market_open <= now.time() <= market_close:
            return True

        logger.debug(f"‚è∞ Outside market hours ({now.time()})")
        return False


    def check_scheduled_messages(self):
        """
        Check and send scheduled messages based on time windows.
        Uses persistence to ensuring messages are sent exactly once per day.
        """
        tz = pytz.timezone(TIME_ZONE)
        now = datetime.now(tz).time()
        
        # Get today's stats to check what has been sent
        daily_stats = self.persistence.get_daily_stats()
        
        # 1. Startup Message + PDH/PDL (09:15 onwards)
        # We allow a window until 09:30 to catch up if we missed 09:15
        if time(9, 15) <= now < time(9, 30):
            if not daily_stats.get("startup_msg_sent"):
                logger.info("‚è∞ Triggering Startup Message")
                
                pdh_pdl_stats = {}
                for instrument in INSTRUMENTS:
                    if INSTRUMENTS[instrument]["active"]:
                        stats = self.fetcher.get_previous_day_stats(instrument)
                        if stats:
                            pdh_pdl_stats[instrument] = stats
                
                if self.telegram_bot.send_startup_message(pdh_pdl_stats):
                    self.persistence.increment_stat("startup_msg_sent")
                else:
                    logger.warning("‚ö†Ô∏è Startup message failed to send")

        # 2. Market Context (09:30 onwards)
        elif time(9, 30) <= now < time(10, 0): # Window until 10:00 AM
            if not daily_stats.get("market_context_msg_sent"):
                logger.info("‚è∞ Triggering Market Context Update")
                
                context_data = {}
                pdh_pdl_stats = {}
                sr_levels = {}
                option_stats = {}
                
                # We need at least SOME data to send the message
                has_data = False

                for instrument in INSTRUMENTS:
                    if INSTRUMENTS[instrument]["active"]:
                        # Opening range stats
                        stats = self.fetcher.get_opening_range_stats(instrument)
                        if stats:
                            context_data[instrument] = stats
                            has_data = True
                        
                        # PDH/PDL
                        p_stats = self.fetcher.get_previous_day_stats(instrument)
                        if p_stats:
                            pdh_pdl_stats[instrument] = p_stats
                        
                        # NEW: S/R levels
                        try:
                            df_5m = self.fetcher.fetch_historical_data(instrument, period="5d", interval="5m")
                            if df_5m is not None and not df_5m.empty:
                                df_5m = self.fetcher.preprocess_ohlcv(df_5m)
                                analyzer = TechnicalAnalyzer(instrument)
                                sr = analyzer.calculate_support_resistance(df_5m)
                                sr_levels[instrument] = sr
                                has_data = True
                        except Exception as e:
                            logger.error(f"‚ùå S/R calculation failed for {instrument}: {e}")

                        # NEW: Option Chain Analysis
                        try:
                            oc_data = self.option_fetcher.fetch_option_chain(instrument)
                            if oc_data:
                                pcr = self.option_analyzer.calculate_pcr(oc_data)
                                max_pain = self.option_analyzer.calculate_max_pain(oc_data)
                                key_strikes = self.option_analyzer.get_key_strikes(oc_data)
                                
                                option_stats[instrument] = {
                                    "pcr": pcr,
                                    "max_pain": max_pain,
                                    "key_strikes": key_strikes
                                }
                                has_data = True
                        except Exception as e:
                            logger.error(f"‚ùå Option stats failed for {instrument}: {e}")
                
                if has_data:
                    if self.telegram_bot.send_market_context(context_data, pdh_pdl_stats, sr_levels, option_stats):
                        self.persistence.increment_stat("market_context_msg_sent")
                else:
                    logger.error("‚ùå No market data available for 9:30 update")
                    # Send partial/error notification if it's getting late (e.g. 09:40)
                    if now >= time(9, 40) and not daily_stats.get("market_context_error_sent"):
                        self.telegram_bot.send_error_notification(
                            "Failed to fetch market data for 9:30 update. Retrying..."
                        )
                        self.persistence.increment_stat("market_context_error_sent")

        # 3. End-of-Day Summary
        elif time(15, 31) <= now <= time(18, 0): # Wider window for EOD
             if not daily_stats.get("daily_summary_msg_sent"):
                logger.info("‚è∞ Triggering End-of-Day Summary")
                
                summary = self.generate_daily_summary()
                if summary:
                    if self.telegram_bot.send_daily_summary(summary):
                        self.persistence.increment_stat("daily_summary_msg_sent")

    def get_statistics(self) -> Dict:
        """Return simple statistics."""
        return {
            "signals_generated": len(self.signals_generated),
            "alerts_sent": self.alerts_sent,
            "ai_usage": self.ai_analyzer.get_usage_stats(),
            "bot_stats": self.telegram_bot.get_stats(),
        }




# ======================================================================
# FILE: app/bootstrap.py
# ======================================================================

"""
Bootstrap Module
Handles the creation and initialization of the Trading Agent.
Implements the AppFactory pattern.
"""
import logging
from app.agent import NiftyTradingAgent
from config.logging_config import setup_logging

logger = setup_logging(__name__)

def create_agent() -> NiftyTradingAgent:
    """
    Factory function to create and configure the trading agent.
    """
    try:
        logger.info("üîß Bootstrapping NiftyTradingAgent...")
        agent = NiftyTradingAgent()
        return agent
    except Exception as e:
        logger.critical(f"‚ùå Failed to create agent: {e}", exc_info=True)
        raise


# ======================================================================
# FILE: app/selfcheck.py
# ======================================================================

"""
Self-Check Module
Verifies environment, configuration, and API connectivity.
"""
import logging
import os
import sys

# Ensure project root is in sys.path to allow imports from config/ and app/
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

from config.settings import validate_config, LOG_DIR, CACHE_DIR
from config.logging_config import setup_logging
from app.bootstrap import create_agent

logger = setup_logging(__name__)

def check_directories():
    """Verify write access to critical directories."""
    dirs = [LOG_DIR, CACHE_DIR]
    success = True
    for d in dirs:
        try:
            os.makedirs(d, exist_ok=True)
            test_file = os.path.join(d, "test_write.tmp")
            with open(test_file, "w") as f:
                f.write("test")
            os.remove(test_file)
            logger.info(f"‚úÖ Write access confirmed: {d}")
        except Exception as e:
            logger.error(f"‚ùå Write access FAILED: {d} | {e}")
            success = False
    return success

def run_self_check():
    """Run full system check."""
    logger.info("üîç Starting System Self-Check...")
    
    # 1. Config Validation
    errors = validate_config()
    if errors:
        for e in errors:
            logger.error(e)
        logger.error("‚ùå Configuration Validation FAILED")
        return False
    logger.info("‚úÖ Configuration Validated")
    
    # 2. Directory Access
    if not check_directories():
        return False

    # 3. Agent Initialization & Connectivity
    try:
        agent = create_agent()
        
        # Grid Connectivity
        groq_ok = agent.ai_analyzer.test_connection()
        if groq_ok:
            logger.info("‚úÖ Groq API Connected")
        else:
            logger.error("‚ùå Groq API Connection FAILED")
            
        tg_ok = agent.telegram_bot.test_connection()
        if tg_ok:
            logger.info("‚úÖ Telegram Bot Connected")
        else:
            logger.error("‚ùå Telegram Bot Connection FAILED")
            
        if groq_ok and tg_ok:
            logger.info("‚úÖ All Systems Operational")
            return True
        else:
            return False
            
    except Exception as e:
        logger.critical(f"‚ùå Agent Bootstrap Failed: {e}", exc_info=True)
        return False

if __name__ == "__main__":
    success = run_self_check()
    exit(0 if success else 1)


# ======================================================================
# FILE: config/__init__.py
# ======================================================================



# ======================================================================
# FILE: config/settings.py
# ======================================================================

"""
Configuration & Settings Module
All API keys, thresholds, and constants in one place for easy debugging
"""

import os
from dotenv import load_dotenv
from enum import Enum

# Load environment variables
load_dotenv()

# ============================================================================
# API KEYS & CREDENTIALS
# ============================================================================

GROQ_API_KEY = os.getenv("GROQ_API_KEY", "YOUR_GROQ_KEY_HERE")
TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN", "YOUR_BOT_TOKEN_HERE")
TELEGRAM_CHAT_ID = os.getenv("TELEGRAM_CHAT_ID", "YOUR_CHAT_ID_HERE")
TELEGRAM_CHANNEL_ID = os.getenv("TELEGRAM_CHANNEL_ID") # Optional Channel ID

# ============================================================================
# FYERS CONFIGURATION
# ============================================================================
FYERS_CLIENT_ID = os.getenv("FYERS_CLIENT_ID", "DURQKS8D17-100") # Default from codebase
FYERS_ACCESS_TOKEN = os.getenv("FYERS_ACCESS_TOKEN")


# ============================================================================
# MARKET PARAMETERS
# ============================================================================


class Instrument(Enum):
    """Trading instruments"""

    NIFTY50 = "NIFTY 50"
    BANKNIFTY = "BANKNIFTY"
    FINNIFTY = "FINNIFTY"


INSTRUMENTS = {
    "NIFTY": {
        "symbol": "NIFTY 50",
        "display_name": "Nifty 50",
        "tick_size": 0.05,
        "lot_size": 75,
        "active": True,
    },
    "BANKNIFTY": {
        "symbol": "BANKNIFTY",
        "display_name": "Bank Nifty",
        "tick_size": 0.05,
        "lot_size": 15,
        "active": False,
    },
    "FINNIFTY": {
        "symbol": "FINNIFTY",
        "display_name": "Fin Nifty",
        "tick_size": 0.05,
        "lot_size": 40,
        "active": False,  # Enable when ready
    },
}

# Trading hours (IST)
MARKET_OPEN_TIME = "09:15"  # Market opens
ANALYSIS_START_TIME = os.getenv("ANALYSIS_START_TIME", "09:05")  # Analysis trigger
MARKET_CLOSE_TIME = "15:30"  # Market closes

# Timeframes for analysis
TIMEFRAMES = {
    "5MIN": "5m",
    "15MIN": "15m",
    "1HOUR": "1h",
    "1DAY": "d",
}

PRIMARY_TIMEFRAME = "5MIN"  # Main breakout detection
CONFIRMATION_TIMEFRAME = "15MIN"  # Trend confirmation

# ============================================================================
# TECHNICAL ANALYSIS THRESHOLDS
# ============================================================================

# Volume Configuration
MIN_VOLUME_RATIO = float(os.getenv("MIN_VOLUME_RATIO", 1.5))  # 1.5x avg volume
VOLUME_PERIOD = 20  # candles lookback

# Breakout Configuration
BREAKOUT_CONFIRMATION_CANDLES = 2
FALSE_BREAKOUT_RETRACEMENT = float(os.getenv("MAX_FALSE_BREAKOUT_PERCENT", 0.5))
RETEST_ZONE_PERCENT = float(os.getenv("RETEST_ZONE_PERCENT", 0.3))

# Support/Resistance Configuration
SR_CLUSTER_TOLERANCE = 0.1  # 0.1% difference = same cluster
MIN_SR_TOUCHES = 2
LOOKBACK_BARS = 2000  # Increased to use full 5-day history (was 100)

# Momentum Configuration
MIN_RSI_BULLISH = int(os.getenv("MIN_MOMENTUM_RSI", 60))
MAX_RSI_BEARISH = int(os.getenv("MAX_MOMENTUM_RSI", 40))
RSI_PERIOD = 14

# ATR (for dynamic SL/TP)
ATR_PERIOD = 14
ATR_SL_MULTIPLIER = 1.5
ATR_TP_MULTIPLIER = 2.5

# Moving Averages
EMA_SHORT = 9
EMA_LONG = 21
SMA_VOLUME = 20

# MACD Configuration
MACD_FAST = 12
MACD_SLOW = 26
MACD_SIGNAL = 9

# Bollinger Bands
BB_PERIOD = 20
BB_STD_DEV = 2

# Stochastic Configuration
STOCH_PERIOD = 14
STOCH_SMOOTH_K = 3
STOCH_SMOOTH_D = 3

# ============================================================================
# RISK MANAGEMENT
# ============================================================================

MIN_RISK_REWARD_RATIO = 1.5
MAX_DAILY_TRADES = 999  # Effectively unlimited (rely on robust filtering)
MIN_SIGNAL_CONFIDENCE = int(os.getenv("MIN_SIGNAL_CONFIDENCE", 65))

DEFAULT_POSITION_SIZE = 1
MAX_POSITION_SIZE = 3

# ============================================================================
# AI & GROQ CONFIGURATION
# ============================================================================

GROQ_MODEL = os.getenv("GROQ_MODEL", "mixtral-8x7b-32768")
GROQ_MAX_TOKENS = int(os.getenv("GROQ_MAX_TOKENS", 400))
GROQ_TEMPERATURE = float(os.getenv("GROQ_TEMPERATURE", 0.3))

# Approximate token budget (for your own tracking; not enforced by API)
GROQ_REQUESTS_PER_DAY = 30000
GROQ_REQUESTS_PER_MINUTE = 300

# ============================================================================
# TELEGRAM CONFIGURATION
# ============================================================================

TELEGRAM_MAX_MESSAGE_LENGTH = 4000
INCLUDE_CHARTS_IN_ALERT = (
    os.getenv("INCLUDE_CHARTS_IN_ALERT", "true").lower() == "true"
)
INCLUDE_AI_SUMMARY_IN_ALERT = (
    os.getenv("INCLUDE_AI_SUMMARY_IN_ALERT", "true").lower() == "true"
)

ALERT_TYPES = {
    "BREAKOUT": "üöÄ BREAKOUT",
    "BREAKOUT_CONFIRMED": "‚úÖ BREAKOUT CONFIRMED",
    "FALSE_BREAKOUT": "‚ö†Ô∏è FALSE BREAKOUT",
    "RETEST": "üéØ RETEST SETUP",
    "INSIDE_BAR": "üìä INSIDE BAR SETUP",
    "BREAKDOWN": "üìâ BREAKDOWN",
    "SUPPORT_HIT": "üõ°Ô∏è SUPPORT HIT",
    "RESISTANCE_HIT": "üî¥ RESISTANCE HIT",
}

# ============================================================================
# SCHEDULING CONFIGURATION
# ============================================================================

TIME_ZONE = os.getenv("TIME_ZONE", "Asia/Kolkata")
SCHEDULE_CRON = "5 9 * * MON-FRI"
INTRADAY_MONITORING_INTERVAL = 5  # minutes

# ============================================================================
# ============================================================================
# CLOUD DEPLOYMENT
# ============================================================================

GOOGLE_CLOUD_PROJECT = os.getenv("GOOGLE_CLOUD_PROJECT", "")
CLOUD_FUNCTION_REGION = os.getenv("CLOUD_FUNCTION_REGION", "us-central1")
FIRESTORE_DATABASE = os.getenv("FIRESTORE_DATABASE", "")

# Auto-detect GCP Environment (Cloud Run / Cloud Functions)
IS_GCP = os.getenv("K_SERVICE") is not None or os.getenv("FUNCTION_NAME") is not None

# Override DEPLOYMENT_MODE if in GCP
if IS_GCP:
    DEPLOYMENT_MODE = "GCP"
else:
    DEPLOYMENT_MODE = os.getenv("DEPLOYMENT_MODE", "LOCAL")

ENABLE_CLOUD_LOGGING = DEPLOYMENT_MODE != "LOCAL"

# ============================================================================
# DATA STORAGE & CACHING
# ============================================================================

if DEPLOYMENT_MODE == "GCP" or IS_GCP:
    # Google Cloud Functions only allows writing to /tmp
    CACHE_DIR = "/tmp/cache"
    LOG_DIR = "/tmp/logs"
else:
    CACHE_DIR = "./cache"
    LOG_DIR = "./logs"

CACHE_DATA_TTL = 3600  # seconds

LOG_LEVEL = os.getenv("LOGLEVEL", "INFO")
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
LOG_DATE_FORMAT = "%Y-%m-%d %H:%M:%S"

# ============================================================================
# DEBUG & DEVELOPMENT
# ============================================================================

DEBUG_MODE = os.getenv("DEBUG_MODE", "False") == "True"

# ============================================================================
# RISK MANAGEMENT
# ============================================================================

# Daily Alert Limits
MAX_ALERTS_PER_DAY = int(os.getenv("MAX_ALERTS_PER_DAY", "999"))  # Effectively unlimited (rely on other filters)
MAX_ALERTS_PER_TYPE = int(os.getenv("MAX_ALERTS_PER_TYPE", "10"))  # Max per signal type
MAX_ALERTS_PER_INSTRUMENT = int(os.getenv("MAX_ALERTS_PER_INSTRUMENT", "15"))  # Max per instrument

# Choppy Market Detection
MIN_ATR_PERCENT = float(os.getenv("MIN_ATR_PERCENT", "0.08"))  # Min volatility for trading (ATR/price %)
MAX_VWAP_CROSSES = int(os.getenv("MAX_VWAP_CROSSES", "4"))  # Max crosses in 10 bars = choppy

# Correlation Limits
MAX_SAME_DIRECTION_ALERTS = int(os.getenv("MAX_SAME_DIRECTION_ALERTS", "3"))  # Max similar directional trades in 15 mins

SEND_TEST_ALERTS = os.getenv("SEND_TEST_ALERTS", "False").lower() == "true"
DRY_RUN = os.getenv("DRY_RUN", "False").lower() == "true"
VERBOSE = os.getenv("VERBOSE", "False").lower() == "true"

# ============================================================================
# PHASE 4: MANIPULATION DEFENSE
# ============================================================================

# Flash Crash Protection
MAX_1MIN_MOVE_PCT = float(os.getenv("MAX_1MIN_MOVE_PCT", 0.4))  # 0.4% move in 1 min = Freeze
CIRCUIT_BREAKER_PAUSE_MINS = 15

# Expiry Day Gamma Guard ( Thursdays )
EXPIRY_STOP_TIME = "14:00"  # Stop taking fresh entries after this time on Thursdays
EXPIRY_RISK_ATR_MULTIPLIER = 1.0  # Tighter stops on Expiry

# VIX Volatility Guard
VIX_PANIC_LEVEL = 24.0
VIX_LOW_LEVEL = 10.0


def validate_config():
    """Validate critical configuration"""
    errors = []

    if not GROQ_API_KEY or GROQ_API_KEY == "YOUR_GROQ_KEY_HERE":
        errors.append("‚ùå GROQ_API_KEY not set in .env")

    if (
        not TELEGRAM_BOT_TOKEN
        or TELEGRAM_BOT_TOKEN == "YOUR_BOT_TOKEN_HERE"
    ):
        errors.append("‚ùå TELEGRAM_BOT_TOKEN not set in .env")

    if not TELEGRAM_CHAT_ID or TELEGRAM_CHAT_ID == "YOUR_CHAT_ID_HERE":
        errors.append("‚ùå TELEGRAM_CHAT_ID not set in .env")

    return errors


os.makedirs(CACHE_DIR, exist_ok=True)
os.makedirs(LOG_DIR, exist_ok=True)

if __name__ == "__main__":
    errs = validate_config()
    if errs:
        print("\n‚ö†Ô∏è  Configuration Issues:\n")
        for e in errs:
            print(f"   {e}")
        print("\nüìù Please create .env file with required keys")
    else:
        print("‚úÖ Configuration validated successfully!")


# ======================================================================
# FILE: config/logging_config.py
# ======================================================================

"""
Centralized Logging Configuration
"""
import logging
import os
import sys
from config.settings import LOG_DIR, DEBUG_MODE

def setup_logging(name: str = __name__) -> logging.Logger:
    """
    Configure and return a logger with consistent formatting.
    """
    log_format = "%(asctime)s | %(name)s | %(levelname)-8s | %(message)s"
    log_level = logging.DEBUG if DEBUG_MODE else logging.INFO
    
    # Ensure log directory exists
    os.makedirs(LOG_DIR, exist_ok=True)
    log_file = os.path.join(LOG_DIR, "trading_agent.log")
    
    # Get the root logger or custom logger
    logger = logging.getLogger() # Root logger
    
    # Avoid adding handlers multiple times
    if not logger.handlers:
        logger.setLevel(log_level)
        
        # Console Handler
        console_handler = logging.StreamHandler(sys.stdout)
        console_handler.setFormatter(logging.Formatter(log_format))
        logger.addHandler(console_handler)
        
        # File Handler
        file_handler = logging.FileHandler(log_file, mode="a")
        file_handler.setFormatter(logging.Formatter(log_format))
        logger.addHandler(file_handler)
    
    # Return logger for the specific module
    return logging.getLogger(name)


# ======================================================================
# FILE: ai_module/groq_analyzer.py
# ======================================================================

"""
Groq AI Analyzer Module
Uses LLaMA 3 70B via Groq API to provide "Hedge Fund Analyst" reasoning for technical signals.
"""

import os
import json
import logging
import requests
from typing import Dict, Optional, Tuple, List
from datetime import datetime
from requests.adapters import HTTPAdapter
from requests.packages.urllib3.util.retry import Retry

from config.settings import (
    GROQ_API_KEY, 
    GROQ_MODEL, 
    GROQ_TEMPERATURE, 
    GROQ_MAX_TOKENS
)

logger = logging.getLogger(__name__)

class GroqAnalyzer:
    def __init__(self):
        self.api_key = GROQ_API_KEY
        self.api_url = "https://api.groq.com/openai/v1/chat/completions"
        self.model = GROQ_MODEL
        
        if not self.api_key or "YOUR_KEY" in self.api_key:
            logger.warning("‚ö†Ô∏è Groq API Key not found. AI Analysis disabled.")
            self.enabled = False
        else:
            self.enabled = True
            logger.info(f"üß† Groq AI Initialized | Model: {self.model}")

        # Setup resilient session
        self.session = requests.Session()
        retries = Retry(total=3, backoff_factor=0.5, status_forcelist=[500, 502, 503, 504])
        self.session.mount('https://', HTTPAdapter(max_retries=retries))

    def analyze_signal(
        self, 
        signal_data: Dict, 
        market_context: Dict, 
        technical_data: Dict
    ) -> Dict:
        """
        Analyze a trading signal using LLaMA 3.
        
        Returns:
            Dict containing:
            - reasoning (str): Natural language explanation
            - confidence (int): 0-100 score
            - risks (List[str]): Potential risks
            - verdict (str): "STRONG BUY", "CAUTIOUS BUY", "PASS"
        """
        if not self.enabled:
            return {"error": "AI Disabled"}

        try:
            prompt = self._construct_prompt(signal_data, market_context, technical_data)
            
            payload = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": self._get_system_prompt()},
                    {"role": "user", "content": prompt}
                ],
                "temperature": GROQ_TEMPERATURE,
                "max_tokens": GROQ_MAX_TOKENS,
                "response_format": {"type": "json_object"}
            }
            
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            start_time = datetime.now()
            response = self.session.post(
                self.api_url, 
                json=payload, 
                headers=headers, 
                timeout=10
            ) 
            response.raise_for_status()
            
            latency = (datetime.now() - start_time).total_seconds()
            result = response.json()
            
            ai_content = result['choices'][0]['message']['content']
            parsed_result = json.loads(ai_content)
            
            logger.info(f"ü§ñ AI Analysis Complete ({latency:.2f}s) | Confidence: {parsed_result.get('confidence')}%")
            
            return parsed_result

        except Exception as e:
            logger.error(f"‚ùå Groq Analysis Failed: {str(e)}")
            return None

    def test_connection(self) -> bool:
        """Test if Groq API is reachable and key is valid."""
        if not self.enabled:
            return False
            
        try:
            # Lightweight test call (list models)
            headers = {"Authorization": f"Bearer {self.api_key}"}
            response = self.session.get("https://api.groq.com/openai/v1/models", headers=headers, timeout=5)
            return response.status_code == 200
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Groq Connection Test Failed: {e}")
            return False

    def get_usage_stats(self) -> Dict:
        """Return usage statistics for the AI module."""
        return {
            "enabled": self.enabled,
            "model": self.model,
            "requests_today": 0, # TODO: Implement real tracking if needed
            "tokens_used": 0
        }

    def _get_system_prompt(self) -> str:
        return """You are a Senior Hedge Fund Technical Analyst. 
Your job is to VALIDATE algorithmic trading signals for NIFTY 50.
You are skeptical, risk-averse, and focus on CONFLUENCE.

OUTPUT FORMAT (JSON):
{
    "verdict": "STRONG_BUY" | "CAUTIOUS_BUY" | "STRONG_SELL" | "CAUTIOUS_SELL" | "PASS",
    "confidence": <0-100 integer>,
    "reasoning": "<Concise 2-sentence explanation focusing on WHY this works or fails>",
    "risks": ["<Risk 1>", "<Risk 2>"]
}

SCORING RULES:
- High Confidence (>80): Needs Trend Alignment + Structure Breakout + Good R:R.
- Medium Confidence (60-80): Good structure but mixed trend or low volume.
- Fail (<50): Counter-trend without reversal structure, or poor metrics.
- DIRECTION: Ensure verdict matches signal direction (SELL for Bearish, BUY for Bullish)."""

    def forecast_market_outlook(self, daily_summary_text: str) -> Dict:
        """
        Generate a market outlook forecast based on the day's summary.
        
        Args:
            daily_summary_text (str): A text summary of the day's price action and signals.
            
        Returns:
            Dict: {
                "outlook": "BULLISH" | "BEARISH" | "NEUTRAL",
                "confidence": int,
                "summary": str
            }
        """
        if not self.enabled:
            return {"outlook": "NEUTRAL", "confidence": 0, "summary": "AI Disabled"}

        try:
            system_prompt = """You are a Market Strategist. 
Analyze the provided end-of-day market summary and forecast the outlook for TOMORROW.
Consider trend, support/resistance tests, and overall sentiment.
OUTPUT JSON: {"outlook": "BULLISH"|"BEARISH"|"NEUTRAL", "confidence": 0-100, "summary": "One sentence outlook."}"""

            user_prompt = f"MARKET SUMMARY:\n{daily_summary_text}\n\nFORECAST THE NEXT SESSION:"

            payload = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                "temperature": 0.7,
                "max_tokens": 150,
                "response_format": {"type": "json_object"}
            }

            headers = {"Authorization": f"Bearer {self.api_key}"}
            
            response = self.session.post(
                self.api_url, 
                json=payload, 
                headers=headers, 
                timeout=10
            ) 
            response.raise_for_status()
            
            result = response.json()
            content = result['choices'][0]['message']['content']
            return json.loads(content)

        except Exception as e:
            logger.error(f"‚ùå Forecast failed: {e}")
            return {"outlook": "NEUTRAL", "confidence": 0, "summary": "Forecast Error"}


    def _construct_prompt(self, sig: Dict, context: Dict, tech: Dict) -> str:
        """Construct the dynamic prompt with signal details."""
        
        # safely access keys
        signal_type = sig.get('signal_type', 'UNKNOWN')
        price = sig.get('price_level', 0)
        trend_15m = context.get('trend_direction', 'FLAT')
        
        mtf_data = (
            f"15m Trend: {trend_15m}\n"
            f"Rel to VWAP: {'Above' if context.get('price_above_vwap') else 'Below'}\n"
            f"Rel to EMA20: {'Above' if context.get('price_above_ema20') else 'Below'}"
        )
        
        option_data = "N/A"
        # If we have option metrics passed in "tech" or "context"
        # Adapted based on usage in main.py
        
        return f"""
ANALYZE THIS TRADE SETUP:

INSTRUMENT: NIFTY 50
SIGNAL: {signal_type}
LEVEL: {price}
CURRENT PRICE: {sig.get('entry_price')}

TECHNICAL CONTEXT:
{mtf_data}

SIGNAL METRICS:
- Confidence: {sig.get('confidence')}%
- R:R Ratio: {sig.get('risk_reward_ratio', 0):.2f}
- Volume Surge: {sig.get('volume_confirmed')}
- Description: {sig.get('description')}

Evaluate based on Multi-Timeframe alignment and Market Structure.
"""

# Singleton access
_analyzer_instance = None

def get_analyzer():
    global _analyzer_instance
    if _analyzer_instance is None:
        _analyzer_instance = GroqAnalyzer()
    return _analyzer_instance


# ======================================================================
# FILE: analysis_module/__init__.py
# ======================================================================



# ======================================================================
# FILE: analysis_module/signal_pipeline.py
# ======================================================================

"""
Signal Pipeline Module
Encapsulates the logic for filtering, scoring, and enriching trading signals.
"""

import logging
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional
import pytz

from config.settings import (
    MAX_SAME_DIRECTION_ALERTS,
    MIN_SIGNAL_CONFIDENCE,
    TIME_ZONE,
)

logger = logging.getLogger(__name__)

class SignalPipeline:
    """
    Orchestrates the signal processing pipeline:
    1. Structural Checks
    2. Choppy Session Filter
    3. IV/Volatility Checks
    4. Correlation Checks
    5. Scoring & AI Enrichment
    """

    def __init__(self, groq_analyzer=None):
        self.groq_analyzer = groq_analyzer

    def process_signals(
        self,
        raw_signals: List[Dict],
        instrument: str,
        technical_context: Dict,
        option_metrics: Dict,
        recent_alerts: Dict,
        market_status: Dict
    ) -> List[Dict]:
        """
        Main entry point to process a batch of raw signals.
        """
        if not raw_signals:
            return []

        # Step 1: Choppy Session Filter & IV Check (Global Checks)
        # --------------------------------------------------------
        if market_status.get("is_choppy"):
            logger.info(f"‚è≠Ô∏è  Suppressing signals for {instrument} (Choppy Session: {market_status.get('choppy_reason')})")
            return []

        iv = option_metrics.get("iv")
        if iv is not None and iv < 10:
             logger.info(f"‚è≠Ô∏è  Suppressing signals for {instrument} (Low IV: {iv}%)")
             return []

        # Step 2: Correlation Check (Recent Alerts)
        # -----------------------------------------
        # Check if we have too many recent alerts in the same direction
        # This is a heuristic to prevent spamming "LONG" alerts if we just sent one.
        
        # Determine aggregate direction of new signals (if all are LONG or all are SHORT)
        has_long = any("BULLISH" in s["signal_type"] or "SUPPORT" in s["signal_type"] for s in raw_signals)
        has_short = any("BEARISH" in s["signal_type"] or "RESISTANCE" in s["signal_type"] for s in raw_signals)
        
        direction_check = "NEUTRAL"
        if has_long and not has_short: direction_check = "BULLISH"
        elif has_short and not has_long: direction_check = "BEARISH"
        
        if direction_check != "NEUTRAL":
            ist = pytz.timezone(TIME_ZONE)
            now = datetime.now(ist)
            recent_window = now - timedelta(minutes=15)
            
            recent_count = sum(
                1 for key, ts in recent_alerts.items()
                if ts > recent_window and 
                (getattr(key, "instrument", "") == instrument or isinstance(key, str) and instrument in key) and
                (
                    ("BULLISH" in str(key) or "SUPPORT" in str(key)) if direction_check == "BULLISH" else
                    ("BEARISH" in str(key) or "RESISTANCE" in str(key))
                )
            )
            
            if recent_count >= MAX_SAME_DIRECTION_ALERTS:
                 logger.info(f"‚è≠Ô∏è  Suppressing {direction_check} signals for {instrument} (Correlation Limit Hit)")
                 return []


        # Step 3: Conflict Resolution
        # ---------------------------
        valid_signals = self.resolve_conflicts(raw_signals, option_metrics)
        
        processed_signals = []

        # Step 4: Individual Signal Scoring & AI
        # --------------------------------------
        for signal in valid_signals:
            # Calculate Technical Score
            score, reasons = self.calculate_score(signal, technical_context, option_metrics)
            signal["score"] = score
            signal["score_reasons"] = reasons
            
            # Filter by Tech Score
            # TODO: Move threshold to config (60)
            if score < 60:
                logger.debug(f"üõë Signal Low Score: {score} | {signal['signal_type']}")
                continue
                
            # AI Enrichment (Advisory)
            if self.groq_analyzer:
                 try:
                    ai_context = {
                        "trend_direction": technical_context.get("higher_tf_context", {}).get("trend_direction", "FLAT"),
                        "pcr": option_metrics.get("pcr"),
                        "oi_sentiment": option_metrics.get("oi_change", {}).get("sentiment")
                    }
                    ai_analysis = self.groq_analyzer.analyze_signal(signal, ai_context, {})
                    signal["ai_analysis"] = ai_analysis
                    
                    # Log if AI disagrees strongly (but don't block by default)
                    if ai_analysis and "STRONG" in ai_analysis.get("verdict", "") and ai_analysis.get("confidence", 0) < 40:
                        logger.warning(f"‚ö†Ô∏è AI Disagrees with signal: {ai_analysis.get('verdict')}")
                        
                 except Exception as e:
                     logger.warning(f"‚ö†Ô∏è AI Analysis failed: {e}")
            
            processed_signals.append(signal)

        return processed_signals

    def resolve_conflicts(self, signals: List[Dict], option_metrics: Dict) -> List[Dict]:
        """
        Resolve conflicting signals (LONG vs SHORT) using Option Data & Confidence.
        """
        if not signals:
            return []
            
        long_signals = [s for s in signals if any(x in s["signal_type"] for x in ["BULLISH", "SUPPORT"])]
        short_signals = [s for s in signals if any(x in s["signal_type"] for x in ["BEARISH", "RESISTANCE"])]
        
        if not long_signals or not short_signals:
            return signals # No conflict
            
        # Conflict Detected
        logger.info(f"‚öîÔ∏è Conflict Detected: {len(long_signals)} LONG vs {len(short_signals)} SHORT")
        
        # 1. Option Chain Bias
        pcr = option_metrics.get("pcr")
        oi_sentiment = option_metrics.get("oi_change", {}).get("sentiment", "NEUTRAL")
        
        if oi_sentiment == "BULLISH" or (pcr and pcr > 1.2):
            logger.info("‚úÖ Resolving to LONG (Option Bias)")
            return long_signals
            
        elif oi_sentiment == "BEARISH" or (pcr and pcr < 0.8):
            logger.info("‚úÖ Resolving to SHORT (Option Bias)")
            return short_signals
            
        # 2. Fallback: Highest Technical Confidence
        all_sigs = long_signals + short_signals
        best_signal = max(all_sigs, key=lambda x: x.get('confidence', 0))
        logger.info(f"‚úÖ Resolving to Highest Confidence: {best_signal['signal_type']}")
        return [best_signal]

    def calculate_score(self, sig_data: Dict, analysis_context: Dict, option_metrics: Dict) -> Tuple[int, List[str]]:
        """
        Pure function to calculate quality score (0-100).
        """
        score = 50  # Base Score
        reasons = []
        
        # 1. Price Action / Confidence
        if sig_data.get("confidence", 0) >= 80:
            score += 15
            reasons.append("Strong Pattern (+15)")
        elif sig_data.get("confidence", 0) >= 65:
            score += 10
            reasons.append("Good Pattern (+10)")

        if sig_data.get("volume_confirmed"):
            score += 10
            reasons.append("Volume High (+10)")
            
        # 2. Option Chain Sentiment
        pcr = option_metrics.get("pcr")
        oi_sentiment = option_metrics.get("oi_change", {}).get("sentiment", "NEUTRAL")
        signal_type = sig_data["signal_type"]
        is_bullish = "BULLISH" in signal_type or "SUPPORT" in signal_type
        
        if pcr:
            if is_bullish:
                if pcr > 1.0: 
                    score += 10
                    reasons.append(f"PCR Bullish {pcr} (+10)")
                elif pcr < 0.6: 
                    score -= 10
                    reasons.append(f"PCR Bearish {pcr} (-10)")
            else: # Bearish
                if pcr < 0.7: 
                    score += 10
                    reasons.append(f"PCR Bearish {pcr} (+10)")
                elif pcr > 1.2: 
                    score -= 10
                    reasons.append(f"PCR Bullish {pcr} (-10)")

        # OI Sentiment Logic
        if is_bullish and oi_sentiment == "BULLISH":
            score += 15
            reasons.append("OI Sentiment Bullish (+15)")
        elif not is_bullish and oi_sentiment == "BEARISH":
            score += 15
            reasons.append("OI Sentiment Bearish (+15)")
        elif (is_bullish and oi_sentiment == "BEARISH") or (not is_bullish and oi_sentiment == "BULLISH"):
            score -= 15
            reasons.append(f"OI Sentiment Conflict {oi_sentiment} (-15)")

        # 3. Multi-Timeframe Trend
        mtf_trend = analysis_context.get("higher_tf_context", {}).get("trend_direction", "FLAT")
        if mtf_trend != "FLAT":
            if is_bullish and mtf_trend == "UP":
                score += 15
                reasons.append("Trend Aligned (15m UP) (+15)")
            elif not is_bullish and mtf_trend == "DOWN":
                score += 15
                reasons.append("Trend Aligned (15m DOWN) (+15)")
            elif (is_bullish and mtf_trend == "DOWN") or (not is_bullish and mtf_trend == "UP"):
                score -= 10
                reasons.append(f"Counter Trend (15m {mtf_trend}) (-10)")
                
                # Reversal Boost
                is_reversal = any(x in sig_data["signal_type"] for x in ["BOUNCE", "RETEST", "PIN_BAR"])
                if is_reversal and (sig_data.get("volume_confirmed") or sig_data.get("momentum_confirmed")):
                     score += 10
                     reasons.append("Reversal Setup Bonus (+10)")

        return max(0, min(100, score)), reasons


# ======================================================================
# FILE: analysis_module/technical.py
# ======================================================================

"""
Technical Analysis Module
Core calculations: PDH/PDL, Support/Resistance, Volume, Breakouts, Advanced TA
Includes debugging output for signal validation
"""

import pandas as pd
import numpy as np
import logging
from datetime import datetime, time
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from enum import Enum

from config.settings import (
    SR_CLUSTER_TOLERANCE,
    MIN_SR_TOUCHES,
    LOOKBACK_BARS,
    MIN_VOLUME_RATIO,
    VOLUME_PERIOD,
    FALSE_BREAKOUT_RETRACEMENT,
    RETEST_ZONE_PERCENT,
    MIN_RSI_BULLISH,
    MAX_RSI_BEARISH,
    RSI_PERIOD,
    ATR_PERIOD,
    EMA_SHORT,
    EMA_LONG,
    MIN_RISK_REWARD_RATIO,
    ATR_SL_MULTIPLIER,
    ATR_TP_MULTIPLIER,
    DEBUG_MODE,
)

logger = logging.getLogger(__name__)


class SignalType(Enum):
    """Signal types"""

    BULLISH_BREAKOUT = "BULLISH_BREAKOUT"
    BEARISH_BREAKOUT = "BEARISH_BREAKOUT"
    FALSE_BREAKOUT = "FALSE_BREAKOUT"
    RETEST_SETUP = "RETEST_SETUP"
    INSIDE_BAR = "INSIDE_BAR"
    SUPPORT_BOUNCE = "SUPPORT_BOUNCE"
    RESISTANCE_BOUNCE = "RESISTANCE_BOUNCE"
    BULLISH_PIN_BAR = "BULLISH_PIN_BAR"
    BEARISH_PIN_BAR = "BEARISH_PIN_BAR"
    BULLISH_ENGULFING = "BULLISH_ENGULFING"
    BEARISH_ENGULFING = "BEARISH_ENGULFING"


@dataclass
class Signal:
    """Trading signal data class"""

    signal_type: SignalType
    instrument: str
    timeframe: str
    price_level: float
    entry_price: float
    stop_loss: float
    take_profit: float
    confidence: float  # 0-100%
    volume_confirmed: bool
    momentum_confirmed: bool
    risk_reward_ratio: float
    timestamp: pd.Timestamp
    description: str
    atr: float = 0.0
    debug_info: Dict = None
    take_profit_2: float = 0.0
    take_profit_3: float = 0.0


@dataclass
class TechnicalLevels:
    """Support/Resistance levels and related metrics"""

    support_levels: List[float]
    resistance_levels: List[float]
    pivot: float
    pdh: float
    pdl: float
    atr: float
    volatility_score: float


class TechnicalAnalyzer:
    """Main technical analysis engine"""

    def __init__(self, instrument: str):
        self.instrument = instrument
        logger.info(f"üî¨ TechnicalAnalyzer initialized for {instrument}")

    # =====================================================================
    # PDH / PDL
    # =====================================================================

    def calculate_pdh_pdl(
        self, df: pd.DataFrame
    ) -> Tuple[Optional[float], Optional[float]]:
        """
        Calculate Previous Day High & Low.

        Uses daily resample of df.
        """
        try:
            df = df.copy()
            df.index = pd.to_datetime(df.index)

            daily_df = df.resample("D").agg(
                {
                    "open": "first",
                    "high": "max",
                    "low": "min",
                    "close": "last",
                    "volume": "sum",
                }
            )

            if len(daily_df) < 2:
                logger.warning("‚ùå Not enough daily data for PDH/PDL")
                return None, None

            prev_day = daily_df.iloc[-2]
            pdh = float(prev_day["high"])
            pdl = float(prev_day["low"])

            current_open = float(daily_df.iloc[-1]["open"])
            gap_pct = (
                ((current_open - pdh) / pdh) * 100.0 if pdh > 0 else 0.0
            )

            logger.info(
                f"üìä PDH/PDL | PDH: {pdh:.2f} | PDL: {pdl:.2f} | "
                f"Gap% vs PDH(open): {gap_pct:.2f}%"
            )

            if DEBUG_MODE:
                logger.debug(
                    f"   PDH: {pdh:.2f}, PDL: {pdl:.2f}, "
                    f"Current open: {current_open:.2f}, Gap%: {gap_pct:.2f}"
                )

            return pdh, pdl

        except Exception as e:
            logger.error(f"‚ùå PDH/PDL calculation failed: {str(e)}")
            return None, None

    # =====================================================================
    # SUPPORT / RESISTANCE
    # =====================================================================

    def calculate_support_resistance(self, df: pd.DataFrame) -> TechnicalLevels:
        """
        Calculate Support/Resistance levels with clustering.
        """
        try:
            df = df.copy()
            lookback = min(LOOKBACK_BARS, len(df))
            df_sub = df.tail(lookback)

            highs = df_sub["high"].values
            lows = df_sub["low"].values

            support_levels = self._find_support_levels(lows)
            resistance_levels = self._find_resistance_levels(highs)

            support_clusters = self._cluster_levels(support_levels)
            resistance_clusters = self._cluster_levels(resistance_levels)

            pdh, pdl = self.calculate_pdh_pdl(df)
            pivots = self._calculate_pivots(df_sub)
            pivot_std = pivots.get("pivot", 0.0)

            atr = self._calculate_atr(df_sub)
            volatility_score = self._calculate_volatility_score(df_sub)

            msg = (
                f"‚úÖ S/R Calculated | Supports: {len(support_clusters)} {support_clusters[:3]}... | "
                f"Resistances: {len(resistance_clusters)} {resistance_clusters[:3]}..."
            )
            logger.info(msg)

            if DEBUG_MODE:
                logger.debug(
                    "   Supports: "
                    f"{[f'{s:.2f}' for s in support_clusters[:5]]}"
                )
                logger.debug(
                    "   Resistances: "
                    f"{[f'{r:.2f}' for r in resistance_clusters[:5]]}"
                )

            return TechnicalLevels(
                support_levels=sorted(support_clusters),
                resistance_levels=sorted(resistance_clusters, reverse=True),
                pivot=pivot_std,
                pdh=pdh or 0.0,
                pdl=pdl or 0.0,
                atr=atr,
                volatility_score=volatility_score,
            )

        except Exception as e:
            logger.error(f"‚ùå S/R calculation failed: {str(e)}")
            return TechnicalLevels([], [], 0.0, 0.0, 0.0, 0.0, 0.0)

    def _find_support_levels(self, lows: np.ndarray) -> List[float]:
        """Identify support levels via local minima."""
        supports: List[float] = []
        for i in range(1, len(lows) - 1):
            if lows[i] < lows[i - 1] and lows[i] < lows[i + 1]:
                supports.append(float(lows[i]))
        return supports

    def _find_resistance_levels(self, highs: np.ndarray) -> List[float]:
        """Identify resistance levels via local maxima."""
        resistances: List[float] = []
        for i in range(1, len(highs) - 1):
            if highs[i] > highs[i - 1] and highs[i] > highs[i + 1]:
                resistances.append(float(highs[i]))
        return resistances

    def _cluster_levels(
        self, levels: List[float], tolerance_pct: float = SR_CLUSTER_TOLERANCE
    ) -> List[float]:
        """Cluster nearby levels together."""
        if not levels:
            return []

        sorted_levels = sorted(levels)
        clusters: List[float] = []
        current_cluster: List[float] = [sorted_levels[0]]

        for level in sorted_levels[1:]:
            cluster_mean = float(np.mean(current_cluster))
            tolerance = cluster_mean * (tolerance_pct / 100.0)

            if abs(level - cluster_mean) <= tolerance:
                current_cluster.append(level)
            else:
                clusters.append(float(np.mean(current_cluster)))
                current_cluster = [level]

        clusters.append(float(np.mean(current_cluster)))

        if DEBUG_MODE:
            logger.debug(
                f"   Clustered {len(sorted_levels)} into {len(clusters)} clusters"
            )

        return clusters

    def _calculate_multi_targets(
        self,
        entry_price: float,
        stop_loss: float,
        direction: str,
        support_resistance: TechnicalLevels,
        is_strong_trend: bool = False
    ) -> Tuple[float, float, float]:
        """
        Calculate T1, T2, T3 based on S/R levels and R:R.
        
        T1 (Safe): Maximum of (Nearest Level, 1:1.5 RR if level too close)
        T2 (Moderate): Next Key Level or 1:2 RR (Only if strong trend)
        T3 (Aggressive): Level after that or 1:3 RR (Only if strong trend)
        
        Returns: (t1, t2, t3)
        """
        atr = support_resistance.atr
        risk = abs(entry_price - stop_loss)
        if risk == 0:
            return 0.0, 0.0, 0.0
            
        t1, t2, t3 = 0.0, 0.0, 0.0
        
        if direction.upper() == "LONG":
            # Identify resistance levels above entry
            relevant_levels = [r for r in sorted(support_resistance.resistance_levels) if r > entry_price]
            
            # --- T1 ---
            if relevant_levels:
                t1 = relevant_levels[0]
                # If risk reward < 1:1, push to next level or forcing 1.5R
                if (t1 - entry_price) < risk:
                     t1 = max(t1, entry_price + (risk * 1.5))
            else:
                t1 = entry_price + (risk * 1.5)
                
            # If trend is weak, stop here
            if not is_strong_trend:
                return t1, 0.0, 0.0
                
            # --- T2 ---
            if len(relevant_levels) > 1:
                t2 = relevant_levels[1]
            else:
                t2 = entry_price + (risk * 2.5)
            if t2 <= t1:
                t2 = max(t2, t1 + (risk * 1.0))

            # --- T3 ---
            if len(relevant_levels) > 2:
                t3 = relevant_levels[2]
            else:
                t3 = entry_price + (risk * 4.0)
            if t3 <= t2:
                t3 = max(t3, t2 + (risk * 1.0))
                
        else: # SHORT
            # Identify support levels below entry (High -> Low for iteration)
            relevant_levels = [s for s in sorted(support_resistance.support_levels, reverse=True) if s < entry_price]
            
            # --- T1 ---
            if relevant_levels:
                t1 = relevant_levels[0]
                if (entry_price - t1) < risk:
                    t1 = min(t1, entry_price - (risk * 1.5))
            else:
                t1 = entry_price - (risk * 1.5)
                
            # If trend is weak, stop here
            if not is_strong_trend:
                return t1, 0.0, 0.0
                
            # --- T2 ---
            if len(relevant_levels) > 1:
                t2 = relevant_levels[1]
            else:
                t2 = entry_price - (risk * 2.5)
            if t2 >= t1:
                 t2 = min(t2, t1 - (risk * 1.0))
                 
            # --- T3 ---
            if len(relevant_levels) > 2:
                t3 = relevant_levels[2]
            else:
                t3 = entry_price - (risk * 4.0)
            if t3 >= t2:
                t3 = min(t3, t2 - (risk * 1.0))
                
        return t1, t2, t3

    def _calculate_pivots(
        self, df: pd.DataFrame
    ) -> Dict[str, float]:
        """Calculate pivot points (Standard & simple Fibonacci-style)."""
        try:
            high = df["high"].iloc[-1]
            low = df["low"].iloc[-1]
            close = df["close"].iloc[-1]

            pivot = (high + low + close) / 3
            r1 = (2 * pivot) - low
            s1 = (2 * pivot) - high
            r2 = pivot + (high - low)
            s2 = pivot - (high - low)

            return {
                "pivot": pivot,
                "r1": r1,
                "s1": s1,
                "r2": r2,
                "s2": s2,
            }
        except Exception as e:
            logger.error(f"Error calculating pivots: {e}")
            return {}

    def calculate_fibonacci_levels(self, df: pd.DataFrame, lookback: int = 50) -> Dict[str, float]:
        """
        Calculate Fibonacci Retracement levels from recent Swing High/Low.
        
        Args:
            df: OHLCV DataFrame
            lookback: Number of candles to scan for Swing High/Low (default 50)
            
        Returns:
            Dict with '0.382', '0.5', '0.618' levels
        """
        try:
            recent_data = df.tail(lookback)
            if recent_data.empty:
                return {}
            
            # Find Swing High and Low
            swing_high = recent_data["high"].max()
            swing_low = recent_data["low"].min()
            range_diff = swing_high - swing_low
            
            # Determine direction (Trend) to know if we represent support or resistance
            # For simplicity in this context, we return the Retracement levels from the Low upwards 
            # (Support in uptrend) AND High downwards (Resistance in downtrend) is too complex for now.
            # We will calculate "Retracement from Low to High" (assuming uptrend support checks)
            # and "Retracement from High to Low" (assuming downtrend resistance checks).
            
            # Just returning plain levels relative to the range is ambiguous without trend.
            # Standard approach: Return both "Retracement Up" (Support) and "Retracement Down" (Resistance) keys?
            # Or simplified: Just levels.
            
            # Let's assume we are looking for SUPPORT levels (pullback in uptrend)
            # 0% is High, 100% is Low.
            # 38.2% Retracement = High - (Range * 0.382)
            # 50% Retracement = High - (Range * 0.5)
            # 61.8% Retracement = High - (Range * 0.618)
            
            fib_support = {
                "0.236": swing_high - (range_diff * 0.236),
                "0.382": swing_high - (range_diff * 0.382),
                "0.5": swing_high - (range_diff * 0.5),
                "0.618": swing_high - (range_diff * 0.618),
                "0.786": swing_high - (range_diff * 0.786),
                "swing_high": swing_high,
                "swing_low": swing_low
            }
            
            return fib_support
            
        except Exception as e:
            logger.error(f"Error calculating Fibonacci levels: {e}")
            return {}

    # =====================================================================
    # VOLUME ANALYSIS
    # =====================================================================

    def check_volume_confirmation(
        self, df: pd.DataFrame
    ) -> Tuple[bool, float, str]:
        """
        Check if current candle has volume confirmation.
        Returns True if volume is zero (index data) to avoid blocking signals.
        """
        try:
            df = df.copy()
            if len(df) < VOLUME_PERIOD + 2:
                return False, 0.0, ""

            # Check if volume data exists (indices often have 0 volume)
            total_volume = df["volume"].sum()
            if total_volume == 0:
                logger.debug("‚ö†Ô∏è  Zero volume detected (Index data) - Bypassing volume check")
                return True, 1.0, "Index (No Vol)"

            current_vol = float(df["volume"].iloc[-1])
            avg_vol = float(
                df["volume"].iloc[-VOLUME_PERIOD - 1 : -1].mean()
            )
            ratio = current_vol / avg_vol if avg_vol > 0 else 0.0
            is_confirmed = ratio >= MIN_VOLUME_RATIO

            info = (
                f"Vol: {current_vol:.0f} | Avg: {avg_vol:.0f} | Ratio: {ratio:.2f}x"
            )

            if is_confirmed:
                logger.info(f"‚úÖ Volume confirmed | {info}")
            else:
                logger.warning(f"‚ö†Ô∏è  Low volume | {info}")

            if DEBUG_MODE:
                logger.debug(f"   Volume threshold: {MIN_VOLUME_RATIO}x")

            return is_confirmed, ratio, info

        except Exception as e:
            logger.error(f"‚ùå Volume check failed: {str(e)}")
            # Default to True on error to not block price signals if data is bad
            return True, 0.0, "Error (Bypassed)"

    # =====================================================================
    # OPENING RANGE BREAKOUT (ORB)
    # =====================================================================

    def get_opening_range(self, df: pd.DataFrame, duration_mins: int = 15) -> Optional[Dict]:
        """
        Calculate opening range (first N minutes of trading session).
        
        ORB is one of the most reliable intraday setups for Nifty/BankNifty.
        Breakouts of the opening range tend to continue in that direction.
        
        Args:
            df: 5-minute OHLC data with datetime index
            duration_mins: 15 or 30 minutes (default 15)
        
        Returns:
            Dict with ORB high/low/range or None if insufficient data
        """
        try:
            # Market opens at 9:15 AM IST
            if duration_mins == 15:
                end_time = "09:30"
            elif duration_mins == 30:
                end_time = "09:45"
            else:
                end_time = "09:30"
            
            # Filter to opening range
            opening_candles = df.between_time("09:15", end_time)
            
            if opening_candles.empty or len(opening_candles) < 2:
                return None
            
            orb_high = opening_candles["high"].max()
            orb_low = opening_candles["low"].min()
            orb_range = orb_high - orb_low
            
            logger.info(
                f"üìä Opening Range ({duration_mins}min) | "
                f"High: {orb_high:.2f} | Low: {orb_low:.2f} | Range: {orb_range:.2f}"
            )
            
            return {
                "high": orb_high,
                "low": orb_low,
                "range": orb_range,
                "duration_mins": duration_mins
            }
        
        except Exception as e:
            logger.error(f"‚ùå Opening range calculation failed: {e}")
            return None

    # =====================================================================
    # HIGHER TF CONTEXT (15m)
    # =====================================================================

    def get_higher_tf_context(self, df_15m: pd.DataFrame, df_5m: pd.DataFrame = None, df_daily: pd.DataFrame = None) -> Dict:
        """
        Build higher timeframe context:
        - 15m Trend direction: UP / DOWN / FLAT
        - 15m RSI and EMAs
        - 5m VWAP and 20 EMA (for intraday setups)
        - Previous day trend
        """
        context = {
            "trend_direction": "FLAT",
            "ema_short_15": 0.0,
            "ema_long_15": 0.0,
            "rsi_15": 50.0,
            "vwap_5m": 0.0,
            "vwap_slope": "FLAT",
            "ema_20_5m": 0.0,
            "price_above_vwap": False,
            "price_above_ema20": False,
            "prev_day_trend": "FLAT",
        }

        try:
            # ====================
            # 15m Trend Analysis
            # ====================
            if df_15m is None or df_15m.empty:
                logger.warning("‚ö†Ô∏è  get_higher_tf_context: empty 15m data")
                return context

            df = df_15m.copy().sort_index()

            if len(df) < max(EMA_LONG, RSI_PERIOD) + 5:
                logger.warning(
                    "‚ö†Ô∏è  get_higher_tf_context: not enough 15m bars"
                )
                return context

            ema_short = df["close"].ewm(
                span=EMA_SHORT, adjust=False
            ).mean()
            ema_long = df["close"].ewm(span=EMA_LONG, adjust=False).mean()

            ema_short_15 = float(ema_short.iloc[-1])
            ema_long_15 = float(ema_long.iloc[-1])
            rsi_15 = float(self._calculate_rsi(df))

            if ema_short_15 > ema_long_15:
                trend = "UP"
            elif ema_short_15 < ema_long_15:
                trend = "DOWN"
            else:
                trend = "FLAT"
            
            # ====================
            # Early Reversal Detection (reduce lag)
            # ====================
            # If trend is DOWN but price > 20EMA and RSI > 55 -> weak UP (Early Reversal)
            current_close = float(df["close"].iloc[-1])
            ema_20_15m = float(df["close"].ewm(span=20, adjust=False).mean().iloc[-1])
            
            if trend == "DOWN" and current_close > ema_20_15m and rsi_15 > 55:
                trend = "UP"  # Early reversal
                logger.info(f"üîÑ Early trend reversal detected (Price > 15m EMA20 & RSI {rsi_15:.1f})")
            
            elif trend == "UP" and current_close < ema_20_15m and rsi_15 < 45:
                trend = "DOWN" # Early correction
                logger.info(f"üîÑ Early trend correction detected (Price < 15m EMA20 & RSI {rsi_15:.1f})")

            context.update(
                {
                    "trend_direction": trend,
                    "ema_short_15": ema_short_15,
                    "ema_long_15": ema_long_15,
                    "rsi_15": rsi_15,
                }
            )

            # ====================
            # 5m VWAP and 20 EMA
            # ====================
            if df_5m is not None and not df_5m.empty and len(df_5m) >= 20:
                df_5m_copy = df_5m.copy().sort_index()
                
                # Calculate VWAP
                _, vwap_5m, vwap_slope = self._calculate_vwap(df_5m_copy)
                
                # Calculate 20 EMA on 5m
                ema_20 = df_5m_copy["close"].ewm(span=20, adjust=False).mean()
                ema_20_5m = float(ema_20.iloc[-1])
                
                # Current price vs VWAP and EMA
                current_price = float(df_5m_copy["close"].iloc[-1])
                price_above_vwap = current_price > vwap_5m
                price_above_ema20 = current_price > ema_20_5m
                
                context.update({
                    "vwap_5m": vwap_5m,
                    "vwap_slope": vwap_slope,
                    "ema_20_5m": ema_20_5m,
                    "price_above_vwap": price_above_vwap,
                    "price_above_ema20": price_above_ema20,
                })

            # ====================
            # Previous Day Trend
            # ====================
            if df_daily is not None:
                prev_day_trend = self._get_previous_day_trend(df_daily)
                context["prev_day_trend"] = prev_day_trend

            # ====================
            # Opening Range (ORB)
            # ====================
            if df_5m is not None:
                orb = self.get_opening_range(df_5m, duration_mins=15)
                if orb:
                    context["opening_range"] = orb
                    context["orb_high"] = orb["high"]
                    context["orb_low"] = orb["low"]
                    context["orb_range"] = orb["range"]

            logger.info(
                "üìê Higher TF context | "
                f"Trend15m: {trend} | "
                f"VWAP: {context.get('vwap_5m', 0):.2f} ({context.get('vwap_slope', 'N/A')}) | "
                f"20EMA: {context.get('ema_20_5m', 0):.2f} | "
                f"PrevDay: {context.get('prev_day_trend', 'N/A')}"
            )
            return context

        except Exception as e:
            logger.error(f"‚ùå get_higher_tf_context failed: {str(e)}")
            return context

    # =====================================================================
    # BREAKOUT QUALITY FILTERS
    # =====================================================================

    def _detect_consolidation(
        self, df: pd.DataFrame, lookback: int = 20
    ) -> Optional[Dict]:
        """
        Detect if price is consolidating (sideways range).
        
        High-quality breakouts come from consolidation, not random noise.
        
        Args:
            df: OHLCV DataFrame
            lookback: Bars to analyze
            
        Returns:
            {
                "is_consolidating": bool,
                "range_high": float,
                "range_low": float,
                "range_pct": float,
                "bars_in_range": int
            }
        """
        try:
            if df is None or len(df) < lookback:
                return None
            
            recent = df.tail(lookback)
            
            # Calculate range
            range_high = float(recent["high"].max())
            range_low = float(recent["low"].min())
            range_pct = ((range_high - range_low) / range_low) * 100.0
            
            # Consolidation criteria:
            # 1. Tight range (< 2% for intraday on indices)
            # 2. Majority of bars within this range (at least 70%)
            # 3. Minimum bars in consolidation (at least 8)
            
            is_tight = range_pct < 2.0
            
            # Count bars fully within range
            bars_in_range = sum(
                1 for _, row in recent.iterrows()
                if range_low <= row["low"] and row["high"] <= range_high
            )
            
            pct_in_range = bars_in_range / lookback
            is_consolidated = is_tight and pct_in_range >= 0.7 and bars_in_range >= 8
            
            result = {
                "is_consolidating": is_consolidated,
                "range_high": range_high,
                "range_low": range_low,
                "range_pct": range_pct,
                "bars_in_range": bars_in_range,
            }
            
            if is_consolidated:
                logger.info(
                    f"üì¶ Consolidation detected | Range: {range_low:.2f}-{range_high:.2f} "
                    f"({range_pct:.2f}%) | {bars_in_range}/{lookback} bars"
                )
            else:
                logger.debug(
                    f"‚è≠Ô∏è No consolidation | Range: {range_pct:.2f}% | "
                    f"Bars in range: {bars_in_range}/{lookback}"
                )
            
            return result
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Consolidation detection failed: {str(e)}")
            return None

    def _detect_volume_surge(
        self, df: pd.DataFrame
    ) -> Tuple[bool, float, str]:
        """
        Detect volume surge on current bar.
        
        Strong breakouts have volume surges, not just average volume.
        
        Criteria:
            - Current volume > 1.5x 20-bar average
            - AND Current volume > highest of last 5 bars
            
        Returns:
            (has_surge, surge_ratio, description)
        """
        try:
            if df is None or len(df) < 20:
                return False, 0.0, "Insufficient data"
            
            # Check if volume data exists
            if df["volume"].sum() == 0:
                logger.debug("‚ö†Ô∏è No volume data - bypassing surge check")
                return True, 1.0, "Index (No Vol)"
            
            current_vol = float(df["volume"].iloc[-1])
            avg_vol_20 = float(df["volume"].tail(20).mean())
            max_vol_5 = float(df["volume"].tail(6).iloc[:-1].max())  # Exclude current
            
            surge_ratio = current_vol / avg_vol_20 if avg_vol_20 > 0 else 0
            
            # Surge conditions
            # Surge conditions
            # Lowered from 1.5 to 1.2 to catch sustained moves with decent volume
            above_average = surge_ratio >= 1.2
            above_recent = current_vol > max_vol_5
            
            has_surge = above_average and above_recent
            
            if has_surge:
                description = f"Volume surge: {surge_ratio:.2f}x avg, highest in 5 bars"
                logger.info(f"üìä {description}")
            else:
                description = f"No surge: {surge_ratio:.2f}x avg (need 1.5x + highest in 5)"
                logger.debug(f"‚è≠Ô∏è {description}")
            
            return has_surge, surge_ratio, description
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Volume surge detection failed: {str(e)}")
            # Default to allowing the trade if check fails
            return True, 1.0, "Error (bypassed)"

    def _is_valid_breakout_time(self) -> Tuple[bool, str]:
        """
        Check if current time is suitable for breakout trading.
        
        Avoid:
            - First 15 mins (09:15-09:30): Too volatile, whipsaws
            - Last hour (14:30-15:30): Low follow-through
            - Lunch hour (12:30-13:30): Low volume, choppy
            
        Best breakout hours: 09:30-12:30, 13:30-14:30
        
        Returns:
            (is_valid, reason)
        """
        try:
            import pytz
            
            ist = pytz.timezone("Asia/Kolkata")
            now = datetime.now(ist).time()
            
            # Morning volatility window
            if time(9, 15) <= now < time(9, 20):
                return False, "Morning volatility (09:15-09:20)"
            
            # Lunch hour (low volume)
            if time(12, 30) <= now < time(13, 0):
                return False, "Lunch hour (12:30-13:00)"
            
            # Last hour (poor follow-through)
            if time(14, 30) <= now <= time(15, 30):
                return False, "Last hour (14:30-15:30)"
            
            # Good breakout windows
            # Relaxed start to 09:20 to catch early trends
            # Europe open approach at 13:00
            if (time(9, 20) <= now < time(12, 30)) or \
               (time(13, 0) <= now < time(14, 30)):
                return True, "Optimal breakout window"
            
            return False, "Outside breakout hours"
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Time check failed: {str(e)}")
            return True, "Time check bypassed"

    # =====================================================================
    # BREAKOUT DETECTION WITH MTF
    # =====================================================================

    def detect_breakout(
        self,
        df: pd.DataFrame,
        support_resistance: TechnicalLevels,
        higher_tf_context: Dict,
    ) -> Optional[Signal]:
        """
        Detect high-quality breakout with multi-factor confirmation.
        
        Filters:
        1. Time of day (avoid choppy periods)
        2. Consolidation (must break from range)
        3. MTF Trend (15m alignment)
        4. Volume Surge (explosive move)
        5. RSI Momentum
        """
        try:
            if df is None or df.empty:
                return None

            # 1. Time of Day Filter
            is_valid_time, time_reason = self._is_valid_breakout_time()
            if not is_valid_time:
                # Log only occasionally to avoid spam
                if datetime.now().minute % 15 == 0:
                    logger.debug(f"‚è≠Ô∏è Breakout skipped: {time_reason}")
                return None

            df = df.copy()
            current = df.iloc[-1]
            current_price = float(current["close"])
            current_high = float(current["high"])
            current_low = float(current["low"])

            trend_dir = higher_tf_context.get("trend_direction", "FLAT")
            rsi_15 = float(higher_tf_context.get("rsi_15", 50.0))

            breakout_signal: Optional[Signal] = None

            rsi_5 = self._calculate_rsi(df)
            
            # 2. Volume Surge Check
            has_surge, surge_ratio, surge_desc = self._detect_volume_surge(df)
            
            # 3. Consolidation Check
            # We check this only if we find a potential breakout level
            consolidation = self._detect_consolidation(df)
            is_consolidating = consolidation["is_consolidating"] if consolidation else False

            # 4. Opening Range Breakout (ORB) Check
            orb = higher_tf_context.get("opening_range")
            is_orb_breakout = False
            orb_direction = None
            orb_boost = 0
            
            if orb:
                current_time = df.index[-1].time()
                # Only check ORB after it's established (after 9:30 AM)
                if current_time > time(9, 30):
                    # Bullish ORB: price breaks above opening range high
                    if current_high > orb["high"] * 1.0005:  # 0.05% buffer
                        is_orb_breakout = True
                        orb_direction = "BULLISH"
                        orb_boost = 10  # Boost confidence for ORB breakouts
                        logger.info(
                            f"üöÄ ORB BULLISH BREAKOUT | Price: {current_price:.2f} > "
                            f"ORB High: {orb['high']:.2f}"
                        )
                    
                    # Bearish ORB: price breaks below opening range low
                    elif current_low < orb["low"] * 0.9995:  # 0.05% buffer
                        is_orb_breakout = True
                        orb_direction = "BEARISH"
                        orb_boost = 10  # Boost confidence for ORB breakouts
                        logger.info(
                            f"üìâ ORB BEARISH BREAKOUT | Price: {current_price:.2f} < "
                            f"ORB Low: {orb['low']:.2f}"
                        )

            # ------------------------
            # Bullish breakout
            # ------------------------
            if support_resistance.resistance_levels:
                # Robustly find nearest resistance (closest to price)
                sorted_resistances = sorted(
                    support_resistance.resistance_levels, 
                    key=lambda x: abs(x - current_price)
                )
                nearest_resistance = float(sorted_resistances[0])

                # Check for breakout (High > Resistance)
                if current_high > nearest_resistance:
                    
                    # Filter: Must be consolidating OR have massive volume surge
                    if not is_consolidating and not has_surge:
                        logger.info(
                            f"‚è≠Ô∏è Bullish breakout ignored (No consolidation/surge) | "
                            f"Vol: {surge_ratio:.1f}x"
                        )
                        return None
                        
                    # Filter: MTF Trend Alignment
                    mtf_ok = (
                        trend_dir == "UP"
                        and rsi_15 >= MIN_RSI_BULLISH
                    )

                    if not mtf_ok:
                        logger.info(
                            "‚è≠Ô∏è  Bullish breakout ignored (MTF filter) | "
                            f"Trend15m: {trend_dir} | RSI15: {rsi_15:.1f}"
                        )
                    else:
                        logger.info(
                            "üöÄ Bullish breakout candidate | "
                            f"Price: {current_price:.2f} > R: {nearest_resistance:.2f} | "
                            f"Consolidation: {is_consolidating} | Surge: {has_surge}"
                        )

                        atr = support_resistance.atr
                        sl = current_low - (atr * ATR_SL_MULTIPLIER)
                        
                        # Strong Trend Logic
                        is_strong_trend = (
                            has_surge 
                            and trend_dir == "UP" 
                            and rsi_15 >= 60 
                            and rsi_5 >= 60
                        )
                        
                        tp1, tp2, tp3 = self._calculate_multi_targets(
                            current_price, sl, "LONG", support_resistance, is_strong_trend
                        )
                        
                        risk_reward = (tp1 - current_price) / max(
                            current_price - sl, 1e-6
                        )

                        # Confidence Scoring
                        confidence = 60.0
                        if has_surge:
                            confidence += 10
                        if is_consolidating:
                            confidence += 10
                        if rsi_5 >= MIN_RSI_BULLISH:
                            confidence += 5
                        if trend_dir == "UP":
                            confidence += 10
                        if risk_reward >= MIN_RISK_REWARD_RATIO:
                            confidence += 5
                        # NEW: ORB boost
                        if is_orb_breakout and orb_direction == "BULLISH":
                            confidence += orb_boost

                        confidence = min(confidence, 95.0)

                        breakout_signal = Signal(
                            signal_type=SignalType.BULLISH_BREAKOUT,
                            instrument=self.instrument,
                            timeframe="5MIN",
                            price_level=nearest_resistance,
                            entry_price=current_price,
                            stop_loss=sl,
                            take_profit=tp1,
                            take_profit_2=tp2,
                            take_profit_3=tp3,
                            confidence=confidence,
                            volume_confirmed=has_surge,
                            momentum_confirmed=(
                                rsi_5 >= MIN_RSI_BULLISH
                            ),
                            risk_reward_ratio=risk_reward,
                            timestamp=pd.Timestamp.now(),
                            description=(
                                f"Bullish breakout at {nearest_resistance:.2f} | "
                                f"RR: {risk_reward:.2f} | "
                                f"Vol Surge: {has_surge} | Consolidation: {is_consolidating}"
                                f"{' | ORB Breakout' if is_orb_breakout and orb_direction == 'BULLISH' else ''}"
                            ),
                            debug_info={
                                "surge_ratio": surge_ratio,
                                "is_consolidating": is_consolidating,
                                "rsi_5": rsi_5,
                                "rsi_15": rsi_15,
                                "trend_dir": trend_dir,
                                "atr": atr,
                                "is_strong_trend": is_strong_trend
                            },
                        )

            # ------------------------
            # Bearish breakdown
            # ------------------------
            if support_resistance.support_levels:
                # Robustly find nearest support (closest to price)
                # Sort by distance to current_price
                sorted_supports = sorted(
                    support_resistance.support_levels, 
                    key=lambda x: abs(x - current_price)
                )
                nearest_support = float(sorted_supports[0])

                if current_low < nearest_support:
                    
                    # Filter: Must be consolidating OR have massive volume surge
                    if not is_consolidating and not has_surge:
                        logger.info(
                            f"‚è≠Ô∏è Bearish breakdown ignored (No consolidation/surge) | "
                            f"Vol: {surge_ratio:.1f}x"
                        )
                        return None
                        
                    mtf_ok = (
                        trend_dir == "DOWN"
                        and rsi_15 <= MAX_RSI_BEARISH
                    )

                    if not mtf_ok:
                        logger.info(
                            "‚è≠Ô∏è  Bearish breakdown ignored (MTF filter) | "
                            f"Trend15m: {trend_dir} | RSI15: {rsi_15:.1f}"
                        )
                    else:
                        logger.info(
                            "üìâ Bearish breakdown candidate | "
                            f"Price: {current_price:.2f} < S: {nearest_support:.2f} | "
                            f"Consolidation: {is_consolidating} | Surge: {has_surge}"
                        )

                        atr = support_resistance.atr
                        sl = current_high + (atr * ATR_SL_MULTIPLIER)
                        
                        # Strong Trend Logic
                        is_strong_trend = (
                            has_surge 
                            and trend_dir == "DOWN" 
                            and rsi_15 <= 40 
                            and rsi_5 <= 40
                        )
                        
                        # Calculate Multi-Targets
                        tp1, tp2, tp3 = self._calculate_multi_targets(
                            current_price, sl, "SHORT", support_resistance, is_strong_trend
                        )
                        
                        risk_reward = (current_price - tp1) / max(
                            sl - current_price, 1e-6
                        )

                        # Confidence Scoring
                        confidence = 60.0
                        if has_surge:
                            confidence += 10
                        if is_consolidating:
                            confidence += 10
                        if rsi_5 <= MAX_RSI_BEARISH:
                            confidence += 5
                        if trend_dir == "DOWN":
                            confidence += 10
                        if risk_reward >= MIN_RISK_REWARD_RATIO:
                            confidence += 5
                        # NEW: ORB boost
                        if is_orb_breakout and orb_direction == "BEARISH":
                            confidence += orb_boost

                        confidence = min(confidence, 95.0)

                        breakout_signal = Signal(
                            signal_type=SignalType.BEARISH_BREAKOUT,
                            instrument=self.instrument,
                            timeframe="5MIN",
                            price_level=nearest_support,
                            entry_price=current_price,
                            stop_loss=sl,
                            take_profit=tp1,
                            take_profit_2=tp2,
                            take_profit_3=tp3,
                            confidence=confidence,
                            volume_confirmed=has_surge,
                            momentum_confirmed=(
                                rsi_5 <= MAX_RSI_BEARISH
                            ),
                            risk_reward_ratio=risk_reward,
                            timestamp=pd.Timestamp.now(),
                            description=(
                                f"Bearish breakdown at {nearest_support:.2f} | "
                                f"RR: {risk_reward:.2f} | "
                                f"Vol Surge: {has_surge} | Consolidation: {is_consolidating}"
                                f"{' | ORB Breakout' if is_orb_breakout and orb_direction == 'BEARISH' else ''}"
                            ),
                            atr=atr,
                            debug_info={
                                "surge_ratio": surge_ratio,
                                "is_consolidating": is_consolidating,
                                "rsi_5": rsi_5,
                                "rsi_15": rsi_15,
                                "trend_dir": trend_dir,
                                "atr": atr,
                            },
                        )

            return breakout_signal

        except Exception as e:
            logger.error(f"‚ùå Breakout detection failed: {str(e)}")
            return None

    # =====================================================================
    # FALSE BREAKOUT & RETEST
    # =====================================================================

    def detect_false_breakout(
        self,
        df: pd.DataFrame,
        breakout_level: float,
        direction: str,
    ) -> Tuple[bool, Dict]:
        """
        Detect false breakout (price fails to hold beyond level).

        Args:
            df: 5m OHLCV DataFrame
            breakout_level: breakout price level (support/resistance)
            direction: "UP" for bullish breakout, "DOWN" for bearish

        Returns:
            (is_false, details_dict)
        """
        details = {
            "retracement_pct": 0.0,
            "weak_volume": False,
            "rejection_candles": 0,
        }

        try:
            if df is None or df.empty:
                return False, details

            recent = df.tail(3).copy()
            if len(recent) < 2:
                return False, details

            vol_confirmed, vol_ratio, _ = self.check_volume_confirmation(df)
            weak_volume = not vol_confirmed

            false_breakout = False
            rejection_candles = 0
            retracement_pct = 0.0

            if direction.upper() == "UP":
                for idx in recent.index[1:]:
                    close_price = float(recent.loc[idx, "close"])
                    if close_price < breakout_level:
                        rejection_candles += 1
                        retracement_pct = (
                            (breakout_level - close_price)
                            / breakout_level
                            * 100.0
                        )

                if (
                    rejection_candles > 0
                    and retracement_pct >= FALSE_BREAKOUT_RETRACEMENT
                ):
                    false_breakout = True

            elif direction.upper() == "DOWN":
                for idx in recent.index[1:]:
                    close_price = float(recent.loc[idx, "close"])
                    if close_price > breakout_level:
                        rejection_candles += 1
                        retracement_pct = (
                            (close_price - breakout_level)
                            / breakout_level
                            * 100.0
                        )

                if (
                    rejection_candles > 0
                    and retracement_pct >= FALSE_BREAKOUT_RETRACEMENT
                ):
                    false_breakout = True

            if false_breakout and weak_volume:
                logger.warning(
                    "‚ö†Ô∏è  FALSE BREAKOUT detected | "
                    f"Dir: {direction} | Level: {breakout_level:.2f} | "
                    f"Retrace: {retracement_pct:.2f}% | "
                    f"Vol weak (ratio: {vol_ratio:.2f}x)"
                )
            elif false_breakout:
                logger.warning(
                    "‚ö†Ô∏è  FALSE BREAKOUT detected (price action) | "
                    f"Dir: {direction} | Level: {breakout_level:.2f} | "
                    f"Retrace: {retracement_pct:.2f}%"
                )

            details.update(
                {
                    "retracement_pct": retracement_pct,
                    "weak_volume": weak_volume,
                    "rejection_candles": rejection_candles,
                }
            )
            return false_breakout, details

        except Exception as e:
            logger.error(f"‚ùå False breakout detection failed: {str(e)}")
            return False, details

    def detect_retest_setup(
        self, 
        df: pd.DataFrame, 
        support_resistance: TechnicalLevels,
        higher_tf_context: Dict = None
    ) -> Optional[Signal]:
        """
        Detect retest setup with role reversal logic.
        
        Properly identifies:
        - Support retest: Price above level (or broke above and pulled back)
        - Resistance retest: Price below level (or broke below and bounced)
        - Role reversal: Former resistance becomes support after breakout
        """
        try:
            if df is None or df.empty or len(df) < 10:
                return None

            current = df.iloc[-1]
            current_price = float(current["close"])
            
            # Look back to check for recent breakouts (Increased to 50 bars / ~4 hours)
            # to capture breakouts that happened earlier in the session
            recent_bars = df.tail(50)
            recent_highs = recent_bars["high"].values
            recent_lows = recent_bars["low"].values

            candidate_levels = (
                support_resistance.support_levels[:3]
                + support_resistance.resistance_levels[:3]
            )

            for level in candidate_levels:
                distance_pct = abs(current_price - level) / level * 100.0
                if distance_pct <= RETEST_ZONE_PERCENT:
                    
                    # ====================
                    # Determine Role Reversal
                    # ====================
                    # Check if price recently broke through this level
                    broke_above = any(recent_highs > level * 1.001)  # 0.1% buffer
                    broke_below = any(recent_lows < level * 0.999)   # 0.1% buffer
                    
                    # Current position
                    price_above_level = current_price > level
                    
                    # ====================
                    # Retest Logic
                    # ====================
                    signal_type = None
                    description = ""
                    is_long = False
                    
                    # SUPPORT RETEST scenarios:
                    # 1. Price above level AND broke above recently (pullback to new support)
                    # 2. Price hovering at support from below
                    if price_above_level:
                        if broke_above:
                            # Role reversal: former resistance now support
                            signal_type = SignalType.SUPPORT_BOUNCE
                            description = f"Support retest at {level:.2f} (former resistance, role reversal)"
                            is_long = True
                        else:
                            # Regular support bounce
                            signal_type = SignalType.SUPPORT_BOUNCE
                            description = f"Support retest at {level:.2f}"
                            is_long = True
                    
                    # RESISTANCE RETEST scenarios:
                    # 1. Price below level AND broke below recently (bounce to new resistance)
                    # 2. Price testing resistance from below
                    else:  # price_above_level == False
                        if broke_below:
                            # Role reversal: former support now resistance
                            signal_type = SignalType.RESISTANCE_BOUNCE
                            description = f"Resistance retest at {level:.2f} (former support, role reversal)"
                            is_long = False
                        else:
                            # Regular resistance test
                            signal_type = SignalType.RESISTANCE_BOUNCE
                            description = f"Resistance retest at {level:.2f}"
                            is_long = False
                    
                    if signal_type is None:
                        continue
                    
                    logger.info(
                        f"üéØ RETEST SETUP | {description} | "
                        f"Price: {current_price:.2f} | Level: {level:.2f} | "
                        f"Dist: {distance_pct:.3f}%"
                    )

                    atr = support_resistance.atr
                    
                    # ====================
                    # Entry, SL, TP Logic
                    # ====================
                    
                    # Determine Strong Trend
                    trend_15m = higher_tf_context.get("trend_direction", "FLAT") if higher_tf_context else "FLAT"
                    rsi_15 = float(higher_tf_context.get("rsi_15", 50)) if higher_tf_context else 50.0
                    
                    is_strong_trend = False
                    if is_long:
                        is_strong_trend = trend_15m == "UP" and rsi_15 >= 55
                    else:
                        is_strong_trend = trend_15m == "DOWN" and rsi_15 <= 45

                    # ====================
                    # Entry, SL, TP Logic
                    # ====================
                    if is_long:
                        # LONG: Support retest
                        entry_price = current_price
                        stop_loss = level - (atr * 0.5)  # SL below support
                        
                        tp1, tp2, tp3 = self._calculate_multi_targets(
                            entry_price, stop_loss, "LONG", support_resistance, is_strong_trend
                        )
                    
                    else:
                        # SHORT: Resistance retest
                        entry_price = current_price
                        stop_loss = level + (atr * 0.5)  # SL above resistance
                        
                        tp1, tp2, tp3 = self._calculate_multi_targets(
                            entry_price, stop_loss, "SHORT", support_resistance, is_strong_trend
                        )
                    
                    # Calculate R:R using T1
                    risk = abs(entry_price - stop_loss)
                    reward = abs(tp1 - entry_price)
                    rr = reward / risk if risk > 0 else 0
                    
                    # Skip if R:R too low
                    if round(rr, 2) < MIN_RISK_REWARD_RATIO:
                        logger.info(f"‚è≠Ô∏è Skipping retest - poor R:R ({rr:.2f}) < {MIN_RISK_REWARD_RATIO}")
                        continue

                    # ====================
                    # Dynamic Confidence Scoring
                    # ====================
                    confidence = 50.0  # Base Score
                    
                    if higher_tf_context:
                        trend_15m = higher_tf_context.get("trend_direction", "FLAT")
                        rsi_15 = float(higher_tf_context.get("rsi_15", 50))
                        price_above_vwap = higher_tf_context.get("price_above_vwap", False)
                        price_above_ema20 = higher_tf_context.get("price_above_ema20", False)
                        
                        # 1. Trend Alignment (+10%)
                        if (is_long and trend_15m == "UP") or \
                           (not is_long and trend_15m == "DOWN"):
                            confidence += 10
                            
                        # 2. Moving Average Support (+5%)
                        if (is_long and price_above_vwap) or \
                           (not is_long and not price_above_vwap):
                            confidence += 5
                            
                        # 3. RSI Confirmation (+5%)
                        if (is_long and rsi_15 > 50) or (not is_long and rsi_15 < 50):
                            confidence += 5
                            
                        # 4. Key Level Confluence (+5%)
                        # Check if level matches PDH/PDL or ORB High/Low
                        pdh = support_resistance.pdh
                        pdl = support_resistance.pdl
                        orb_high = higher_tf_context.get("orb_high", 0)
                        orb_low = higher_tf_context.get("orb_low", 0)
                        
                        confluence_level = False
                        for key_lvl in [pdh, pdl, orb_high, orb_low]:
                            if key_lvl > 0 and abs(level - key_lvl) < (level * 0.002):
                                confluence_level = True
                                break
                        
                        if confluence_level:
                            confidence += 5

                    # 5. Role Reversal (+10%) - Stronger than simple touch
                    if (is_long and description and "role reversal" in description) or \
                       (not is_long and description and "role reversal" in description):
                        confidence += 10
                        
                    # 6. High R:R (+5%)
                    if rr >= 2.0:
                        confidence += 5
                        
                    confidence = min(confidence, 95.0)

                    return Signal(
                        signal_type=signal_type,
                        instrument=self.instrument,
                        timeframe="5MIN",
                        price_level=level,
                        entry_price=entry_price,
                        stop_loss=stop_loss,
                        take_profit=tp1,
                        take_profit_2=tp2,
                        take_profit_3=tp3,
                        confidence=confidence,
                        volume_confirmed=False,
                        momentum_confirmed=False,
                        risk_reward_ratio=rr,
                        timestamp=pd.Timestamp.now(),
                        description=description,
                        atr=atr,
                        debug_info={
                            "distance_pct": distance_pct,
                            "broke_above": broke_above,
                            "broke_below": broke_below,
                            "price_above_level": price_above_level,
                            "is_role_reversal": "role reversal" in description,
                            "is_strong_trend": is_strong_trend
                        },
                    )

            return None

        except Exception as e:
            logger.error(f"‚ùå Retest detection failed: {str(e)}")
            return None

    def detect_inside_bar(
        self,
        df: pd.DataFrame,
        higher_tf_context: Dict,
        support_resistance: TechnicalLevels
    ) -> Optional[Signal]:
        """
        Detect high-probability inside bar setup with full context awareness.
        
        Only fires when:
        - Pattern is valid (size, volume)
        - Trend alignment (15m + VWAP + 20 EMA + prev day)
        - Logical target with good R:R
        - Breakout confirmed (price beyond mother bar range)
        
        Args:
            df: 5m OHLCV data
            higher_tf_context: Contains 15m trend, VWAP, 20 EMA, prev day trend
            support_resistance: S/R levels for smart targeting
        """
        try:
            if df is None or len(df) < 2:
                return None

            prev_candle = df.iloc[-2]  # Mother bar
            curr_candle = df.iloc[-1]  # Inside bar (current)

            # ====================
            # 1. Pattern Detection
            # ====================
            is_inside = (
                curr_candle["high"] < prev_candle["high"]
                and curr_candle["low"] > prev_candle["low"]
            )

            if not is_inside:
                return None

            logger.info("üìä INSIDE BAR PATTERN DETECTED | Validating setup...")

            # ====================
            # 2. Pattern Quality Check
            # ====================
            is_valid, rejection_reason = self._validate_inside_bar_pattern(
                prev_candle, curr_candle, df
            )
            
            if not is_valid:
                logger.info(f"‚è≠Ô∏è Inside bar rejected: {rejection_reason}")
                return None

            # ====================
            # 3. Extract Context
            # ====================
            trend_15m = higher_tf_context.get("trend_direction", "FLAT")
            price_above_vwap = higher_tf_context.get("price_above_vwap", False)
            price_above_ema20 = higher_tf_context.get("price_above_ema20", False)
            vwap_slope = higher_tf_context.get("vwap_slope", "FLAT")
            prev_day_trend = higher_tf_context.get("prev_day_trend", "FLAT")
            vwap_5m = higher_tf_context.get("vwap_5m", 0.0)
            ema_20_5m = higher_tf_context.get("ema_20_5m", 0.0)
            
            current_price = float(curr_candle["close"])
            rsi_5 = self._calculate_rsi(df)

            # ====================
            # 4. Determine Directional Bias
            # ====================
            direction = None
            signal_type = None
            
            # LONG bias conditions
            long_conditions = [
                price_above_vwap,
                price_above_ema20,
                trend_15m == "UP" or prev_day_trend == "UP",
            ]
            
            # SHORT bias conditions
            short_conditions = [
                not price_above_vwap,
                not price_above_ema20,
                trend_15m == "DOWN" or prev_day_trend == "DOWN",
            ]
            
            # Require at least 2 of 3 conditions
            if sum(long_conditions) >= 2:
                direction = "LONG"
                signal_type = SignalType.INSIDE_BAR
            elif sum(short_conditions) >= 2:
                direction = "SHORT"
                signal_type = SignalType.INSIDE_BAR
            else:
                logger.info(
                    "‚è≠Ô∏è Inside bar skipped - no clear directional bias | "
                    f"VWAP: {price_above_vwap} | 20EMA: {price_above_ema20} | "
                    f"Trend15m: {trend_15m} | PrevDay: {prev_day_trend}"
                )
                return None

            logger.info(f"‚úÖ Directional bias: {direction}")

            # ====================
            # 5. Breakout Entry Logic
            # ====================
            # Check if breakout has actually happened
            if direction == "LONG":
                # For LONG, need close ABOVE mother bar high
                if current_price <= prev_candle["high"]:
                    logger.debug(
                        "‚è≥ Inside bar LONG setup pending - waiting for breakout above mother bar high"
                    )
                    return None  # Wait for actual breakout
                
                entry_price = float(prev_candle["high"])
                sl_price = float(prev_candle["low"])
                
            else:  # SHORT
                # For SHORT, need close BELOW mother bar low
                if current_price >= prev_candle["low"]:
                    logger.debug(
                        "‚è≥ Inside bar SHORT setup pending - waiting for breakout below mother bar low"
                    )
                    return None  # Wait for actual breakout
                
                entry_price = float(prev_candle["low"])
                sl_price = float(prev_candle["high"])

            # Check if mother bar is too wide - use 50% level for SL
            mother_range = abs(prev_candle["high"] - prev_candle["low"])
            atr = support_resistance.atr
            if mother_range > atr * 2.0:
                logger.info(f"‚ö†Ô∏è Wide mother bar detected - using 50% SL level")
                if direction == "LONG":
                    sl_price = prev_candle["low"] + (mother_range * 0.5)
                else:
                    sl_price = prev_candle["high"] - (mother_range * 0.5)

            # ====================
            # 6. Volume Confirmation
            # ====================
            vol_confirmed, vol_ratio, _ = self.check_volume_confirmation(df)

            # ====================
            # 7. Smart Target Calculation
            # ====================
            is_strong_trend = vol_confirmed
            
            tp1, tp2, tp3 = self._calculate_multi_targets(
                entry_price, sl_price, direction, support_resistance, is_strong_trend
            )
            
            risk = abs(entry_price - sl_price)
            reward = abs(tp1 - entry_price)
            rr_ratio = reward / risk if risk > 0 else 0
            
            if tp1 == 0 or rr_ratio < 1.0:
                logger.info(f"‚è≠Ô∏è Inside bar skipped - no valid target or poor R:R ({rr:.2f} < {MIN_RISK_REWARD_RATIO})")
                return None

            # ====================
            # 8. Confidence Scoring
            # ====================
            confidence = 60.0
            
            # VWAP alignment
            if (direction == "LONG" and price_above_vwap) or \
               (direction == "SHORT" and not price_above_vwap):
                confidence += 10
                
            # 20 EMA alignment
            if (direction == "LONG" and price_above_ema20) or \
               (direction == "SHORT" and not price_above_ema20):
                confidence += 10
                
            # 15m trend alignment
            if (direction == "LONG" and trend_15m == "UP") or \
               (direction == "SHORT" and trend_15m == "DOWN"):
                confidence += 10
                
            # Previous day trend alignment
            if (direction == "LONG" and prev_day_trend == "UP") or \
               (direction == "SHORT" and prev_day_trend == "DOWN"):
                confidence += 5
                
            # Volume confirmation
            if vol_confirmed:
                confidence += 10
                
            # Good R:R
            if rr_ratio >= 2.0:
                confidence += 10
                
            # RSI alignment
            if (direction == "LONG" and rsi_5 >= 50) or \
               (direction == "SHORT" and rsi_5 <= 50):
                confidence += 5

            confidence = min(confidence, 95.0)

            # ====================
            # 9. Build Description
            # ====================
            description = (
                f"Inside bar {direction} breakout | "
                f"VWAP: {'‚úì' if ((direction=='LONG' and price_above_vwap) or (direction=='SHORT' and not price_above_vwap)) else '‚úó'} | "
                f"20EMA: {'‚úì' if ((direction=='LONG' and price_above_ema20) or (direction=='SHORT' and not price_above_ema20)) else '‚úó'} | "
                f"15m: {trend_15m} | PrevDay: {prev_day_trend}"
            )

            logger.info(
                f"üéØ HIGH-QUALITY INSIDE BAR {direction} | "
                f"Entry: {entry_price:.2f} | SL: {sl_price:.2f} | T1: {tp1:.2f} | "
                f"R:R: {rr_ratio:.2f} | Conf: {confidence:.0f}%"
            )

            return Signal(
                signal_type=signal_type,
                instrument=self.instrument,
                timeframe="5MIN",
                price_level=float(curr_candle["close"]),
                entry_price=entry_price,
                stop_loss=sl_price,
                take_profit=tp1,
                take_profit_2=tp2,
                take_profit_3=tp3,
                confidence=confidence,
                volume_confirmed=vol_confirmed,
                momentum_confirmed=(rsi_5 >= 50 if direction == "LONG" else rsi_5 <= 50),
                risk_reward_ratio=rr_ratio,
                timestamp=pd.Timestamp.now(),
                description=description,
                debug_info={
                    "direction": direction,
                    "mother_high": float(prev_candle["high"]),
                    "mother_low": float(prev_candle["low"]),
                    "inside_high": float(curr_candle["high"]),
                    "inside_low": float(curr_candle["low"]),
                    "trend_15m": trend_15m,
                    "vwap_5m": vwap_5m,
                    "ema_20_5m": ema_20_5m,
                    "prev_day_trend": prev_day_trend,
                    "rsi_5": rsi_5,
                    "vol_ratio": vol_ratio,
                    "is_strong_trend": is_strong_trend
                },
            )

        except Exception as e:
            logger.error(f"‚ùå Inside bar detection failed: {str(e)}")
            return None

    def _validate_inside_bar_pattern(
        self,
        prev_candle: pd.Series,
        curr_candle: pd.Series,
        df: pd.DataFrame
    ) -> Tuple[bool, str]:
        """
        Validate inside bar pattern quality.
        
        Returns:
            (is_valid, rejection_reason)
        """
        try:
            mother_range = prev_candle['high'] - prev_candle['low']
            inside_range = curr_candle['high'] - curr_candle['low']
            
            # Check if inside bar is not too tiny
            if inside_range < mother_range * 0.2:
                return False, "Inside bar too small (< 20% of mother bar)"
            
            # Check if inside bar is not too large  
            if inside_range > mother_range * 0.8:
                return False, "Inside bar too large (> 80% of mother bar)"
            
            # Check if mother bar is not too wide
            atr = self._calculate_atr(df)
            if mother_range > atr * 2.5:
                return False, f"Mother bar too wide ({mother_range:.2f} > 2.5x ATR)"
            
            # Check volume (if available)
            if df['volume'].sum() > 0:
                avg_vol = df['volume'].tail(20).mean()
                mother_vol = prev_candle['volume']
                curr_vol = curr_candle['volume']
                
                # Prefer volume on mother bar or breakout bar
                if mother_vol < avg_vol * 0.7 and curr_vol < avg_vol * 0.7:
                    return False, "Low volume on both mother and inside bar"
            
            return True, ""
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Pattern validation failed: {str(e)}")
            return True, ""  # Default to valid if check fails

    def _calculate_inside_bar_targets(
        self,
        entry: float,
        sl: float,
        direction: str,
        support_resistance: TechnicalLevels,
        current_price: float
    ) -> Tuple[Optional[float], float, str]:
        """
        Calculate intelligent take profit using S/R and PDH/PDL.
        
        Args:
            entry: Entry price
            sl: Stop loss
            direction: "LONG" or "SHORT"
            support_resistance: S/R levels
            current_price: Current market price
            
        Returns:
            (take_profit, risk_reward_ratio, target_reason)
        """
        try:
            risk = abs(entry - sl)
            atr = support_resistance.atr
            
            # Find nearest logical target
            target = None
            target_reason = ""
            
            if direction == "LONG":
                # Look for resistance above current price
                candidates = []
                
                # Check resistance clusters
                for r in support_resistance.resistance_levels:
                    if r > current_price:
                        candidates.append((r, "Resistance"))
                
                # Check PDH
                if support_resistance.pdh > current_price:
                    candidates.append((support_resistance.pdh, "PDH"))
                
                # Sort by distance and pick nearest
                if candidates:
                    candidates.sort(key=lambda x: abs(x[0] - current_price))
                    target, target_reason = candidates[0]
                else:
                    # Fallback to ATR-based
                    target = entry + (atr * 2.0)
                    target_reason = "ATR 2.0x"
                    
            else:  # SHORT
                # Look for support below current price
                candidates = []
                
                # Check support clusters
                for s in support_resistance.support_levels:
                    if s < current_price:
                        candidates.append((s, "Support"))
                
                # Check PDL
                if support_resistance.pdl < current_price and support_resistance.pdl > 0:
                    candidates.append((support_resistance.pdl, "PDL"))
                
                # Sort by distance and pick nearest
                if candidates:
                    candidates.sort(key=lambda x: abs(x[0] - current_price))
                    target, target_reason = candidates[0]
                else:
                    # Fallback to ATR-based
                    target = entry - (atr * 2.0)
                    target_reason = "ATR 2.0x"
            
            # Calculate R:R
            if target:
                reward = abs(target - entry)
                rr = reward / risk if risk > 0 else 0
                
                # Skip if R:R too low
                if rr < 1.5:
                    logger.info(f"‚è≠Ô∏è Skipping inside bar - poor R:R ({rr:.2f} < {MIN_RISK_REWARD_RATIO})")
                    return None, 0.0, "R:R < 1.5"
                
                return target, rr, target_reason
            
            return None, 0.0, "No logical target found"
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Target calculation failed: {str(e)}")
            # Fallback to simple ATR-based
            if direction == "LONG":
                target = entry + (risk * 2.0)
            else:
                target = entry - (risk * 2.0)
            return target, 2.0, "ATR Fallback"

    # =====================================================================
    # INDICATOR CALCULATIONS
    # =====================================================================

    def _calculate_rsi(
        self, df: pd.DataFrame, period: int = RSI_PERIOD
    ) -> float:
        """Calculate RSI (Relative Strength Index)."""
        try:
            delta = df["close"].diff()
            gain = delta.where(delta > 0, 0.0).rolling(period).mean()
            loss = -delta.where(delta < 0, 0.0).rolling(period).mean()

            if loss.iloc[-1] == 0 or pd.isna(loss.iloc[-1]):
                return 50.0

            rs = gain / loss
            rsi = 100.0 - (100.0 / (1.0 + rs))
            return float(rsi.iloc[-1])

        except Exception:
            return 50.0

    def _calculate_atr(
        self, df: pd.DataFrame, period: int = ATR_PERIOD
    ) -> float:
        """Calculate Average True Range."""
        try:
            high_low = df["high"] - df["low"]
            high_close = (df["high"] - df["close"].shift()).abs()
            low_close = (df["low"] - df["close"].shift()).abs()

            ranges = pd.concat(
                [high_low, high_close, low_close], axis=1
            )
            true_range = ranges.max(axis=1)
            atr = true_range.rolling(period).mean()

            return float(atr.iloc[-1])

        except Exception:
            return 0.0

    def _calculate_volatility_score(self, df: pd.DataFrame) -> float:
        """Calculate volatility score (0-100)."""
        try:
            returns = df["close"].pct_change()
            volatility = float(returns.std() * 100.0)
            score = min(volatility * 100.0, 100.0)
            return score
        except Exception:
            return 50.0

    def _calculate_vwap(self, df: pd.DataFrame) -> Tuple[pd.Series, float, str]:
        """
        Calculate intraday VWAP (Volume Weighted Average Price).
        Resets at day boundaries for intraday analysis.
        
        Returns:
            (vwap_series, current_vwap, vwap_slope)
        """
        try:
            df = df.copy()
            
            # Check if we have volume data
            if df['volume'].sum() == 0:
                logger.debug("‚ö†Ô∏è No volume data for VWAP - using simple average")
                vwap_series = df['close']
                return vwap_series, float(vwap_series.iloc[-1]), "FLAT"
            
            # Calculate typical price
            df['typical_price'] = (df['high'] + df['low'] + df['close']) / 3.0
            
            # Identify day boundaries (reset VWAP at each day)
            df['date'] = pd.to_datetime(df.index).date
            
            # Calculate VWAP for each day
            vwap_list = []
            for date, group in df.groupby('date'):
                group = group.copy()
                group['cum_vol'] = group['volume'].cumsum()
                group['cum_vol_price'] = (group['typical_price'] * group['volume']).cumsum()
                group['vwap'] = group['cum_vol_price'] / group['cum_vol']
                vwap_list.append(group['vwap'])
            
            vwap_series = pd.concat(vwap_list)
            current_vwap = float(vwap_series.iloc[-1])
            
            # Determine VWAP slope (last 5 bars)
            if len(vwap_series) >= 5:
                vwap_slope = "UP" if vwap_series.iloc[-1] > vwap_series.iloc[-5] else "DOWN"
            else:
                vwap_slope = "FLAT"
            
            logger.debug(f"VWAP: {current_vwap:.2f} | Slope: {vwap_slope}")
            return vwap_series, current_vwap, vwap_slope
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è VWAP calculation failed: {str(e)}")
            # Fallback to close price
            return df['close'], float(df['close'].iloc[-1]), "FLAT"

    def _get_previous_day_trend(self, df: pd.DataFrame) -> str:
        """
        Determine previous day's trend based on daily data.
        
        Args:
            df: DataFrame with at least 2 days of data
            
        Returns:
            "UP" / "DOWN" / "FLAT"
        """
        try:
            if df is None or len(df) < 2:
                return "FLAT"
            
            # Get yesterday's candle (second to last)
            prev_day = df.iloc[-2]
            
            # Simple trend: close vs open
            if prev_day['close'] > prev_day['open'] * 1.002:  # 0.2% threshold
                return "UP"
            elif prev_day['close'] < prev_day['open'] * 0.998:
                return "DOWN"
            else:
                return "FLAT"
                
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Previous day trend calc failed: {str(e)}")
            return "FLAT"

    def detect_pin_bar(
        self,
        df: pd.DataFrame,
        support_resistance: TechnicalLevels,
        higher_tf_context: Dict,
    ) -> Optional[Signal]:
        """
        Detect pin bar (rejection candle with long wick).
        
        Bullish Pin Bar (Hammer):
            - Long lower wick (>60% of range)
            - Small body (<30% of range)
            - At support level
            - Uptrend or reversal setup
        
        Bearish Pin Bar (Shooting Star):
            - Long upper wick (>60% of range)
            - Small body (<30% of range)
            - At resistance level
            - Downtrend or reversal setup
        """
        try:
            if df is None or df.empty or len(df) < 20:
                return None

            current = df.iloc[-1]
            current_open = float(current["open"])
            current_close = float(current["close"])
            current_high = float(current["high"])
            current_low = float(current["low"])
            current_price = current_close

            # Calculate candle components
            body_size = abs(current_close - current_open)
            upper_wick = current_high - max(current_open, current_close)
            lower_wick = min(current_open, current_close) - current_low
            total_range = current_high - current_low

            if total_range < 0.0001:  # Avoid division by zero
                return None

            body_pct = (body_size / total_range)
            upper_wick_pct = (upper_wick / total_range)
            lower_wick_pct = (lower_wick / total_range)

            atr = support_resistance.atr
            trend_dir = higher_tf_context.get("trend_direction", "FLAT")
            rsi_15 = float(higher_tf_context.get("rsi_15", 50.0))

            # =============================
            # BULLISH PIN BAR (Hammer)
            # =============================
            if lower_wick_pct > 0.6 and body_pct < 0.3:
                # Check if at support level
                at_support = False
                support_level = None
                
                for level in support_resistance.support_levels[:3]:
                    distance_pct = abs(current_low - level) / level * 100
                    if distance_pct <= 0.5:  # Within 0.5% of support
                        at_support = True
                        support_level = level
                        break
                
                # Also check if near PDL
                if not at_support and support_resistance.pdl > 0:
                    distance_pct = abs(current_low - support_resistance.pdl) / support_resistance.pdl * 100
                    if distance_pct <= 0.5:
                        at_support = True
                        support_level = support_resistance.pdl

                if at_support:
                    # Logic Update: Allow counter-trend IF confirmed by RSI/Volume
                    is_valid_setup = False
                    setup_reason = ""
                    
                    if DEBUG_MODE:
                         logger.debug(f"DEBUG: PinBar at Support. Trend: {trend_dir}, RSI: {rsi_15}")
                    
                    if trend_dir in ["UP", "FLAT"]:
                        is_valid_setup = True
                        setup_reason = "Trend Alignment"
                    elif trend_dir == "DOWN":
                        # Counter-trend checks
                        # Require Oversold RSI OR Volume Surge
                        vol_surge, _, _ = self._detect_volume_surge(df)
                        if rsi_15 < 40:
                            is_valid_setup = True
                            setup_reason = f"Counter-Trend (RSI {rsi_15:.1f} Oversold)"
                        elif vol_surge:
                            is_valid_setup = True
                            setup_reason = "Counter-Trend (Volume Surge)"
                            
                    if not is_valid_setup:
                         if DEBUG_MODE:
                             logger.debug(f"DEBUG: Setup Invalid. RSI {rsi_15} not < 40 and No Surge")

                    if is_valid_setup:
                        logger.info(
                            f"üî® BULLISH PIN BAR detected | {setup_reason} | "
                            f"Lower wick: {lower_wick_pct*100:.1f}% | "
                            f"At support: {support_level:.2f}"
                        )

                        entry_price = current_close
                        stop_loss = current_low - (atr * 0.5)
                        
                        # Target: Next resistance or PDH
                        target = None
                        for r in support_resistance.resistance_levels:
                            if r > current_price:
                                target = r
                                break
                        
                        if not target and support_resistance.pdh > current_price:
                            target = support_resistance.pdh
                        
                        if not target:
                            target = current_price + (atr * 3.0)
                        
                        risk = abs(entry_price - stop_loss)
                        reward = abs(target - entry_price)
                        rr = reward / risk if risk > 0 else 0
                        
                        if rr < 1.5:
                            logger.info(f"‚è≠Ô∏è Bullish pin bar skipped: Poor R:R ({rr:.2f})")
                            return None

                        confidence = 65.0
                        if trend_dir == "UP":
                            confidence += 10
                        if rsi_15 < 40:  # Deep Oversold
                            confidence += 10
                        elif rsi_15 < 50:
                            confidence += 5
                        if lower_wick_pct > 0.7:  # Very long wick
                            confidence += 5

                        return Signal(
                            signal_type=SignalType.BULLISH_PIN_BAR,
                            instrument=self.instrument,
                            timeframe="5MIN",
                            price_level=support_level,
                            entry_price=entry_price,
                            stop_loss=stop_loss,
                            take_profit=target,
                            confidence=min(confidence, 90.0),
                            volume_confirmed=False,
                            momentum_confirmed=(rsi_15 < 50),
                            risk_reward_ratio=rr,
                            timestamp=pd.Timestamp.now(),
                            description=(
                                f"Bullish pin bar at {support_level:.2f} | {setup_reason} | "
                                f"Lower wick: {lower_wick_pct*100:.0f}% | RR: {rr:.1f}"
                            ),
                            debug_info={
                                "lower_wick_pct": lower_wick_pct,
                                "body_pct": body_pct,
                                "trend_dir": trend_dir,
                                "rsi_15": rsi_15,
                            },
                        )

            # =============================
            # BEARISH PIN BAR (Shooting Star)
            # =============================
            if upper_wick_pct > 0.6 and body_pct < 0.3:
                # Check if at resistance level
                at_resistance = False
                resistance_level = None
                
                for level in support_resistance.resistance_levels[:3]:
                    distance_pct = abs(current_high - level) / level * 100
                    if distance_pct <= 0.5:  # Within 0.5% of resistance
                        at_resistance = True
                        resistance_level = level
                        break
                
                # Also check if near PDH
                if not at_resistance and support_resistance.pdh > 0:
                    distance_pct = abs(current_high - support_resistance.pdh) / support_resistance.pdh * 100
                    if distance_pct <= 0.5:
                        at_resistance = True
                        resistance_level = support_resistance.pdh

                if at_resistance:
                    # Logic Update: Allow counter-trend IF confirmed by RSI/Volume
                    is_valid_setup = False
                    setup_reason = ""
                    
                    if trend_dir in ["DOWN", "FLAT"]:
                        is_valid_setup = True
                        setup_reason = "Trend Alignment"
                    elif trend_dir == "UP":
                        # Counter-trend checks
                        # Require Overbought RSI OR Volume Surge
                        vol_surge, _, _ = self._detect_volume_surge(df)
                        if rsi_15 > 60:
                            is_valid_setup = True
                            setup_reason = f"Counter-Trend (RSI {rsi_15:.1f} Overbought)"
                        elif vol_surge:
                            is_valid_setup = True
                            setup_reason = "Counter-Trend (Volume Surge)"

                    if is_valid_setup:
                        logger.info(
                            f"‚≠ê BEARISH PIN BAR detected | {setup_reason} | "
                            f"Upper wick: {upper_wick_pct*100:.1f}% | "
                            f"At resistance: {resistance_level:.2f}"
                        )

                        entry_price = current_close
                        stop_loss = current_high + (atr * 0.5)
                        
                        # Target: Next support or PDL
                        target = None
                        for s in support_resistance.support_levels:
                            if s < current_price:
                                target = s
                                break
                        
                        if not target and support_resistance.pdl > 0 and support_resistance.pdl < current_price:
                            target = support_resistance.pdl
                        
                        if not target:
                            target = current_price - (atr * 3.0)
                        
                        risk = abs(stop_loss - entry_price)
                        reward = abs(entry_price - target)
                        rr = reward / risk if risk > 0 else 0
                        
                        if rr < 1.5:
                            logger.info(f"‚è≠Ô∏è Bearish pin bar skipped: Poor R:R ({rr:.2f})")
                            return None

                        confidence = 65.0
                        if trend_dir == "DOWN":
                            confidence += 10
                        if rsi_15 > 60:  # Deep Overbought
                            confidence += 10
                        elif rsi_15 > 50:
                            confidence += 5
                        if upper_wick_pct > 0.7:  # Very long wick
                            confidence += 5

                        return Signal(
                            signal_type=SignalType.BEARISH_PIN_BAR,
                            instrument=self.instrument,
                            timeframe="5MIN",
                            price_level=resistance_level,
                            entry_price=entry_price,
                            stop_loss=stop_loss,
                            take_profit=target,
                            confidence=min(confidence, 90.0),
                            volume_confirmed=False,
                            momentum_confirmed=(rsi_15 > 50),
                            risk_reward_ratio=rr,
                            timestamp=pd.Timestamp.now(),
                            description=(
                                f"Bearish pin bar at {resistance_level:.2f} | {setup_reason} | "
                                f"Upper wick: {upper_wick_pct*100:.0f}% | RR: {rr:.1f}"
                            ),
                            debug_info={
                                "upper_wick_pct": upper_wick_pct,
                                "body_pct": body_pct,
                                "trend_dir": trend_dir,
                                "rsi_15": rsi_15,
                            },
                        )

            return None

        except Exception as e:
            logger.error(f"‚ùå Pin bar detection failed: {str(e)}")
            return None

    def detect_engulfing(
        self,
        df: pd.DataFrame,
        support_resistance: TechnicalLevels,
        higher_tf_context: Dict,
    ) -> Optional[Signal]:
        """
        Detect bullish or bearish engulfing candlestick pattern.
        
        Bullish Engulfing:
            - Previous candle is bearish (red)
            - Current candle is bullish (green)
            - Current candle body completely engulfs previous body
            - At support level or in uptrend
            - Volume confirmation
        
        Bearish Engulfing:
            - Previous candle is bullish (green)
            - Current candle is bearish (red)
            - Current candle body completely engulfs previous body
            - At resistance level or in downtrend
            - Volume confirmation
        """
        try:
            if df is None or df.empty or len(df) < 20:
                return None

            prev = df.iloc[-2]
            current = df.iloc[-1]
            
            prev_open = float(prev["open"])
            prev_close = float(prev["close"])
            prev_high = float(prev["high"])
            prev_low = float(prev["low"])
            
            curr_open = float(current["open"])
            curr_close = float(current["close"])
            curr_high = float(current["high"])
            curr_low = float(current["low"])
            current_price = curr_close

            # Calculate body sizes
            prev_body = abs(prev_close - prev_open)
            curr_body = abs(curr_close - curr_open)
            
            # Require meaningful candles
            if prev_body < 1 or curr_body < 1:
                return None

            atr = support_resistance.atr
            trend_dir = higher_tf_context.get("trend_direction", "FLAT")
            rsi_15 = float(higher_tf_context.get("rsi_15", 50.0))


            # Volume check (current bar should have higher volume)
            vol_surge, surge_ratio, _ = self._detect_volume_surge(df)

            # =============================
            # BULLISH ENGULFING
            # =============================
            is_bullish_engulfing = (
                prev_close < prev_open and  # Previous bearish
                curr_close > curr_open and  # Current bullish
                curr_open <= prev_close and  # Opens at/below prev close
                curr_close >= prev_open      # Closes at/above prev open
            )

            if is_bullish_engulfing:
                # Check if at support level
                at_support = False
                support_level = None
                
                for level in support_resistance.support_levels[:3]:
                    distance_pct = abs(curr_low - level) / level * 100
                    if distance_pct <= 0.5:
                        at_support = True
                        support_level = level
                        break
                
                if not at_support and support_resistance.pdl > 0:
                    distance_pct = abs(curr_low - support_resistance.pdl) / support_resistance.pdl * 100
                    if distance_pct <= 0.5:
                        at_support = True
                        support_level = support_resistance.pdl

                # Require either support level OR uptrend
                if at_support or trend_dir == "UP":
                    # Require volume confirmation
                    if not vol_surge:
                        logger.info(f"‚è≠Ô∏è Bullish engulfing skipped: No volume surge ({surge_ratio:.1f}x)")
                        return None
                    
                    logger.info(
                        f"üü¢ BULLISH ENGULFING detected | "
                        f"Prev: {prev_open:.2f}->{prev_close:.2f} | "
                        f"Curr: {curr_open:.2f}->{curr_close:.2f} | "
                        f"Vol: {surge_ratio:.1f}x"
                    )

                    entry_price = curr_close
                    stop_loss = curr_low - (atr * 0.5)
                    
                    # Target: Next resistance
                    target = None
                    for r in support_resistance.resistance_levels:
                        if r > current_price:
                            target = r
                            break
                    
                    if not target and support_resistance.pdh > current_price:
                        target = support_resistance.pdh
                    
                    if not target:
                        target = current_price + (atr * 3.0)
                    
                    risk = abs(entry_price - stop_loss)
                    reward = abs(target - entry_price)
                    rr = reward / risk if risk > 0 else 0
                    
                    if rr < 1.5:
                        logger.info(f"‚è≠Ô∏è Bullish engulfing skipped: Poor R:R ({rr:.2f})")
                        return None

                    confidence = 70.0
                    if trend_dir == "UP":
                        confidence += 10
                    if at_support:
                        confidence += 5
                    if rsi_15 < 50:
                        confidence += 5
                    if surge_ratio > 2.0:
                        confidence += 5

                    return Signal(
                        signal_type=SignalType.BULLISH_ENGULFING,
                        instrument=self.instrument,
                        timeframe="5MIN",
                        price_level=support_level if at_support else curr_low,
                        entry_price=entry_price,
                        stop_loss=stop_loss,
                        take_profit=target,
                        confidence=min(confidence, 95.0),
                        volume_confirmed=True,
                        momentum_confirmed=(rsi_15 < 50),
                        risk_reward_ratio=rr,
                        timestamp=pd.Timestamp.now(),
                        description=(
                            f"Bullish engulfing pattern | "
                            f"Vol surge: {surge_ratio:.1f}x | RR: {rr:.1f}"
                        ),
                        debug_info={
                            "surge_ratio": surge_ratio,
                            "engulf_ratio": curr_body / prev_body if prev_body > 0 else 0,
                            "trend_dir": trend_dir,
                            "rsi_15": rsi_15,
                        },
                    )

            # =============================
            # BEARISH ENGULFING
            # =============================
            is_bearish_engulfing = (
                prev_close > prev_open and  # Previous bullish
                curr_close < curr_open and  # Current bearish
                curr_open >= prev_close and  # Opens at/above prev close
                curr_close <= prev_open      # Closes at/below prev open
            )

            if is_bearish_engulfing:
                # Check if at resistance level
                at_resistance = False
                resistance_level = None
                
                for level in support_resistance.resistance_levels[:3]:
                    distance_pct = abs(curr_high - level) / level * 100
                    if distance_pct <= 0.5:
                        at_resistance = True
                        resistance_level = level
                        break
                
                if not at_resistance and support_resistance.pdh > 0:
                    distance_pct = abs(curr_high - support_resistance.pdh) / support_resistance.pdh * 100
                    if distance_pct <= 0.5:
                        at_resistance = True
                        resistance_level = support_resistance.pdh

                # Require either resistance level OR downtrend
                if at_resistance or trend_dir == "DOWN":
                    # Require volume confirmation
                    if not vol_surge:
                        logger.info(f"‚è≠Ô∏è Bearish engulfing skipped: No volume surge ({surge_ratio:.1f}x)")
                        return None
                    
                    logger.info(
                        f"üî¥ BEARISH ENGULFING detected | "
                        f"Prev: {prev_open:.2f}->{prev_close:.2f} | "
                        f"Curr: {curr_open:.2f}->{curr_close:.2f} | "
                        f"Vol: {surge_ratio:.1f}x"
                    )

                    entry_price = curr_close
                    stop_loss = curr_high + (atr * 0.5)
                    
                    # Target: Next support
                    target = None
                    for s in support_resistance.support_levels:
                        if s < current_price:
                            target = s
                            break
                    
                    if not target and support_resistance.pdl > 0 and support_resistance.pdl < current_price:
                        target = support_resistance.pdl
                    
                    if not target:
                        target = current_price - (atr * 3.0)
                    
                    risk = abs(stop_loss - entry_price)
                    reward = abs(entry_price - target)
                    rr = reward / risk if risk > 0 else 0
                    
                    if rr < 1.5:
                        logger.info(f"‚è≠Ô∏è Bearish engulfing skipped: Poor R:R ({rr:.2f})")
                        return None

                    confidence = 70.0
                    if trend_dir == "DOWN":
                        confidence += 10
                    if at_resistance:
                        confidence += 5
                    if rsi_15 > 50:
                        confidence += 5
                    if surge_ratio > 2.0:
                        confidence += 5

                    return Signal(
                        signal_type=SignalType.BEARISH_ENGULFING,
                        instrument=self.instrument,
                        timeframe="5MIN",
                        price_level=resistance_level if at_resistance else curr_high,
                        entry_price=entry_price,
                        stop_loss=stop_loss,
                        take_profit=target,
                        confidence=min(confidence, 95.0),
                        volume_confirmed=True,
                        momentum_confirmed=(rsi_15 > 50),
                        risk_reward_ratio=rr,
                        timestamp=pd.Timestamp.now(),
                        description=(
                            f"Bearish engulfing pattern | "
                            f"Vol surge: {surge_ratio:.1f}x | RR: {rr:.1f}"
                        ),
                        debug_info={
                            "surge_ratio": surge_ratio,
                            "engulf_ratio": curr_body / prev_body if prev_body > 0 else 0,
                            "trend_dir": trend_dir,
                            "rsi_15": rsi_15,
                        },
                    )

            return None

        except Exception as e:
            logger.error(f"‚ùå Engulfing detection failed: {str(e)}")
            return None

    def _is_choppy_session(self, df: pd.DataFrame) -> Tuple[bool, str]:
        """
        Detect if market is choppy/ranging (avoid trading in such conditions).
        
        Returns:
            (is_choppy, reason)
        
        Criteria:
            - ATR < 0.3% of price (very low volatility)
            - Price oscillating around VWAP (4+ crosses in 10 bars)
        """
        try:
            from config.settings import MIN_ATR_PERCENT, MAX_VWAP_CROSSES
            
            if df is None or len(df) < 20:
                return False, ""
            
            current_price = float(df.iloc[-1]["close"])
            atr = self._calculate_atr(df)
            
            # 1. Check ATR (volatility)
            atr_pct = (atr / current_price) * 100
            
            if atr_pct < MIN_ATR_PERCENT:
                return True, f"Low volatility (ATR: {atr_pct:.2f}%)"
            else:
                logger.info(f"‚úÖ Volatility OK | ATR: {atr_pct:.4f}% (> {MIN_ATR_PERCENT}%)")
            
            # 2. Check VWAP oscillation (choppy price action)
            _, vwap, _ = self._calculate_vwap(df)
            recent_closes = df.tail(10)["close"]
            
            # Count VWAP crosses
            crosses = 0
            for i in range(1, len(recent_closes)):
                prev_close = recent_closes.iloc[i-1]
                curr_close = recent_closes.iloc[i]
                
                if (prev_close < vwap and curr_close > vwap) or \
                   (prev_close > vwap and curr_close < vwap):
                    crosses += 1
            
            if crosses >= MAX_VWAP_CROSSES:
                return True, f"Choppy (VWAP crosses: {crosses})"
            
            return False, ""
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Choppy session check failed: {str(e)}")
            return False, ""
    # =====================================================================
    # TOP-LEVEL ANALYSIS WRAPPER (WITH MTF)
    # =====================================================================

    def analyze_with_multi_tf(
        self, df_5m: pd.DataFrame, higher_tf_context: Dict, df_15m: pd.DataFrame = None
    ) -> Dict:
        """
        Full analysis using 5m data + 15m higher timeframe context.
        """
        result = {
            "pdh": None,
            "pdl": None,
            "levels": None,
            "volume_confirmed": False,
            "volume_ratio": 0.0,
            "breakout_signal": None,
            "retest_signal": None,
            "inside_bar_signal": None,
            "pin_bar_signal": None,
            "engulfing_signal": None,
        }

        try:
            if df_5m is None or df_5m.empty:
                logger.error("‚ùå analyze_with_multi_tf: empty 5m data")
                return result

            pdh, pdl = self.calculate_pdh_pdl(df_5m)
            
            # Use 15m data for Support/Resistance if available (Clean Levels)
            # Otherwise fall back to 5m (Noisy but better than nothing)
            sr_source_df = df_15m if df_15m is not None and not df_15m.empty else df_5m
            levels = self.calculate_support_resistance(sr_source_df)
            
            vol_confirmed, vol_ratio, _ = self.check_volume_confirmation(df_5m)
            breakout = self.detect_breakout(df_5m, levels, higher_tf_context)
            retest = self.detect_retest_setup(df_5m, levels, higher_tf_context)
            inside_bar = self.detect_inside_bar(df_5m, higher_tf_context, levels)
            pin_bar = self.detect_pin_bar(df_5m, levels, higher_tf_context)
            engulfing = self.detect_engulfing(df_5m, levels, higher_tf_context)

            result.update(
                {
                    "pdh": pdh,
                    "pdl": pdl,
                    "levels": levels,
                    "volume_confirmed": vol_confirmed,
                    "volume_ratio": vol_ratio,
                    "breakout_signal": breakout,
                    "retest_signal": retest,
                    "inside_bar_signal": inside_bar,
                    "pin_bar_signal": pin_bar,
                    "engulfing_signal": engulfing,
                }
            )
            return result

        except Exception as e:
            logger.error(f"‚ùå analyze_with_multi_tf failed: {str(e)}")
            return result


# =========================================================================
# HELPER
# =========================================================================


def analyze_instrument(df: pd.DataFrame, instrument: str) -> Dict:
    """
    Legacy helper (single timeframe).
    """
    analyzer = TechnicalAnalyzer(instrument)
    pdh, pdl = analyzer.calculate_pdh_pdl(df)
    levels = analyzer.calculate_support_resistance(df)
    vol_confirmed, vol_ratio, _ = analyzer.check_volume_confirmation(df)
    breakout = analyzer.detect_breakout(
        df, levels, {"trend_direction": "FLAT", "rsi_15": 50.0}
    )
    retest = analyzer.detect_retest_setup(df, levels)
    inside_bar = analyzer.detect_inside_bar(df)

    return {
        "pdh": pdh,
        "pdl": pdl,
        "levels": levels,
        "volume_confirmed": vol_confirmed,
        "volume_ratio": vol_ratio,
        "breakout_signal": breakout,
        "retest_signal": retest,
        "inside_bar_signal": inside_bar,
    }


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.DEBUG if DEBUG_MODE else logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )
    logger.info("‚úÖ Technical Analysis Module loaded")


# ======================================================================
# FILE: analysis_module/option_chain_analyzer.py
# ======================================================================


import logging
from typing import Dict, Optional, List, Tuple

logger = logging.getLogger(__name__)

class OptionChainAnalyzer:
    """
    Analyzes option chain data to extract key metrics like PCR, Max Pain, and S/R levels.
    """
    
    def calculate_pcr(self, option_data: Dict) -> Optional[float]:
        """
        Calculate Put-Call Ratio (Total Put OI / Total Call OI).
        """
        try:
            total_call_oi = 0
            total_put_oi = 0
            
            records = option_data.get('records', {})
            data = records.get('data', [])
            
            for item in data:
                if 'CE' in item:
                    total_call_oi += item['CE'].get('openInterest', 0)
                if 'PE' in item:
                    total_put_oi += item['PE'].get('openInterest', 0)
            
            if total_call_oi == 0:
                logger.warning("OptionChainAnalyzer: Total Call OI is 0")
                return None
            
            pcr = total_put_oi / total_call_oi
            return round(pcr, 4)
            
        except Exception as e:
            logger.error(f"Error calculating PCR: {e}")
            return None

    def calculate_max_pain(self, option_data: Dict) -> Optional[float]:
        """
        Calculate Max Pain theory strike price.
        Max Pain is the strike where option writers lose the least amount of money.
        """
        try:
            records = option_data.get('records', {})
            data = records.get('data', [])
            
            strikes = []
            call_oi = {}
            put_oi = {}
            
            for item in data:
                strike = item['strikePrice']
                strikes.append(strike)
                call_oi[strike] = item.get('CE', {}).get('openInterest', 0)
                put_oi[strike] = item.get('PE', {}).get('openInterest', 0)
            
            if not strikes:
                return None
                
            # Sort strikes to ensure correct iteration
            strikes.sort()
            
            pain_values = {}
            
            for strike in strikes:
                current_pain = 0
                
                # Call Pain: (Spot - Strike) * OI for In-The-Money Calls (Spot > Strike)
                # If expiry is at 'strike', calls below 'strike' are ITM
                # Loss = (Strike_Expiry - Strike_Option) * OI
                # Here we assume expiry is at 'strike' to calculate pain AT that level
                
                # Pain if market expires at 'strike':
                
                # 1. Call Writers lose if Strike > Call_Strike
                # Loss = (Strike - Call_Strike) * Call_OI
                for s in strikes:
                    if s < strike:
                         current_pain += (strike - s) * call_oi.get(s, 0)
                         
                # 2. Put Writers lose if Strike < Put_Strike
                # Loss = (Put_Strike - Strike) * Put_OI
                for s in strikes:
                    if s > strike:
                        current_pain += (s - strike) * put_oi.get(s, 0)
                        
                pain_values[strike] = current_pain
                
            # Find strike with minimum pain
            max_pain_strike = min(pain_values, key=pain_values.get)
            return max_pain_strike
            
        except Exception as e:
            logger.error(f"Error calculating Max Pain: {e}")
            return None

    def calculate_atm_iv(self, option_data: Dict, spot_price: float) -> Optional[float]:
        """
        Calculate average Implied Volatility (IV) for ATM strikes.
        Returns average of Call IV and Put IV for the strike closest to spot price.
        """
        try:
            records = option_data.get('records', {})
            data = records.get('data', [])
            
            if not data or spot_price == 0:
                return None
                
            # Find ATM strike (closest to spot)
            atm_strike_data = min(data, key=lambda x: abs(x['strikePrice'] - spot_price))
            
            iv_sum = 0
            count = 0
            
            if 'CE' in atm_strike_data:
                iv = atm_strike_data['CE'].get('impliedVolatility', 0)
                if iv > 0:
                    iv_sum += iv
                    count += 1
                    
            if 'PE' in atm_strike_data:
                iv = atm_strike_data['PE'].get('impliedVolatility', 0)
                if iv > 0:
                    iv_sum += iv
                    count += 1
            
            if count == 0:
                return None
                
            return round(iv_sum / count, 2)
            
        except Exception as e:
            logger.error(f"Error calculating ATM IV: {e}")
            return None

    def analyze_oi_change(self, option_data: Dict, spot_price: float) -> Dict:
        """
        Analyze Change in Open Interest to determine sentiment.
        Calculates net OI change for strikes within 5% of spot.
        """
        try:
            records = option_data.get('records', {})
            data = records.get('data', [])
            
            if not data or spot_price <= 0:
                return {}
            
            # Filter for strikes within 5% range to focus on relevant activity
            relevant_data = [
                d for d in data 
                if abs(d['strikePrice'] - spot_price) < (spot_price * 0.05)
            ]
            
            total_call_change = 0
            total_put_change = 0
            
            for item in relevant_data:
                if 'CE' in item:
                    total_call_change += item['CE'].get('changeinOpenInterest', 0)
                if 'PE' in item:
                    total_put_change += item['PE'].get('changeinOpenInterest', 0)
            
            # Determine sentiment based on net flow
            # Call OI Increase > Put OI Increase -> Bearish (Resistance building)
            # Put OI Increase > Call OI Increase -> Bullish (Support building)
            
            sentiment = "NEUTRAL"
            difference = total_put_change - total_call_change
            
            # Significant difference threshold (e.g., 50k contracts)
            # Adjust based on instrument volume, but relative comparison is safer
            
            if total_call_change > 0 and total_put_change > 0:
                if total_put_change > (total_call_change * 1.5):
                    sentiment = "BULLISH"
                elif total_call_change > (total_put_change * 1.5):
                    sentiment = "BEARISH"
            
            # Handling unwinding scenarios (negative OI change)
            elif total_call_change < 0 and total_put_change < 0:
                 if abs(total_call_change) > abs(total_put_change) * 1.5:
                     sentiment = "BULLISH_UNWINDING" # Short covering
                 elif abs(total_put_change) > abs(total_call_change) * 1.5:
                     sentiment = "BEARISH_UNWINDING" # Long unwinding

            return {
                "total_call_change": total_call_change,
                "total_put_change": total_put_change,
                "sentiment": sentiment,
                "net_change_diff": difference
            }
            
        except Exception as e:
            logger.error(f"Error analyzing OI change: {e}")
            return {}

    def get_key_strikes(self, option_data: Dict) -> Dict:
        """
        Identify strikes with highest Open Interest for Support and Resistance.
        """
        try:
            records = option_data.get('records', {})
            data = records.get('data', [])
            
            call_oi_map = {}
            put_oi_map = {}
            
            for item in data:
                strike = item['strikePrice']
                if 'CE' in item:
                    call_oi_map[strike] = item['CE'].get('openInterest', 0)
                if 'PE' in item:
                    put_oi_map[strike] = item['PE'].get('openInterest', 0)
            
            # Find max OI strikes
            max_call_oi_strike = max(call_oi_map, key=call_oi_map.get) if call_oi_map else 0
            max_put_oi_strike = max(put_oi_map, key=put_oi_map.get) if put_oi_map else 0
            
            # Get top 3 levels
            top_calls = sorted(call_oi_map.items(), key=lambda x: x[1], reverse=True)[:3]
            top_puts = sorted(put_oi_map.items(), key=lambda x: x[1], reverse=True)[:3]
            
            return {
                "max_call_oi_strike": max_call_oi_strike,
                "max_put_oi_strike": max_put_oi_strike,
                "resistance_levels": [s for s, oi in top_calls],
                "support_levels": [s for s, oi in top_puts],
                "max_call_oi": call_oi_map.get(max_call_oi_strike, 0),
                "max_put_oi": put_oi_map.get(max_put_oi_strike, 0)
            }
            
        except Exception as e:
            logger.error(f"Error getting key strikes: {e}")
            return {}

if __name__ == "__main__":
    # Integration test with Fetcher
    try:
        from data_module.option_chain_fetcher import OptionChainFetcher
        
        logging.basicConfig(level=logging.INFO)
        fetcher = OptionChainFetcher()
        analyzer = OptionChainAnalyzer()
        
        print("Fetching data...")
        data = fetcher.fetch_option_chain("NIFTY")
        
        if data:
            print("\n--- Analysis Results ---")
            
            pcr = analyzer.calculate_pcr(data)
            print(f"PCR: {pcr}")
            
            max_pain = analyzer.calculate_max_pain(data)
            print(f"Max Pain: {max_pain}")
            
            levels = analyzer.get_key_strikes(data)
            print(f"Max Call OI (Res): {levels['max_call_oi_strike']}")
            print(f"Max Put OI (Sup): {levels['max_put_oi_strike']}")
            print(f"Top 3 Resistances: {levels['resistance_levels']}")
            print(f"Top 3 Supports: {levels['support_levels']}")
            
        else:
            print("Failed to fetch data for analysis")
            
    except ImportError:
        print("Please run this from the project root to test imports")


# ======================================================================
# FILE: analysis_module/manipulation_guard.py
# ======================================================================

"""
Manipulation Guard (Circuit Breaker)
Protects against Flash Crashes, Freak Trades, and Expiry Manipulation.
"""

import logging
from datetime import datetime, time
import pandas as pd
import numpy as np
from typing import Dict, Tuple, Optional

from config.settings import (
    MAX_1MIN_MOVE_PCT,
    EXPIRY_STOP_TIME,
    VIX_PANIC_LEVEL,
    VIX_LOW_LEVEL,
    TIME_ZONE
)

logger = logging.getLogger(__name__)

class CircuitBreaker:
    def __init__(self):
        self.triggered = False
        self.trigger_reason = None
        self.trigger_time = None
        self.pause_duration = 0
        self.last_vix = 0.0

    def check_market_integrity(self, df_5m: pd.DataFrame, current_price: float, instrument: str = "NIFTY 50") -> Tuple[bool, str]:
        """
        Run all safety checks.
        Returns: (is_safe, reason)
        """
        
        # 1. Check if Breaker already tripped
        if self.triggered:
            elapsed = (datetime.now() - self.trigger_time).total_seconds() / 60
            if elapsed < self.pause_duration:
                return False, f"Circuit Breaker Active ({self.trigger_reason}) - {int(self.pause_duration - elapsed)}m remaining"
            else:
                self._reset_breaker()

        # 2. Flash Crash / Velocity Check (1-minute equivalent using last 5m candle limit)
        # Note: Ideally we check tick data or 1m data. Using 5m rapid move proxy.
        if not df_5m.empty:
            last_candle = df_5m.iloc[-1]
            high = last_candle['high']
            low = last_candle['low']
            open_p = last_candle['open']
            
            # Use High-Low range as proxy for volatility/velocity
            move_pct = ((high - low) / open_p) * 100
            
            # If a single 5m candle moves > 2x the 1min limit (approx), it's a crash/spike
            if move_pct > (MAX_1MIN_MOVE_PCT * 2.5): 
                self._trip_breaker("Flash Move Detected", 15)
                return False, f"Flash Crash Protection: {move_pct:.2f}% move in 5m"

        # 3. Expiry Day Gamma Guard
        if self._is_expiry_danger_zone(instrument):
             return False, "Expiry Gamma Guard Active (Post 2:00 PM)"

        # 4. Freak Trade Filter (Wick check)
        # If current price is far from last close but within candle? (Implied in Flash check)

        return True, "Market Normal"

    def _is_expiry_danger_zone(self, instrument: str) -> bool:
        """Check if it's Tuesday (Nifty Expiry) and past the Stop Time."""
        now = datetime.now()
        
        # NIFTY 50 Expiry = Tuesday (Weekday 1)
        # BANKNIFTY Expiry = Wednesday (Weekday 2) -> Future improvement
        
        is_expiry_day = False
        if "NIFTY" in instrument and "BANK" not in instrument:
             is_expiry_day = now.weekday() == 1  # 1 = Tuesday
        
        if not is_expiry_day:
            return False
            
        # Parse Stop Time
        stop_hour, stop_min = map(int, EXPIRY_STOP_TIME.split(":"))
        if now.time() >= time(stop_hour, stop_min):
            return True
            
        return False

    def _trip_breaker(self, reason: str, duration_mins: int):
        self.triggered = True
        self.trigger_reason = reason
        self.trigger_time = datetime.now()
        self.pause_duration = duration_mins
        logger.warning(f"üö® CIRCUIT BREAKER TRIPPED: {reason}. Pausing for {duration_mins} mins.")

    def _reset_breaker(self):
        self.triggered = False
        self.trigger_reason = None
        self.trigger_time = None
        logger.info("‚úÖ Circuit Breaker Reset. Resuming operations.")
        
    def check_vix(self, vix_value: float) -> str:
        """Return market mode based on VIX"""
        if vix_value > VIX_PANIC_LEVEL:
            return "PANIC"
        if vix_value < VIX_LOW_LEVEL:
            return "DEAD"
        return "NORMAL"


# ======================================================================
# FILE: data_module/__init__.py
# ======================================================================



# ======================================================================
# FILE: data_module/fetcher.py
# ======================================================================

"""
Data Fetching Module
Retrieves real-time OHLCV data and historical data.
Includes debugging, caching, and fallback mechanisms.
"""

import requests
import pandas as pd
import yfinance as yf
from datetime import datetime
import json
import os
import logging
from typing import Dict, List, Optional
import time

from config.settings import (
    CACHE_DIR,
    INSTRUMENTS,
    INSTRUMENTS,
    DEBUG_MODE,
    FYERS_CLIENT_ID,
)
from data_module.fyers_interface import FyersApp

logger = logging.getLogger(__name__)


class DataFetcher:
    """Fetch real-time market data with caching & error handling"""

    def __init__(self):

        self.session = requests.Session()
        self.session.headers.update(
            {
                "User-Agent": (
                    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                    "AppleWebKit/537.36 (KHTML, like Gecko) "
                    "Chrome/120.0 Safari/537.36"
                )
            }
        )
        self.cache: Dict[str, Dict] = {}
        self.cache_time: Dict[str, float] = {}

        # Initialize Fyers App
        self.fyers_app = FyersApp(app_id=FYERS_CLIENT_ID)
        
        logger.info(f"üöÄ DataFetcher initialized | Primary: Fyers | Fallback: YFinance")

    # =====================================================================
    # REAL-TIME DATA FETCHING
    # =====================================================================

    def fetch_realtime_data(self, instrument: str) -> Optional[Dict]:
        """
        Fetch real-time market data from Fyers (Primary) or YFinance (Fallback).
        
        Returns:
            Dict: {
                'price': float,
                'dayHigh': float,
                'dayLow': float,
                'volume': float,
                'timestamp': str,
                'symbol': str
            }
        """
        if instrument not in INSTRUMENTS:
            logger.error(f"‚ùå Unknown instrument: {instrument}")
            return None

        cache_key = f"rt_{instrument}"
        if self._is_cache_valid(cache_key, ttl=10):
            return self.cache[cache_key]

        # 1. Try Fyers API
        data = self._fetch_fyers_data(instrument)
        if data:
            self.cache[cache_key] = data
            self.cache_time[cache_key] = time.time()
            return data

        # 2. Fallback to YFinance
        logger.warning(f"‚ö†Ô∏è Fyers failed, falling back to yfinance for {instrument}")
        data = self._fetch_yfinance_snapshot(instrument)
        if data:
            # Longer cache for yfinance as it's slower/delayed
            self.cache[cache_key] = data
            self.cache_time[cache_key] = time.time() 
            return data
            
        logger.error(f"‚ùå All data sources failed for {instrument}")
        return None

    def _fetch_fyers_data(self, instrument: str) -> Optional[Dict]:
        """Fetch from Fyers."""
        try:
            quote = self.fyers_app.get_quote(instrument)
            if not quote:
                return None
            
            # Debug Fyers structure
            if DEBUG_MODE:
                logger.info(f"DEBUG: Fyers Quote: {quote}")

            # Handle Fyers v3 structure: data might be in 'v' key
            # Check if 'lp' is directly in quote or in quote['v']
            data_source = quote.get('v', quote) if isinstance(quote.get('v'), dict) else quote
            
            # Map fields (Fyers v3 keys: lp, high_price, low_price, open_price, volume)
            # OR keys: lp, h, l, o, v (older/ws api?)
            # Let's handle both
            
            price = data_source.get('lp') or data_source.get('last_price') or 0
            high = data_source.get('high_price') or data_source.get('h') or 0
            low = data_source.get('low_price') or data_source.get('l') or 0
            open_p = data_source.get('open_price') or data_source.get('o') or 0
            volume = data_source.get('volume') or data_source.get('v') or 0

            return {
                "symbol": instrument,
                "price": float(price),
                "lastPrice": float(price),
                "dayHigh": float(high),
                "dayLow": float(low),
                "open": float(open_p),
                "volume": float(volume),
                "timestamp": datetime.now().isoformat(),
                "source": "FYERS"
            }
        except Exception as e:
            logger.error(f"‚ùå Fyers fetch error: {e}")
            return None

    def _fetch_yfinance_snapshot(self, instrument: str) -> Optional[Dict]:
        """Get snapshot from yfinance."""
        try:
            # Fetch 1 day of data with 5m interval to get latest candle
            df = self.fetch_historical_data(instrument, period="1d", interval="5m")
            if df is None or df.empty:
                return None
            
            # Preprocess to ensure standard lowercase columns
            df = self.preprocess_ohlcv(df)
                
            latest = df.iloc[-1]
            return {
                "symbol": instrument,
                "price": float(latest['close']),
                "dayHigh": float(df['high'].max()), 
                "dayLow": float(df['low'].min()),
                "open": float(df.iloc[0]['open']),
                "volume": float(df['volume'].sum()), 
                "timestamp": latest.name.isoformat(),
                "source": "YFINANCE"
            }
        except Exception as e:
            logger.error(f"‚ùå YFinance snapshot error: {e}")
            return None

    # =====================================================================
    # HISTORICAL DATA FETCHING (YFINANCE)
    # =====================================================================

    def fetch_historical_data(
        self,
        instrument: str,
        period: str = "5d",
        interval: str = "5m",
    ) -> Optional[pd.DataFrame]:
        """
        Fetch historical data for technical analysis setup using yfinance.

        Args:
            instrument: 'NIFTY', 'BANKNIFTY', or 'FINNIFTY'
            period: '5d', '1mo', etc.
            interval: '5m', '15m', '1h', '1d'

        Returns:
            DataFrame with OHLCV or None
        """
        symbol_map = {
            "NIFTY": "^NSEI",
            "BANKNIFTY": "^NSEBANK",
            "FINNIFTY": "^NSEINFRA",  # adjust as needed
        }

        if instrument not in symbol_map:
            logger.error(f"‚ùå No yfinance symbol for instrument: {instrument}")
            return None

        yf_symbol = symbol_map[instrument]

        logger.debug(
            f"üìä Fetching historical data | "
            f"Instrument: {instrument} | Period: {period} | Interval: {interval}"
        )

        try:
            df = yf.download(
                yf_symbol,
                period=period,
                interval=interval,
                progress=False,
                prepost=False,
                auto_adjust=True,  # Fix FutureWarning & ensure consistent Close
            )

            if isinstance(df, pd.Series):
                df = df.to_frame().T

            if df.empty:
                logger.warning(
                    f"‚ö†Ô∏è  Empty historical data returned for {instrument}"
                )
                return None

            logger.info(
                f"‚úÖ Historical data fetched: {instrument} | {len(df)} candles"
            )
            return df

        except Exception as e:
            logger.error(f"‚ùå Failed to fetch historical  {str(e)}")
            return None

    def get_historical_data(self, instrument: str, interval: str, bars: int) -> Optional[pd.DataFrame]:
        """
        Get historical data with bars-based signature (for choppy session filter).
        
        Args:
            instrument: 'NIFTY', 'BANKNIFTY', or 'FINNIFTY'
            interval: '5m', '15m', etc
            bars: Number of bars needed
            
        Returns:
            DataFrame with OHLCV or None
        """
        # Convert bars to period
        # Rough estimate: 78 5-min bars per trading day
        if interval == "5m":
            days = max(1, (bars // 78) + 1)
        elif interval == "15m":
            days = max(1, (bars // 26) + 1)
        elif interval == "1h":
            days = max(2, (bars // 6) + 1)
        else:
            days = 5
        
        period = f"{days}d"
        df = self.fetch_historical_data(instrument, period, interval)
        
        if df is not None and not df.empty:
            # Return last N bars
            return df.tail(bars)
        return df

    def get_previous_day_stats(self, instrument: str) -> Optional[Dict]:
        """
        Fetch Previous Day High (PDH) and Low (PDL).
        """
        try:
            df = self.fetch_historical_data(instrument, period="5d", interval="1d")
            if df is None or len(df) < 2:
                return None
            
            # Get previous day (last completed candle)
            prev_day = df.iloc[-2]
            
            return {
                "pdh": prev_day["high"],
                "pdl": prev_day["low"],
                "pdc": prev_day["close"],
                "date": prev_day.name.strftime("%Y-%m-%d")
            }
        except Exception as e:
            logger.error(f"‚ùå Failed to fetch PDH/PDL for {instrument}: {str(e)}")
            return None

    def get_opening_range_stats(self, instrument: str) -> Optional[Dict]:
        """
        Fetch High/Low of the first 5-min and 15-min candles of the current day.
        """
        try:
            # Fetch today's data (1d period, 5m interval)
            df_5m = self.fetch_historical_data(instrument, period="1d", interval="5m")
            df_15m = self.fetch_historical_data(instrument, period="1d", interval="15m")
            
            stats = {}
            
            if df_5m is not None and not df_5m.empty:
                first_5m = df_5m.iloc[0]
                stats["orb_5m_high"] = first_5m["high"]
                stats["orb_5m_low"] = first_5m["low"]
                
            if df_15m is not None and not df_15m.empty:
                first_15m = df_15m.iloc[0]
                stats["orb_15m_high"] = first_15m["high"]
                stats["orb_15m_low"] = first_15m["low"]
                
            return stats if stats else None
            
        except Exception as e:
            logger.error(f"‚ùå Failed to fetch Opening Range for {instrument}: {str(e)}")
            return None

    # =====================================================================
    # DATA VALIDATION
    # =====================================================================

    def _validate_nse_response(self, data: Dict) -> bool:
        """Deprecated validation."""
        return True

    # =====================================================================
    # CACHING
    # =====================================================================

    def _is_cache_valid(self, cache_key: str, ttl: int = 60) -> bool:
        """Check if cached data is still valid."""
        if cache_key not in self.cache_time:
            return False

        age = time.time() - self.cache_time[cache_key]
        is_valid = age < ttl

        if DEBUG_MODE:
            logger.debug(
                f"   Cache age: {age:.1f}s | TTL: {ttl}s | Valid: {is_valid}"
            )

        return is_valid

    def clear_cache(self, instrument: Optional[str] = None):
        """Clear cache for specific instrument or all."""
        if instrument:
            cache_key = f"nse_{instrument}"
            if cache_key in self.cache:
                del self.cache[cache_key]
                del self.cache_time[cache_key]
                logger.info(f"üóëÔ∏è  Cleared cache for {instrument}")
        else:
            self.cache.clear()
            self.cache_time.clear()
            logger.info("üóëÔ∏è  Cleared all cache")

    # =====================================================================
    # PREPROCESSING
    # =====================================================================

    def preprocess_ohlcv(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        Preprocess OHLCV data for analysis.

        Adds:
        - hl_range
        - hl_mid
        - co_change
        - typical_price
        """
        try:
            df = df.copy()
            
            # Handle MultiIndex columns from yfinance
            if isinstance(df.columns, pd.MultiIndex):
                # Flatten multi-index columns (e.g., ('Close', 'NIFTY') -> 'Close')
                df.columns = df.columns.get_level_values(0)
            
            # Rename 'Adj Close' to 'Close' if 'Close' is missing
            if "Close" in df.columns and "Adj Close" in df.columns:
                # If both exist, drop 'Adj Close' and keep 'Close'
                df = df.drop(columns=["Adj Close"])
            elif "Adj Close" in df.columns:
                # If only 'Adj Close' exists, rename it to 'Close'
                # If only 'Adj Close' exists, rename it to 'Close'
                df = df.rename(columns={"Adj Close": "Close"})
            
            # Ensure DatetimeIndex (Robustness Fix)
            # If index is just numbers but we have a 'Date' or 'Datetime' column, use it.
            if not isinstance(df.index, pd.DatetimeIndex):
                for time_col in ["Date", "date", "Datetime", "datetime", "timestamp"]:
                    if time_col in df.columns:
                        df[time_col] = pd.to_datetime(df[time_col])
                        df.set_index(time_col, inplace=True)
                        logger.debug(f"   ‚úÖ Set DatetimeIndex from column: {time_col}")
                        break
            
            # Lowercase all column names
            df.columns = [str(c).lower() for c in df.columns]
            
            if DEBUG_MODE:
                logger.debug(f"   Columns after processing: {list(df.columns)}")

            if not {"open", "high", "low", "close"}.issubset(df.columns):
                logger.warning(f"‚ö†Ô∏è  preprocess_ohlcv: missing OHLC columns. Have: {list(df.columns)}")
                return df

            df["hl_range"] = df["high"] - df["low"]
            df["hl_mid"] = (df["high"] + df["low"]) / 2.0
            df["co_change"] = (df["close"] - df["open"]) / df["open"] * 100.0
            df["typical_price"] = (
                df["high"] + df["low"] + df["close"]
            ) / 3.0

            logger.debug(
                f"‚úÖ Preprocessed {len(df)} candles | Added calculated fields"
            )
            return df

        except Exception as e:
            logger.error(f"‚ùå Preprocessing failed: {str(e)}")
            return df

    # =====================================================================
    # SAVE / LOAD CSV (for debugging/backtesting)
    # =====================================================================

    def save_to_csv(
        self, df: pd.DataFrame, instrument: str, filename: Optional[str] = None
    ):
        """Save data to CSV for offline analysis."""
        try:
            if filename is None:
                ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"{CACHE_DIR}/{instrument}_{ts}.csv"

            df.to_csv(filename)
            logger.info(f"üíæ Saved  {filename}")

        except Exception as e:
            logger.error(f"‚ùå Failed to save CSV: {str(e)}")

    def load_from_csv(self, filename: str) -> Optional[pd.DataFrame]:
        """Load data from CSV."""
        try:
            df = pd.read_csv(filename, index_col=0, parse_dates=True)
            logger.info(
                f"üìÇ Loaded  {filename} | {len(df)} rows"
            )
            return df

        except Exception as e:
            logger.error(f"‚ùå Failed to load CSV: {str(e)}")
            return None


# =========================================================================
# UTILITY
# =========================================================================


_fetcher: Optional[DataFetcher] = None


def get_data_fetcher() -> DataFetcher:
    """Singleton pattern for DataFetcher."""
    global _fetcher
    if _fetcher is None:
        _fetcher = DataFetcher()
    return _fetcher


def test_data_fetcher():
    """Test the data fetcher with NIFTY and BANKNIFTY."""
    logger.info("üß™ Testing DataFetcher...")

    fetcher = get_data_fetcher()

    for instrument in ["NIFTY", "BANKNIFTY"]:
        logger.info(f"\nüìå Testing {instrument}...")

        data = fetcher.fetch_realtime_data(instrument)
        if data is not None:
            logger.info(f"   ‚úÖ Real-time: {data.get('price')}")

        df = fetcher.fetch_historical_data(
            instrument, period="5d", interval="5m"
        )
        if df is not None:
            logger.info(f"   ‚úÖ Historical: {len(df)} candles")

    logger.info("\n‚úÖ DataFetcher tests completed!")


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.DEBUG if DEBUG_MODE else logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )
    test_data_fetcher()


# ======================================================================
# FILE: data_module/fyers_interface.py
# ======================================================================


import logging
import os
from typing import Dict, Optional, Any
from fyers_apiv3 import fyersModel
import time

logger = logging.getLogger(__name__)

class FyersApp:
    def __init__(self, app_id: str, secret_id: Optional[str] = None, access_token: Optional[str] = None):
        self.client_id = app_id  # App ID (e.g., DURQKS8D17-100)
        self.secret_key = secret_id
        self.access_token = access_token
        self.fyers: Optional[fyersModel.FyersModel] = None
        self.mapper = {
            "NIFTY": "NSE:NIFTY50-INDEX",
            "BANKNIFTY": "NSE:NIFTYBANK-INDEX",
            "FINNIFTY": "NSE:FINNIFTY-INDEX"
        }
        
        self.initialize_session()

    def initialize_session(self):
        """
        Initialize Fyers Model.
        Requires access_token. If not provided, it attempts to read from env or file.
        """
        if not self.access_token:
            # Try to load from env
            self.access_token = os.getenv("FYERS_ACCESS_TOKEN")
        
        if not self.access_token:
            # If no token, we can't make authenticated calls
            logger.warning("‚ö†Ô∏è Fyers Access Token is missing. Fyers API calls will fail.")
            return

        try:
            self.fyers = fyersModel.FyersModel(
                client_id=self.client_id,
                token=self.access_token,
                is_async=False, 
                log_path=os.getcwd()
            )
            logger.info("‚úÖ Fyers Model initialized")
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize Fyers Model: {e}")

    def get_option_chain(self, symbol: str) -> Optional[Dict[str, Any]]:
        """
        Fetch option chain for the given symbol.
        Args:
            symbol: Common symbol name (e.g., "NIFTY", "BANKNIFTY")
        """
        if not self.fyers:
            logger.error("‚ùå Fyers session not initialized")
            return None
            
        fyers_symbol = self.mapper.get(symbol)
        if not fyers_symbol:
            logger.error(f"‚ùå Unknown symbol for Fyers: {symbol}")
            return None
            
        try:
            # According to Fyers API v3 docs
            data = {
                "symbol": fyers_symbol,
                "strikecount": 20, # Fetch adequate strikes
                "timestamp": ""
            }
            
            response = self.fyers.optionchain(data=data)
            
            if response.get("s") == "ok":
                logger.info(f"‚úÖ Fyers Option Chain fetched for {symbol}")
                return response
            else:
                logger.error(f"‚ùå Fyers API Error: {response.get('message', 'Unknown Error')}")
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Exception fetching Fyers Option Chain: {e}")
            return None

    def get_quote(self, symbol: str) -> Optional[Dict[str, Any]]:
        """
        Fetch Level 1 quote (LTP, OHLC) for a symbol.
        """
        if not self.fyers:
            # Try re-initializing if token is available
            self.initialize_session()
            if not self.fyers:
                return None
                
        fyers_symbol = self.mapper.get(symbol)
        if not fyers_symbol:
            logger.error(f"‚ùå Unknown symbol: {symbol}")
            return None

        try:
            data = {"symbols": fyers_symbol}
            response = self.fyers.quotes(data=data)
            
            if response.get("s") == "ok" and "d" in response:
                return response["d"][0] # Return the first (and only) result
            else:
                logger.error(f"‚ùå Fyers Quote Failed: {response.get('message')}")
                return None
        except Exception as e:
            logger.error(f"‚ùå Exception fetching quote: {e}")
            return None

if __name__ == "__main__":
    # Test Block
    APP_ID = "DURQKS8D17-100"
    SECRET_ID = os.getenv("FYERS_SECRET_ID") # User said they have it
    ACCESS_TOKEN = os.getenv("FYERS_ACCESS_TOKEN")
    
    app = FyersApp(app_id=APP_ID, secret_id=SECRET_ID, access_token=ACCESS_TOKEN)
    if app.fyers:
        print("Testing Fetch...")
        data = app.get_option_chain("NIFTY")
        print(data)


# ======================================================================
# FILE: data_module/persistence.py
# ======================================================================

"""
Persistence Module
Handles state storage using Google Cloud Firestore.
Required for stateless Cloud Function execution to track daily stats.
"""

import logging
import os
from datetime import datetime
from typing import Dict, List, Optional
import json
import pytz

from google.cloud import firestore
from config.settings import TIME_ZONE, DEBUG_MODE

logger = logging.getLogger(__name__)

class PersistenceManager:
    """Manages daily state in Firestore."""
    
    def __init__(self):
        self.db = None
        self.collection_name = "daily_stats"
        self.project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
        
        if not self.project_id:
            logger.warning("‚ö†Ô∏è GOOGLE_CLOUD_PROJECT not set, persistence disabled")
            return

        try:
            self.db = firestore.Client(project=self.project_id)
            logger.info(f"üíæ Firestore initialized | Project: {self.project_id}")
        except Exception as e:
            logger.error(f"‚ùå Firestore init failed: {str(e)}")

    def _get_today_doc_id(self) -> str:
        """Get document ID for today (YYYY-MM-DD)."""
        return datetime.now().strftime("%Y-%m-%d")

    def increment_stat(self, stat_name: str, value: int = 1):
        """Increment a counter stat."""
        if not self.db:
            return

        try:
            doc_ref = self.db.collection(self.collection_name).document(self._get_today_doc_id())
            
            # Use atomic increment
            doc_ref.set({
                stat_name: firestore.Increment(value),
                "last_updated": firestore.SERVER_TIMESTAMP
            }, merge=True)
            
        except Exception as e:
            logger.error(f"‚ùå Failed to increment {stat_name}: {str(e)}")

    def _sanitize_for_firestore(self, data):
        """Recursively convert numpy types to standard Python types."""
        try:
            import numpy as np
            
            if isinstance(data, dict):
                return {k: self._sanitize_for_firestore(v) for k, v in data.items()}
            elif isinstance(data, list):
                return [self._sanitize_for_firestore(v) for v in data]
            elif isinstance(data, (np.integer, np.int64, np.int32)):
                return int(data)
            elif isinstance(data, (np.floating, np.float64, np.float32)):
                return float(data)
            elif isinstance(data, np.bool_):
                return bool(data)
            elif hasattr(data, "item"):  # Generic numpy scalar check
                return data.item()
            return data
        except ImportError:
            return data
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Sanitization failed: {e}")
            return data

    def add_event(self, event_type: str, event_data: Dict):
        """Add an event (breakout, signal) to the daily list."""
        if not self.db:
            return

        try:
            # Sanitize data (convert numpy types to python types)
            clean_data = self._sanitize_for_firestore(event_data)
            
            doc_ref = self.db.collection(self.collection_name).document(self._get_today_doc_id())
            
            # Firestore array_union to append to list
            doc_ref.set({
                f"events.{event_type}": firestore.ArrayUnion([clean_data]),
                "last_updated": firestore.SERVER_TIMESTAMP
            }, merge=True)
            
        except Exception as e:
            logger.error(f"‚ùå Failed to add event {event_type}: {str(e)}")

    def get_daily_stats(self) -> Dict:
        """Retrieve all stats for today."""
        if not self.db:
            return {}

        try:
            doc_ref = self.db.collection(self.collection_name).document(self._get_today_doc_id())
            doc = doc_ref.get()
            
            if doc.exists:
                return doc.to_dict()
            
            # If doc doesn't exist, create it initialized
            initial_stats = {"created_at": firestore.SERVER_TIMESTAMP}
            doc_ref.set(initial_stats, merge=True)
            return initial_stats
            
        except Exception as e:
            logger.error(f"‚ùå Failed to get daily stats: {str(e)}")
            return {}
    
    
    def on_new_trading_day(self):
        """
        Reset daily stats and alerts if the date has changed.
        Should be called at startup.
        """
        if not self.db: return
        
        try:
            today_id = self._get_today_doc_id()
             # We can't easily "check" if it's a new day without storing "last_run_date"
             # But if we rely on _get_today_doc_id() for daily_stats, we just need to ensure 
             # recent_alerts are cleared if they belong to previous days.
            pass
        except Exception as e:
            logger.error(f"‚ùå Failed to handle new trading day: {e}")

    def save_recent_alerts(self, recent_alerts: Dict):
        """
        Save recent alerts to Firestore for duplicate detection across executions.
        
        Args:
            recent_alerts: Dict of {AlertKey: timestamp}
        """
        if not self.db:
            return
        
        try:
            doc_ref = self.db.collection("system_state").document("recent_alerts")
            
            # Convert AlertKey objects to string representation for JSON compatibility
            # Keys must be strings in Firestore maps
            alerts_serialized = {}
            for key, timestamp in recent_alerts.items():
                k_str = str(key) if not isinstance(key, str) else key
                alerts_serialized[k_str] = timestamp.isoformat()
            
            doc_ref.set({
                "alerts": alerts_serialized,
                "updated_at": firestore.SERVER_TIMESTAMP
            })
            
            logger.debug(f"üíæ Saved {len(recent_alerts)} recent alerts to Firestore")
        
        except Exception as e:
            logger.error(f"‚ùå Failed to save recent alerts: {e}")
    
    def get_recent_alerts(self) -> Dict:
        """
        Retrieve recent alerts from Firestore.
        
        Returns:
            Dict of {AlertKey: timestamp}
        """
        from data_module.persistence_models import AlertKey
        
        if not self.db:
            return {}
        
        recent_alerts = {}
        try:
            doc_ref = self.db.collection("system_state").document("recent_alerts")
            doc = doc_ref.get()
            
            if not doc.exists:
                return {}
            
            data = doc.to_dict()
            alerts_serialized = data.get("alerts", {})
            
            ist = pytz.timezone("Asia/Kolkata")
            today = datetime.now(ist).strftime("%Y-%m-%d")
            
            for key_str, timestamp_str in alerts_serialized.items():
                try:
                    # Parse timestamp
                    dt = datetime.fromisoformat(timestamp_str)
                    if dt.tzinfo is None:
                        dt = ist.localize(dt)
                    
                    # Parse Key string back to AlertKey if possible
                    # Format: instrument|signal_type|level_ticks|date
                    parts = key_str.split("|")
                    if len(parts) == 4:
                        if parts[3] != today:
                            # Skip alerts from previous days
                            continue
                            
                        alert_key = AlertKey(
                            instrument=parts[0],
                            signal_type=parts[1],
                            level_ticks=int(parts[2]),
                            date=parts[3]
                        )
                        recent_alerts[alert_key] = dt
                    else:
                        # Legacy string key support (or if format changes)
                        # We might choose to drop legacy keys to force clean state
                        pass 
                        
                except Exception as e:
                    logger.warning(f"‚ö†Ô∏è Failed to parse alert entry {key_str}: {e}")
            
            logger.info(f"üìÇ Loaded {len(recent_alerts)} active alerts for today from Firestore")
            return recent_alerts
        
        except Exception as e:
            logger.error(f"‚ùå Failed to get recent alerts: {e}")
            # Fail Closed: Return empty dict means we might re-alert if DB is down but memory is empty.
            # However, main.py will populate memory as it runs.
            return {}

# =========================================================================
# SINGLETON
# =========================================================================

_persistence: Optional[PersistenceManager] = None


def get_persistence() -> PersistenceManager:
    """Singleton pattern for PersistenceManager."""
    global _persistence
    if _persistence is None:
        _persistence = PersistenceManager()
    return _persistence


# ======================================================================
# FILE: data_module/persistence_models.py
# ======================================================================

"""
Persistence Models
Data classes for structured storage and alerting keys.
"""

from dataclasses import dataclass
from datetime import datetime
import pytz
from typing import Dict, Optional

@dataclass(frozen=True)
class AlertKey:
    """
    Structured key for duplicate alert detection.
    Frozen so it can be hashed and used as a dict key.
    """
    instrument: str
    signal_type: str
    level_ticks: int  # price normalized to ticks
    date: str         # 'YYYY-MM-DD'
    
    def __str__(self):
        return f"{self.instrument}|{self.signal_type}|{self.level_ticks}|{self.date}"

def build_alert_key(signal: Dict, tick_size: float = 0.05) -> AlertKey:
    """
    Factory to create an AlertKey from a signal dictionary.
    """
    # Use price_level (for SR/Breakout) or entry_price (for patterns)
    level = signal.get("price_level") or signal.get("entry_price") or 0.0
    
    # Normalize to ticks to avoid float rounding dupes
    if tick_size > 0:
        level_ticks = int(round(level / tick_size))
    else:
        level_ticks = int(level)
        
    # Use localized date
    ist = pytz.timezone("Asia/Kolkata")
    today = datetime.now(ist).strftime("%Y-%m-%d")
    
    return AlertKey(
        instrument=signal["instrument"],
        signal_type=signal["signal_type"],
        level_ticks=level_ticks,
        date=today,
    )


# ======================================================================
# FILE: data_module/option_chain_fetcher.py
# ======================================================================


import requests
import time
import logging
from typing import Dict, Optional
from datetime import datetime
from config.settings import FYERS_CLIENT_ID
from data_module.fyers_interface import FyersApp

logger = logging.getLogger(__name__)

class OptionChainFetcher:
    """
    Fetches option chain data from NSE official API.
    Handles session management and headers to mimic a browser.
    """
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'en-US,en;q=0.9',
            'Referer': 'https://www.nseindia.com/option-chain'
        })
        self.cache = {}
        self.cache_time = {}
        self.cache_ttl = 60  # 1 minute cache
        
        # Initial visit to set cookies
        try:
            self.session.get("https://www.nseindia.com", timeout=10)
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Initial NSE visit failed: {e}")
            
        # Initialize Fyers App for fallback
        self.fyers_app = FyersApp(app_id=FYERS_CLIENT_ID)

    def _is_cache_valid(self, key: str) -> bool:
        if key in self.cache and key in self.cache_time:
            if time.time() - self.cache_time[key] < self.cache_ttl:
                return True
        return False

    def fetch_option_chain(self, instrument: str) -> Optional[Dict]:
        """
        Fetch option chain for NIFTY or BANKNIFTY.
        Prioritizes Fyers API. Falls back to NSE website if Fyers fails.
        
        Args:
            instrument: Symbol name (e.g., "NIFTY", "BANKNIFTY")
            
        Returns:
            Dictionary containing option chain data or None if failed.
        """
        # Map instrument to NSE symbol format
        symbol = "NIFTY" if "NIFTY" in instrument and "BANK" not in instrument else "BANKNIFTY"
        if "FIN" in instrument: symbol = "FINNIFTY"
        
        cache_key = f"oc_{symbol}"
        if self._is_cache_valid(cache_key):
            return self.cache[cache_key]

        # ----------------------------------------
        # PRIMARY: FYERS API
        # ----------------------------------------
        data = self.fetch_fyers_data(instrument)
        if data:
            self.cache[cache_key] = data
            self.cache_time[cache_key] = time.time()
            return data

        # ----------------------------------------
        # FALLBACK: NSE WEBSITE (Scraping)
        # ----------------------------------------
        logger.warning(f"‚ö†Ô∏è Fyers Option Chain failed. Falling back to NSE Scraping for {symbol}")
        
        url = f"https://www.nseindia.com/api/option-chain-indices?symbol={symbol}"
        
        try:
            # Add specific headers for API call
            headers = {
                'Referer': f'https://www.nseindia.com/option-chain?symbol={symbol}'
            }
            
            response = self.session.get(url, headers=headers, timeout=10)
            
            if response.status_code == 401:
                # Refresh session if unauthorized
                logger.info("üîÑ Refreshing NSE session...")
                self.session.get("https://www.nseindia.com", timeout=10)
                response = self.session.get(url, headers=headers, timeout=10)

            response.raise_for_status()
            data = response.json()
            
            # Validate Data
            if "records" not in data or "data" not in data.get("records", {}):
                raise ValueError("Invalid NSE data structure (missing records)")

            # Cache result
            self.cache[cache_key] = data
            self.cache_time[cache_key] = time.time()
            
            return data
            
        except Exception as e:
            logger.error(f"‚ùå Failed to fetch option chain for {symbol}: {e}")
            return None

    def fetch_fyers_data(self, instrument: str) -> Optional[Dict]:
        """Fetch and transform data from Fyers."""
        try:
            raw_data = self.fyers_app.get_option_chain(instrument)
            if raw_data and raw_data.get('data'):
                return self._transform_fyers_to_nse(raw_data['data'])
            return None
        except Exception as e:
            logger.error(f"‚ùå Fyers Fallback failed: {e}")
            return None

    def _transform_fyers_to_nse(self, fyers_data: Dict) -> Dict:
        """
        Transform Fyers response to match NSE structure for compatibility.
        """
        options_chain = fyers_data.get('optionsChain', [])
        expiry_data = fyers_data.get('expiryData', [])
        
        grouped = {}
        for item in options_chain:
            strike = item.get('strike_price')
            if not strike or strike <= 0: continue
            
            if strike not in grouped:
                grouped[strike] = {'strikePrice': strike}
            
            # Determine type
            sym = item.get('symbol', '')
            if 'CE' in sym[-2:]: type_key = 'CE'
            elif 'PE' in sym[-2:]: type_key = 'PE'
            else: continue
            
            # Map fields
            # Note: Fyers keys need to be verified. Assuming standard keys here.
            # Adjust keys based on actual Fyers API response inspection if needed.
            node = {
                'strikePrice': strike,
                'openInterest': item.get('oi', 0),
                'changeinOpenInterest': item.get('oich', 0),
                'totalTradedVolume': item.get('volume', 0),
                'impliedVolatility': item.get('iv', 0),
                'lastPrice': item.get('ltp', 0),
                'change': item.get('ltpch', 0), 
                'pChange': item.get('ltpchp', 0)
            }
            grouped[strike][type_key] = node

        unique_expiries = [x.get('date') for x in expiry_data if x.get('date')]
        
        data_list = sorted(list(grouped.values()), key=lambda x: x['strikePrice'])
        
        return {
            'records': {
                'expiryDates': unique_expiries,
                'data': data_list,
                'timestamp':  datetime.now().strftime("%d-%b-%Y %H:%M:%S")
            },
            'filtered': {
                'data': data_list, # Providing full list as filtered for now
                'CE': {'totOI': 0, 'totVol': 0}, 
                'PE': {'totOI': 0, 'totVol': 0}
            }
        }

if __name__ == "__main__":
    # Test execution
    logging.basicConfig(level=logging.INFO)
    fetcher = OptionChainFetcher()
    data = fetcher.fetch_option_chain("NIFTY")
    if data:
        print("‚úÖ Fetch success")
        records = data.get('records', {})
        print(f"Expiry Dates: {records.get('expiryDates', [])[:3]}")
    else:
        print("‚ùå Fetch failed")


# ======================================================================
# FILE: data_module/trade_tracker.py
# ======================================================================

"""
Trade Tracker Module
Tracks individual trade alerts and their outcomes in Firestore.
"""

import logging
import os
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import pytz

from google.cloud import firestore
from google.cloud.firestore import FieldFilter
from config.settings import TIME_ZONE

logger = logging.getLogger(__name__)

class TradeTracker:
    """Tracks trades and performance stats."""
    
    def __init__(self):
        self.db = None
        self.collection_name = "trades"
        self.project_id = os.getenv("GOOGLE_CLOUD_PROJECT")
        
        if not self.project_id:
            logger.warning("‚ö†Ô∏è GOOGLE_CLOUD_PROJECT not set, trade tracking disabled")
            return

        try:
            self.db = firestore.Client(project=self.project_id)
        except Exception as e:
            logger.error(f"‚ùå Firestore init failed for TradeTracker: {str(e)}")

    def record_alert(self, signal: Dict) -> Optional[str]:
        """
        Record a new trade alert.
        Returns trade_id if successful.
        """
        if not self.db:
            return None

        try:
            trade_id = str(uuid.uuid4())
            ist = pytz.timezone(TIME_ZONE)
            now = datetime.now(ist)
            
            # Clean up signal data for storage (remove non-serializable objects)
            trade_data = {
                "trade_id": trade_id,
                "timestamp": now,
                "date": now.strftime("%Y-%m-%d"),
                "instrument": signal.get("instrument"),
                "signal_type": signal.get("signal_type"),
                "price_level": signal.get("price_level"),
                "entry_price": signal.get("entry_price"),
                "stop_loss": signal.get("stop_loss"),
                "take_profit": signal.get("take_profit"),
                "confidence": signal.get("confidence"),
                "risk_reward": signal.get("risk_reward_ratio"),
                "risk_reward": signal.get("risk_reward_ratio"),
                "description": signal.get("description"),
                "atr": signal.get("atr", 0.0),
                "status": "OPEN",  # OPEN, WIN, LOSS, BREAKEVEN
                "filters": signal.get("debug_info", {}),
                "outcome": None
            }
            
            self.db.collection(self.collection_name).document(trade_id).set(trade_data)
            logger.info(f"üìù Trade recorded: {trade_id} | {signal.get('signal_type')}")
            return trade_id
            
        except Exception as e:
            logger.error(f"‚ùå Failed to record trade: {str(e)}")
            return None

    def update_outcome(self, trade_id: str, outcome: Dict) -> bool:
        """
        Update trade outcome.
        outcome = {
            "status": "WIN" | "LOSS" | "BREAKEVEN",
            "exit_price": float,
            "pnl_points": float,
            "duration_mins": float
        }
        """
        if not self.db:
            return False

        try:
            doc_ref = self.db.collection(self.collection_name).document(trade_id)
            doc_ref.update({
                "status": outcome.get("status"),
                "outcome": outcome,
                "closed_at": firestore.SERVER_TIMESTAMP
            })
            return True
        except Exception as e:
            logger.error(f"‚ùå Failed to update trade outcome: {str(e)}")
            return False

    def check_open_trades(self, current_prices: Dict[str, float]) -> int:
        """
        Check all open trades and automatically close them if TP or SL is hit.
        
        Args:
            current_prices: Dict of {instrument: current_price}
            
        Returns:
            Number of trades closed
        """
        if not self.db:
            return 0

        try:
            ist = pytz.timezone(TIME_ZONE)
            now = datetime.now(ist)
            
            # Query open trades
            trades_ref = self.db.collection(self.collection_name)
            query = trades_ref.where(filter=FieldFilter("status", "==", "OPEN")).stream()
            
            closed_count = 0
            
            for doc in query:
                trade = doc.to_dict()
                trade_id = trade.get("trade_id")
                instrument = trade.get("instrument")
                entry = trade.get("entry_price")
                tp = trade.get("take_profit")
                sl = trade.get("stop_loss")
                signal_type = trade.get("signal_type", "")
                opened_at = trade.get("timestamp")
                
                # Skip if we don't have current price for this instrument
                if instrument not in current_prices:
                    continue
                
                current_price = current_prices[instrument]
                
                # Determine if LONG or SHORT
                is_long = "BULLISH" in signal_type or "SUPPORT" in signal_type or "LONG" in signal_type
                atr = trade.get("atr", 0.0)
                
                # ===========================
                # ATR TRAILING STOP LOGIC
                # ===========================
                # If trade is in profit, move SL to lock gains
                # We use 1.5x ATR for trailing (tighter than initial 2.0x usually)
                trailing_mult = 1.5
                
                if atr > 0:
                    if is_long:
                        # New potential SL = Current Price - (ATR * Mult)
                        potential_sl = current_price - (atr * trailing_mult)
                        # Only move SL UP
                        if potential_sl > sl:
                            logger.info(f"üîÑ Trailing SL updated for {instrument}: {sl:.2f} -> {potential_sl:.2f}")
                            sl = potential_sl
                            # Update in DB deeply
                            doc.reference.update({"stop_loss": sl})
                    else:
                        # SHORT
                        potential_sl = current_price + (atr * trailing_mult)
                        # Only move SL DOWN
                        if potential_sl < sl:
                            logger.info(f"üîÑ Trailing SL updated for {instrument}: {sl:.2f} -> {potential_sl:.2f}")
                            sl = potential_sl
                            doc.reference.update({"stop_loss": sl})
                
                outcome = None
                exit_price = None
                
                # Check if TP or SL hit
                if is_long:
                    # LONG trade
                    if current_price >= tp:
                        # Target hit - WIN
                        outcome = "WIN"
                        exit_price = tp
                    elif current_price <= sl:
                        # Stop loss hit - LOSS
                        outcome = "LOSS"
                        exit_price = sl
                else:
                    # SHORT trade
                    if current_price <= tp:
                        # Target hit - WIN
                        outcome = "WIN"
                        exit_price = tp
                    elif current_price >= sl:
                        # Stop loss hit - LOSS
                        outcome = "LOSS"
                        exit_price = sl
                
                # Update trade if outcome determined
                if outcome:
                    pnl_points = abs(exit_price - entry) if outcome == "WIN" else -abs(exit_price - entry)
                    
                    # Calculate duration
                    duration_mins = (now - opened_at).total_seconds() / 60.0 if opened_at else 0
                    
                    outcome_data = {
                        "status": outcome,
                        "exit_price": exit_price,
                        "pnl_points": pnl_points,
                        "duration_mins": duration_mins,
                        "closed_by": "AUTO"
                    }
                    
                    # Update in Firestore
                    doc_ref = self.db.collection(self.collection_name).document(trade_id)
                    doc_ref.update({
                        "status": outcome,
                        "outcome": outcome_data,
                        "closed_at": now
                    })
                    
                    closed_count += 1
                    logger.info(
                        f"‚úÖ Trade auto-closed: {instrument} {signal_type} | "
                        f"{outcome} @ {exit_price:.2f} | P&L: {pnl_points:.2f}"
                    )
            
            return closed_count
            
        except Exception as e:
            logger.error(f"‚ùå Failed to check open trades: {str(e)}")
            return 0

    def get_stats(self, days: int = 7) -> Dict:
        """
        Calculate performance stats for the last N days.
        """
        if not self.db:
            return {}

        try:
            # Calculate start date
            start_date = (datetime.now() - timedelta(days=days)).strftime("%Y-%m-%d")
            
            # Query trades
            trades_ref = self.db.collection(self.collection_name)
            query = trades_ref.where(filter=FieldFilter("date", ">=", start_date)).stream()
            
            total_alerts = 0
            wins = 0
            losses = 0
            by_type = {}
            
            for doc in query:
                trade = doc.to_dict()
                total_alerts += 1
                
                stype = trade.get("signal_type", "UNKNOWN")
                status = trade.get("status", "OPEN")
                
                # Stats by type
                if stype not in by_type:
                    by_type[stype] = {"count": 0, "wins": 0, "losses": 0}
                
                by_type[stype]["count"] += 1
                
                if status == "WIN":
                    wins += 1
                    by_type[stype]["wins"] += 1
                elif status == "LOSS":
                    losses += 1
                    by_type[stype]["losses"] += 1
            
            win_rate = (wins / (wins + losses)) * 100 if (wins + losses) > 0 else 0
            
            return {
                "period_days": days,
                "total_alerts": total_alerts,
                "wins": wins,
                "losses": losses,
                "win_rate": win_rate,
                "by_type": by_type
            }
            
        except Exception as e:
            logger.error(f"‚ùå Failed to get stats: {str(e)}")
            return {}

# Singleton
_tracker = None

def get_trade_tracker() -> TradeTracker:
    global _tracker
    if _tracker is None:
        _tracker = TradeTracker()
    return _tracker


# ======================================================================
# FILE: telegram_module/bot_handler.py
# ======================================================================

"""
Telegram Bot Handler
Sends formatted alerts, signals, and notifications to Telegram.
"""

import requests
import json
import logging
from typing import Dict, Optional
from datetime import datetime

from config.settings import (
    TELEGRAM_BOT_TOKEN,
    TELEGRAM_CHAT_ID,
    TELEGRAM_CHANNEL_ID,
    TELEGRAM_MAX_MESSAGE_LENGTH,
    INCLUDE_CHARTS_IN_ALERT,
    INCLUDE_AI_SUMMARY_IN_ALERT,
    ALERT_TYPES,
    DRY_RUN,
    DEBUG_MODE,
)

logger = logging.getLogger(__name__)


class TelegramBot:
    """Send alerts and messages to Telegram."""

    def __init__(self):
        self.token = TELEGRAM_BOT_TOKEN
        self.chat_id = TELEGRAM_CHAT_ID
        self.channel_id = TELEGRAM_CHANNEL_ID
        self.base_url = f"https://api.telegram.org/bot{self.token}"
        self.message_count = 0

        logger.info(f"ü§ñ TelegramBot initialized | Chat ID: {self.chat_id} | Channel: {self.channel_id}")
        self._validate_credentials()

    def _validate_credentials(self):
        if not self.token or self.token == "YOUR_BOT_TOKEN_HERE":
            logger.error("‚ùå TELEGRAM_BOT_TOKEN not configured")
        if not self.chat_id or self.chat_id == "YOUR_CHAT_ID_HERE":
            logger.error("‚ùå TELEGRAM_CHAT_ID not configured")

    # =====================================================================
    # CORE SEND
    # =====================================================================

    def send_message(self, text: str, parse_mode: str = "HTML") -> bool:
        """
        Send a plain message to Telegram chat.
        """
        if DRY_RUN:
            logger.warning(f"üö´ DRY RUN: Not sending Telegram message: {text[:80]}...")
            return True

        if len(text) > TELEGRAM_MAX_MESSAGE_LENGTH:
            logger.warning(
                f"‚ö†Ô∏è  Message too long ({len(text)} chars), truncating"
            )
            text = text[: TELEGRAM_MAX_MESSAGE_LENGTH - 3] + "..."

        import time

        url = f"{self.base_url}/sendMessage"
        
        # List of targets
        targets = [self.chat_id]
        if self.channel_id:
            targets.append(self.channel_id)
        
        success_count = 0
        
        for target_id in targets:
            retries = 3
            backoff = 2
            
            while retries > 0:
                try:
                    payload = {
                        "chat_id": target_id,
                        "text": text,
                        "parse_mode": parse_mode,
                        "disable_web_page_preview": True,
                    }

                    response = requests.post(url, json=payload, timeout=10)
                    
                    # Handle Rate Limiting (429) explicitly
                    if response.status_code == 429:
                        retry_after = int(response.json().get("parameters", {}).get("retry_after", backoff))
                        logger.warning(f"‚è≥ Rate limited by Telegram. Retrying after {retry_after}s...")
                        time.sleep(retry_after)
                        retries -= 1
                        continue
                        
                    response.raise_for_status()

                    data = response.json()
                    if data.get("ok"):
                        msg_id = data["result"]["message_id"]
                        success_count += 1
                        logger.info(f"‚úÖ Telegram message sent to {target_id} | ID: {msg_id}")
                        break # Success, move to next target
                    else:
                        logger.error(f"‚ùå Failed to send to {target_id}: {data.get('description', 'Unknown')}")
                        break # Logic error, don't retry

                except requests.exceptions.RequestException as e:
                    logger.error(f"‚ùå Telegram send failed (Attempt {4-retries}/3): {str(e)}")
                    retries -= 1
                    time.sleep(backoff)
                    backoff *= 2  # Exponential backoff for network errors
        
        if success_count > 0:
            self.message_count += 1
            return True
        return False

    # =====================================================================
    # SIGNAL ALERTS
    # =====================================================================

    def _format_targets(self, signal: Dict) -> str:
        """Format T1, T2, T3 targets."""
        tp1 = float(signal.get("take_profit", 0.0))
        tp2 = float(signal.get("take_profit_2", 0.0))
        tp3 = float(signal.get("take_profit_3", 0.0))
        
        # Base T1
        txt = f"üéØ Target 1: {tp1:.2f} (Safe)"
        
        # If strong trend, show T2/T3
        if tp2 > 0 and abs(tp2 - tp1) > 1.0:
             txt += f"\nüéØ Target 2: {tp2:.2f}"
        if tp3 > 0 and abs(tp3 - tp2) > 1.0:
             txt += f"\nüéØ Target 3: {tp3:.2f}"
             
        return txt

    def _format_ai_analysis(self, signal: Dict) -> str:
        """Helper to format AI analysis section."""
        if not INCLUDE_AI_SUMMARY_IN_ALERT:
            return ""
            
        ai_data = signal.get("ai_analysis")
        if not ai_data:
            return ""

        verdict = ai_data.get("verdict", "N/A")
        reasoning = ai_data.get("reasoning", "No details")
        ai_conf = ai_data.get("confidence", 0)
        
        # Check for legacy schema fallback
        if "recommendation" in ai_data:
            verdict = ai_data.get("recommendation")
            reasoning = ai_data.get("summary")

        return (
            f"ü§ñ <b>AI Analyst Review</b>\n"
            f"‚Ä¢ Verdict: {verdict} ({ai_conf}%)\n"
            f"‚Ä¢ Logic: <i>{reasoning}</i>\n"
        )

    def send_breakout_alert(self, signal: Dict) -> bool:
        """Send formatted breakout/breakdown alert."""
        try:
            instrument = signal.get("instrument", "N/A")
            signal_type = signal.get("signal_type", "BREAKOUT")
            entry = float(signal.get("entry_price", 0.0))
            sl = float(signal.get("stop_loss", 0.0))
            tp = float(signal.get("take_profit", 0.0))
            rr = float(signal.get("risk_reward_ratio", 0.0))
            conf = float(signal.get("confidence", 0.0))

            emoji = "üöÄ" if "BULLISH" in signal_type else "üìâ"

            header = ALERT_TYPES.get(
                "BREAKOUT", "BREAKOUT"
            ) if "BREAKOUT" in signal_type else ALERT_TYPES.get(
                "BREAKDOWN", "BREAKDOWN"
            )

            message = (
                f"{emoji} {header}\n\n"
                f"üìä {instrument}\n"
                f"üí∞ Entry: {entry:.2f}\n"
                f"üõë SL: {sl:.2f}\n"
                f"{self._format_targets(signal)}\n"
                f"üìà RR: {rr:.2f}:1\n"
                f"‚ö° Confidence: {conf:.1f}%\n"
                f"üèÜ Score: {signal.get('score', 'N/A')}/100\n\n"
                f"{signal.get('description', '')}\n\n"
            )
            
            # Add Score Reasons
            reasons = signal.get("score_reasons", [])
            if reasons:
                message += f"üìù Factors: {', '.join(reasons)}\n\n"
            
            # Add IST timestamp
            import pytz
            ist = pytz.timezone("Asia/Kolkata")
            now_ist = datetime.now(ist)
            message += f"‚è∞ {now_ist.strftime('%Y-%m-%d %H:%M:%S IST')}\n\n"

            # Add AI Analysis
            message += self._format_ai_analysis(signal)

            return self.send_message(message)

        except Exception as e:
            logger.error(f"‚ùå Failed to format breakout alert: {str(e)}")
            return False

    def send_false_breakout_alert(self, signal: Dict) -> bool:
        """Send false breakout warning."""
        try:
            instrument = signal.get("instrument", "N/A")
            level = float(signal.get("price_level", 0.0))
            fb = signal.get("false_breakout_details", {})
            retrace = float(fb.get("retracement_pct", 0.0))

            message = (
                f"‚ö†Ô∏è {ALERT_TYPES.get('FALSE_BREAKOUT', 'FALSE BREAKOUT')}\n\n"
                f"üìä {instrument}\n"
                f"üìç Level: {level:.2f}\n"
                f"‚Ü© Retracement: {retrace:.2f}%\n\n"
                f"Possible trap / failed breakout at key level.\n\n"
                f"‚è∞ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            )

            return self.send_message(message)

        except Exception as e:
            logger.error(
                f"‚ùå Failed to format false breakout alert: {str(e)}"
            )
            return False

    def send_retest_alert(self, signal: Dict) -> bool:
        """Send retest setup alert."""
        try:
            import pytz
            
            instrument = signal.get("instrument", "N/A")
            signal_type = signal.get("signal_type", "RETEST")
            level = float(signal.get("price_level", 0.0))
            entry = float(signal.get("entry_price", 0.0))
            sl = float(signal.get("stop_loss", 0.0))
            tp = float(signal.get("take_profit", 0.0))
            conf = float(signal.get("confidence", 0.0))
            desc = signal.get("description", "")
            
            # Determine direction
            direction = "üìà LONG" if entry > sl else "üìâ SHORT"
            emoji = "üéØ" if "SUPPORT" in signal_type.upper() else "üîÑ"
            
            # Calculate R:R
            risk = abs(entry - sl)
            reward = abs(tp - entry)
            rr = reward / risk if risk > 0 else 0
            
            # Get IST time
            ist = pytz.timezone("Asia/Kolkata")
            now_ist = datetime.now(ist)

            message = (
                f"{emoji} {ALERT_TYPES.get('RETEST', 'RETEST')} {direction}\n\n"
                f"üìä <b>{instrument}</b>\n"
                f"üìç Key Level: {level:.2f}\n\n"
                f"<b>üí∞ Entry:</b> {entry:.2f}\n"
                f"<b>üõë Stop Loss:</b> {sl:.2f}\n"
                f"<b>{self._format_targets(signal)}</b>\n"
                f"<b>üìà Risk:Reward:</b> 1:{rr:.1f}\n"
                f"<b>‚ö° Confidence:</b> {conf:.0f}%\n"
                f"<b>üèÜ Score:</b> {signal.get('score', 'N/A')}/100\n\n"
                f"üí° {desc}\n\n"
            )
            
            # Add Score Reasons
            reasons = signal.get("score_reasons", [])
            if reasons:
                message += f"üìù Factors: {', '.join(reasons)}\n\n"
            
            message += f"‚è∞ {now_ist.strftime('%Y-%m-%d %H:%M:%S IST')}\n\n"
            
            # Add AI Analysis
            message += self._format_ai_analysis(signal)

            return self.send_message(message)

        except Exception as e:
            logger.error(f"‚ùå Failed to format retest alert: {str(e)}")
            return False

    def send_inside_bar_alert(self, signal: Dict) -> bool:
        """Send inside bar setup alert."""
        try:
            import pytz
            
            instrument = signal.get("instrument", "N/A")
            entry = float(signal.get("entry_price", 0.0))
            sl = float(signal.get("stop_loss", 0.0))
            tp = float(signal.get("take_profit", 0.0))
            conf = float(signal.get("confidence", 0.0))
            desc = signal.get("description", "")
            
            # Calculate R:R
            risk = abs(entry - sl)
            reward = abs(tp - entry)
            rr = reward / risk if risk > 0 else 0
            
            # Get IST time
            ist = pytz.timezone("Asia/Kolkata")
            now_ist = datetime.now(ist)

            message = (
                f"üìä {ALERT_TYPES.get('INSIDE_BAR', 'INSIDE BAR SETUP')}\n\n"
                f"üìä <b>{instrument}</b>\n\n"
                f"<b>üí∞ Entry:</b> {entry:.2f}\n"
                f"<b>üõë Stop Loss:</b> {sl:.2f}\n"
                f"<b>{self._format_targets(signal)}</b>\n"
                f"<b>üìà Risk:Reward:</b> 1:{rr:.1f}\n"
                f"<b>‚ö° Confidence:</b> {conf:.0f}%\n"
                f"<b>üèÜ Score:</b> {signal.get('score', 'N/A')}/100\n\n"
                f"üí° {desc}\n\n"
            )

            # Add Score Reasons
            reasons = signal.get("score_reasons", [])
            if reasons:
                message += f"üìù Factors: {', '.join(reasons)}\n\n"
                
            message += f"‚è∞ {now_ist.strftime('%Y-%m-%d %H:%M:%S IST')}\n\n"
            
            # Add AI Analysis
            message += self._format_ai_analysis(signal)

            return self.send_message(message)

        except Exception as e:
            logger.error(
                f"‚ùå Failed to format inside bar alert: {str(e)}"
            )
            return False

    # =====================================================================
    # OTHER NOTIFICATIONS
    # =====================================================================

    def send_daily_summary(self, summary_data: Dict) -> bool:
        """Send comprehensive end-of-day market summary."""
        try:
            message = "<b>üìä END-OF-DAY MARKET SUMMARY</b>\n"
            message += f"üìÖ {datetime.now().strftime('%B %d, %Y')}\n\n"
            
            # Price action for each instrument
            instruments_data = summary_data.get("instruments", {})
            for instrument, data in instruments_data.items():
                change_pct = data.get("change_pct", 0)
                emoji = "üìà" if change_pct > 0 else "üìâ" if change_pct < 0 else "‚ûñ"
                
                message += f"<b>{emoji} {instrument}</b>\n"
                message += f"Open: {data.get('open', 0):.2f} | High: {data.get('high', 0):.2f}\n"
                message += f"Low: {data.get('low', 0):.2f} | <b>Close: {data.get('close', 0):.2f}</b>\n"
                message += f"Change: <b>{change_pct:+.2f}%</b>\n"
                
                # Key levels
                if data.get("pdh") and data.get("pdl"):
                    message += f"PDH: {data['pdh']:.2f} | PDL: {data['pdl']:.2f}\n"
                
                # Trend
                st_trend = data.get("short_term_trend", "NEUTRAL")
                lt_trend = data.get("long_term_trend", "NEUTRAL")
                message += f"Trend: {st_trend} (ST) / {lt_trend} (LT)\n"
                
                # Option Chain Summary
                if "option_chain" in data:
                    oc = data["option_chain"]
                    message += f"Option Chain: PCR {oc.get('pcr', 'N/A')} | MP {oc.get('max_pain', 'N/A')} | {oc.get('sentiment', 'NEUTRAL')}\n"
                
                message += "\n"
            
            # Events summary
            stats = summary_data.get("statistics", {})
            message += "<b>üéØ Today's Events</b>\n"
            message += f"üöÄ Breakouts: {stats.get('breakouts', 0)}\n"
            message += f"üìâ Breakdowns: {stats.get('breakdowns', 0)}\n"
            message += f"üîÑ Retests: {stats.get('retests', 0)}\n"
            message += f"‚Ü©Ô∏è Reversals: {stats.get('reversals', 0)}\n\n"
            
            # Performance stats
            perf = summary_data.get("performance", {})
            if perf and perf.get("total_alerts", 0) > 0:
                message += "<b>üìä Performance (Last 24h)</b>\n"
                message += f"Total Alerts: {perf.get('total_alerts', 0)}\n"
                
                # Only show win rate if we have closed trades
                wins = perf.get("wins", 0)
                losses = perf.get("losses", 0)
                if wins + losses > 0:
                    message += f"Win Rate: {perf.get('win_rate', 0):.1f}% ({wins}W-{losses}L)\n"
                
                by_type = perf.get("by_type", {})
                if by_type:
                    message += "<i>By Setup:</i>\n"
                    for stype, data in by_type.items():
                        readable_type = stype.replace("_", " ").title()
                        count = data.get("count", 0)
                        message += f"- {readable_type}: {count}\n"
                message += "\n"
            
            # AI Forecast
            forecast = summary_data.get("ai_forecast", {})
            if forecast:
                outlook = forecast.get("outlook", "NEUTRAL")
                outlook_emoji = "üü¢" if outlook == "BULLISH" else "üî¥" if outlook == "BEARISH" else "üü°"
                
                message += f"<b>{outlook_emoji} AI Forecast - {outlook}</b>\n"
                message += f"Confidence: {forecast.get('confidence', 50):.0f}%\n"
                
                # Parse summary if it's a JSON string (common with LLM output)
                ai_summary = forecast.get("summary", "No forecast available")
                if isinstance(ai_summary, str) and ai_summary.strip().startswith("{"):
                    try:
                        import json
                        parsed = json.loads(ai_summary)
                        ai_summary = parsed.get("summary", ai_summary)
                    except:
                        pass
                        
                message += f"{ai_summary}\n\n"
            
            # Statistics
            message += "<b>üìä Session Stats</b>\n"
            message += f"üì° Data Fetches: {stats.get('data_fetches', 0)}\n"
            message += f"üîç Analyses: {stats.get('analyses_run', 0)}\n"
            message += f"üîî Alerts Sent: {stats.get('alerts_sent', 0)}\n"
            
            return self.send_message(message)

        except Exception as e:
            logger.error(
                f"‚ùå Failed to send daily summary: {str(e)}"
            )
            return False

    def send_error_notification(
        self, error_msg: str, context: str = ""
    ) -> bool:
        """Send error notification."""
        try:
            message = (
                "‚ùå ERROR NOTIFICATION\n\n"
                f"{context}\n\n"
                f"Error: {error_msg[:500]}\n\n"
                f"‚è∞ {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            )

            return self.send_message(message)

        except Exception as e:
            logger.error(
                f"‚ùå Failed to send error notification: {str(e)}"
            )
            return False

    def send_startup_message(self, pdh_pdl_stats: Optional[Dict] = None) -> bool:
        """Send startup confirmation message with optional PDH/PDL stats."""
        try:
            message = (
                "üöÄ NIFTY AI TRADING AGENT STARTED\n\n"
                "‚úÖ System online and monitoring markets\n"
                "üìä Instruments: NIFTY50, BANKNIFTY\n"
                "üîî Breakout / retest / inside bar alerts will be sent\n"
                "‚è∞ Active: 09:15 - 15:30 IST\n"
            )

            if pdh_pdl_stats:
                message += "\nüìã <b>Previous Day Stats</b>\n"
                for instrument, stats in pdh_pdl_stats.items():
                    message += (
                        f"\n<b>{instrument}</b>\n"
                        f"High: {stats['pdh']:.2f}\n"
                        f"Low: {stats['pdl']:.2f}\n"
                        f"Close: {stats['pdc']:.2f}\n"
                    )

            return self.send_message(message)

        except Exception as e:
            logger.error(
                f"‚ùå Failed to send startup message: {str(e)}"
            )
            return False

    def send_market_context(self, context_data: Dict, pdh_pdl_stats: Optional[Dict] = None, sr_levels: Optional[Dict] = None, option_stats: Optional[Dict] = None) -> bool:
        """Send market context (Opening Range + S/R) update with optional PDH/PDL."""
        try:
            message = "üåÖ <b>MARKET CONTEXT UPDATE</b>\n\n"
            
            all_instruments = set(context_data.keys())
            if pdh_pdl_stats:
                all_instruments.update(pdh_pdl_stats.keys())
            if sr_levels:
                all_instruments.update(sr_levels.keys())
            if option_stats:
                all_instruments.update(option_stats.keys())
            
            for instrument in sorted(list(all_instruments)):
                message += f"<b>{instrument}</b>\n"
                
                # PDH/PDL
                if pdh_pdl_stats and instrument in pdh_pdl_stats:
                    stats = pdh_pdl_stats[instrument]
                    message += (
                        f"PDH: {stats['pdh']:.2f} | PDL: {stats['pdl']:.2f}\n"
                    )

                # Opening Range
                if instrument in context_data:
                    stats = context_data[instrument]
                    if "orb_5m_high" in stats:
                        message += (
                            f"5m OR: {stats['orb_5m_low']:.2f} - {stats['orb_5m_high']:.2f}\n"
                        )
                    if "orb_15m_high" in stats:
                        message += (
                            f"15m OR: {stats['orb_15m_low']:.2f} - {stats['orb_15m_high']:.2f}\n"
                        )
                
                # NEW: Support/Resistance Levels
                if sr_levels and instrument in sr_levels:
                    sr = sr_levels[instrument]
                    
                    # Handle both dictionary (tests) and TechnicalLevels object (prod)
                    if isinstance(sr, dict):
                        s_levels = sr.get('support', []) or sr.get('support_levels', [])
                        r_levels = sr.get('resistance', []) or sr.get('resistance_levels', [])
                    else:
                        # Assume TechnicalLevels dataclass
                        s_levels = getattr(sr, 'support_levels', [])
                        r_levels = getattr(sr, 'resistance_levels', [])

                    # Show top 3 supports and resistances
                    supports = sorted(s_levels)[-3:] if s_levels else []
                    resistances = sorted(r_levels)[:3] if r_levels else []
                    
                    if supports:
                        message += f"üìä Supports: {', '.join([f'{s:.2f}' for s in supports])}\n"
                    if resistances:
                        message += f"üìä Resistances: {', '.join([f'{r:.2f}' for r in resistances])}\n"

                # NEW: Option Chain Stats
                if option_stats and instrument in option_stats:
                    oc = option_stats[instrument]
                    message += f"üé≤ PCR: {oc.get('pcr', 'N/A')} | Max Pain: {oc.get('max_pain', 'N/A')}\n"
                    
                    ks = oc.get('key_strikes', {})
                    if ks:
                         message += f"üîë Res: {ks.get('max_call_oi_strike', 'N/A')} | Sup: {ks.get('max_put_oi_strike', 'N/A')}\n"
                
                message += "\n"

            message += f"‚è∞ {datetime.now().strftime('%H:%M:%S')}"
            return self.send_message(message)

        except Exception as e:
            logger.error(f"‚ùå Failed to send market context: {str(e)}")
            return False

    # =====================================================================
    # MEDIA (optional stub)
    # =====================================================================

    def send_chart(self, chart_path: str, caption: str = "") -> bool:
        """Send chart image to Telegram (optional, can be extended)."""
        if not INCLUDE_CHARTS_IN_ALERT:
            logger.debug("‚è≠Ô∏è  Chart sending disabled in settings")
            return True

        if DRY_RUN:
            logger.warning(
                f"üö´ DRY RUN: Not sending chart: {chart_path}"
            )
            return True

        try:
            url = f"{self.base_url}/sendPhoto"
            
            targets = [self.chat_id]
            if self.channel_id:
                targets.append(self.channel_id)
            
            success_count = 0

            with open(chart_path, "rb") as photo:
                file_content = photo.read()
                
            for target_id in targets:
                # Re-open file or use content for each request? 
                # requests files param expects an open file handle. 
                # Better to send bytes.
                
                try:
                    files = {"photo": file_content}
                    data = {
                        "chat_id": target_id,
                        "caption": caption[:1024],
                    }

                    logger.debug(f"üì§ Sending chart to {target_id}: {chart_path}")
                    response = requests.post(
                        url, files=files, data=data, timeout=30
                    )
                    response.raise_for_status()

                    if response.json().get("ok"):
                        success_count += 1
                        logger.info(f"‚úÖ Chart sent to {target_id}")
                    else:
                        logger.error(f"‚ùå Failed to send chart to {target_id}")
                except Exception as inner_e:
                    logger.error(f"‚ùå Error sending chart to {target_id}: {inner_e}")

            return success_count > 0

        except Exception as e:
            logger.error(f"‚ùå Chart sending failed: {str(e)}")
            return False

    # =====================================================================
    # CONNECTION TEST & STATS
    # =====================================================================

    def test_connection(self) -> bool:
        """Test Telegram bot connection."""
        try:
            logger.info("üß™ Testing Telegram connection...")
            url = f"{self.base_url}/getMe"
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            data = response.json()
            if data.get("ok"):
                bot_name = data["result"].get("first_name", "Bot")
                logger.info(
                    f"‚úÖ Telegram connection successful | Bot: {bot_name}"
                )
                return True
            logger.error("‚ùå Telegram getMe returned not ok")
            return False
        except Exception as e:
            logger.error(f"‚ùå Telegram connection test failed: {str(e)}")
            return False

    def get_stats(self) -> Dict:
        """Get simple bot statistics."""
        return {
            "messages_sent": self.message_count,
            "chat_id": self.chat_id,
        }


_bot: Optional[TelegramBot] = None


def get_bot() -> TelegramBot:
    """Singleton getter for TelegramBot."""
    global _bot
    if _bot is None:
        _bot = TelegramBot()
    return _bot


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.DEBUG if DEBUG_MODE else logging.INFO,
        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    )
    bot = get_bot()
    bot.test_connection()
    bot.send_startup_message()


# Alias for backward compatibility / explicit naming
TelegramBotHandler = TelegramBot

def format_signal_message(signal: Dict) -> str:
    """Legacy/Helper formatter (optional)."""
    return f"{signal.get('signal_type', 'SIGNAL')} @ {signal.get('price_level', 0)}"


